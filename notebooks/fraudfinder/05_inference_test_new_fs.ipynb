{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "ur8xi4C7S06n",
    "tags": []
   },
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Fraudfinder - Inference Demo (New Feature Store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Fraudfinder](https://github.com/googlecloudplatform/fraudfinder) is a series of labs on how to build a real-time fraud detection system on Google Cloud. Throughout the Fraudfinder labs, you will learn how to read historical bank transaction data stored in data warehouse, read from a live stream of new transactions, perform exploratory data analysis (EDA), do feature engineering, ingest features into a feature store, train a model using feature store, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do real-time inference on your model with feature store, and monitor your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "This notebook shows how to use Feature Store and Model Endpoint for Realtime Inference\n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "* Invoke a Vetex AI Feature Store and Vetex AI Endpoint to test Realtime predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration settings from the setup notebook\n",
    "\n",
    "Set the constants used in this notebook and load the config settings from the `00_environment_setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "config = !gsutil cat gs://{BUCKET_NAME}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf",
    "tags": []
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries\n",
    "Next you will import the libraries needed for this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Vertex AI SDK\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "REGION = \"us-central1\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import json\n",
    "\n",
    "# General imports\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.aiplatform_v1 import (\n",
    "    FeatureOnlineStoreAdminServiceClient,\n",
    "    FeatureOnlineStoreServiceClient,\n",
    "    FeatureRegistryServiceClient,\n",
    ")\n",
    "from google.cloud.aiplatform_v1.types import feature as feature_pb2\n",
    "from google.cloud.aiplatform_v1.types import feature_group as feature_group_pb2\n",
    "from google.cloud.aiplatform_v1.types import (\n",
    "    feature_online_store as feature_online_store_pb2,\n",
    ")\n",
    "from google.cloud.aiplatform_v1.types import (\n",
    "    feature_online_store_admin_service as feature_online_store_admin_service_pb2,\n",
    ")\n",
    "from google.cloud.aiplatform_v1.types import (\n",
    "    feature_online_store_service as feature_online_store_service_pb2,\n",
    ")\n",
    "from google.cloud.aiplatform_v1.types import (\n",
    "    feature_registry_service as feature_registry_service_pb2,\n",
    ")\n",
    "from google.cloud.aiplatform_v1.types import feature_view as feature_view_pb2\n",
    "from google.cloud.aiplatform_v1.types import (\n",
    "    featurestore_service as featurestore_service_pb2,\n",
    ")\n",
    "from google.cloud.aiplatform_v1.types import io as io_pb2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vertex AI SDK\n",
    "vertex_ai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "def read_from_sub(project_id, subscription_name, messages=10):\n",
    "    \"\"\"\n",
    "    Read messages from a Pub/Sub subscription\n",
    "    Args:\n",
    "        project_id: project ID\n",
    "        subscription_name: the name of a Pub/Sub subscription in your project\n",
    "        messages: number of messages to read\n",
    "    Returns:\n",
    "        msg_data: list of messages in your Pub/Sub subscription as a Python dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    import ast\n",
    "\n",
    "    from google.api_core import retry\n",
    "    from google.cloud import pubsub_v1\n",
    "\n",
    "    subscriber = pubsub_v1.SubscriberClient()\n",
    "    subscription_path = subscriber.subscription_path(\n",
    "        project_id, subscription_name\n",
    "    )\n",
    "\n",
    "    # Wrap the subscriber in a 'with' block to automatically call close() to\n",
    "    # close the underlying gRPC channel when done.\n",
    "    with subscriber:\n",
    "        # The subscriber pulls a specific number of messages. The actual\n",
    "        # number of messages pulled may be smaller than max_messages.\n",
    "        response = subscriber.pull(\n",
    "            subscription=subscription_path,\n",
    "            max_messages=messages,\n",
    "            retry=retry.Retry(deadline=300),\n",
    "        )\n",
    "\n",
    "        if len(response.received_messages) == 0:\n",
    "            print(\"no messages\")\n",
    "            return\n",
    "\n",
    "        ack_ids = []\n",
    "        msg_data = []\n",
    "        for received_message in response.received_messages:\n",
    "            msg = ast.literal_eval(\n",
    "                received_message.message.data.decode(\"utf-8\")\n",
    "            )\n",
    "            msg_data.append(msg)\n",
    "            ack_ids.append(received_message.ack_id)\n",
    "\n",
    "        # Acknowledges the received messages so they will not be sent again.\n",
    "        subscriber.acknowledge(subscription=subscription_path, ack_ids=ack_ids)\n",
    "\n",
    "        print(\n",
    "            f\"Received and acknowledged {len(response.received_messages)} messages from {subscription_path}.\"\n",
    "        )\n",
    "\n",
    "        return msg_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": "ENDPOINT_ID = \"4917679004925820928\"  # TODO: add your endpoint id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(ENDPOINT_ID)\n",
    "from google.cloud import aiplatform as aiplatform\n",
    "\n",
    "# Instantiate Vertex AI Endpoint object\n",
    "endpoint_obj = aiplatform.Endpoint(ENDPOINT_ID)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "messages_tx = read_from_sub(\n",
    "    project_id=PROJECT_ID, subscription_name=\"ff-tx-sub\", messages=1\n",
    ")\n",
    "\n",
    "messages_tx"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "\n",
    "# Instantiate Vertex AI Feature Store object\n",
    "\n",
    "data_client = FeatureOnlineStoreServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(compact=True)\n",
    "\n",
    "\n",
    "def fs_features_lookup(ff_feature_store, features_type, features_key):\n",
    "\n",
    "    FEATURE_VIEW_ID = f\"fv_fraudfinder_{features_type}\"\n",
    "    FEATURE_VIEW_FULL_ID = f\"projects/{PROJECT_ID}/locations/{REGION}/featureOnlineStores/{ff_feature_store}/featureViews/{FEATURE_VIEW_ID}\"\n",
    "\n",
    "    features_map = {}\n",
    "\n",
    "    print(FEATURE_VIEW_FULL_ID)\n",
    "\n",
    "    try:\n",
    "        fe_continuous_data = data_client.fetch_feature_values(\n",
    "            request=feature_online_store_service_pb2.FetchFeatureValuesRequest(\n",
    "                feature_view=FEATURE_VIEW_FULL_ID,\n",
    "                data_key=feature_online_store_service_pb2.FeatureViewDataKey(\n",
    "                    key=features_key\n",
    "                ),\n",
    "                data_format=feature_online_store_service_pb2.FeatureViewDataFormat.PROTO_STRUCT,\n",
    "            )\n",
    "        )\n",
    "        features_map.update(\n",
    "            {k: v for k, v in fe_continuous_data.proto_struct.items()}\n",
    "        )\n",
    "    except Exception as exp:\n",
    "        print(f\"Requested entity {features_key} was not found\")\n",
    "    return features_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bigquery df --project {PROJECT_ID}\n",
    "SELECT * FROM tx.t_customers_streaming_features\n",
    "ORDER BY feature_timestamp DESC\n",
    "LIMIT 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "customer_key = df[\"entity_id\"][0]  # Or put known customer id here\n",
    "print(f\"entity_id={customer_key}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "customer_features = fs_features_lookup(\n",
    "    FEATURESTORE_ID, \"customers\", customer_key #customer_key\n",
    ")\n",
    "print(json.dumps(customer_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bigquery df --project {PROJECT_ID}\n",
    "SELECT * FROM tx.v_terminals_features\n",
    "ORDER BY feature_timestamp DESC\n",
    "LIMIT 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "terminal_key = df[\"entity_id\"][0]  # Or put known customer id here\n",
    "print(f\"entity_id={customer_key}\")\n",
    "terminal_features = fs_features_lookup(\n",
    "    FEATURESTORE_ID, \"terminals\", terminal_key\n",
    ")  # Change key values\n",
    "pp.pprint(terminal_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(compact=True)\n",
    "\n",
    "# Payload for manual test:\n",
    "# payload_json = {\n",
    "#     \"TX_ID\": \"61210be0744c43232990152d3eb2c2deb6035d8b\",\n",
    "#     \"TX_TS\": \"2025-09-06 17:27:51\",\n",
    "#     \"CUSTOMER_ID\": \"7389471951168361\",\n",
    "#     \"TERMINAL_ID\": \"45087784\",\n",
    "#     \"TX_AMOUNT\": 32.77\n",
    "# }\n",
    "\n",
    "default_features = {\n",
    "    \"customer_id_avg_amount_14day_window\": 0,\n",
    "    \"customer_id_avg_amount_15min_window\": 0,\n",
    "    \"customer_id_avg_amount_1day_window\": 0,\n",
    "    \"customer_id_avg_amount_30min_window\": 0,\n",
    "    \"customer_id_avg_amount_60min_window\": 0,\n",
    "    \"customer_id_avg_amount_7day_window\": 0,\n",
    "    \"customer_id_nb_tx_14day_window\": 0,\n",
    "    \"customer_id_nb_tx_7day_window\": 0,\n",
    "    \"customer_id_nb_tx_15min_window\": 0,\n",
    "    \"customer_id_nb_tx_1day_window\": 0,\n",
    "    \"customer_id_nb_tx_30min_window\": 0,\n",
    "    \"customer_id_nb_tx_60min_window\": 0,\n",
    "    \"terminal_id_avg_amount_15min_window\": 0,\n",
    "    \"terminal_id_avg_amount_30min_window\": 0,\n",
    "    \"terminal_id_avg_amount_60min_window\": 0,\n",
    "    \"terminal_id_nb_tx_14day_window\": 0,\n",
    "    \"terminal_id_nb_tx_15min_window\": 0,\n",
    "    \"terminal_id_nb_tx_1day_window\": 0,\n",
    "    \"terminal_id_nb_tx_30min_window\": 0,\n",
    "    \"terminal_id_nb_tx_60min_window\": 0,\n",
    "    \"terminal_id_nb_tx_7day_window\": 0,\n",
    "    \"terminal_id_risk_14day_window\": 0,\n",
    "    \"terminal_id_risk_1day_window\": 0,\n",
    "    \"terminal_id_risk_7day_window\": 0,\n",
    "}\n",
    "\n",
    "# Reading 1-st message\n",
    "payload_json = messages_tx[0]\n",
    "\n",
    "payload = default_features\n",
    "payload[\"tx_amount\"] = payload_json[\"TX_AMOUNT\"]\n",
    "\n",
    "# look up the customer features from New Vertex AI Feature Store\n",
    "customer_features = fs_features_lookup(\n",
    "    FEATURESTORE_ID, \"customers\", payload_json[\"CUSTOMER_ID\"]\n",
    ")\n",
    "# print the customer features from Vertex AI Feature Store\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"customer_features:\")\n",
    "pp.pprint(customer_features)\n",
    "\n",
    "# look up the treminal features from New Vertex AI Feature Store\n",
    "terminal_features = fs_features_lookup(\n",
    "    FEATURESTORE_ID, \"terminals\", payload_json[\"TERMINAL_ID\"]\n",
    ")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"terminal features:\")\n",
    "pp.pprint(terminal_features)\n",
    "\n",
    "# Add customer features to payload\n",
    "payload.update(customer_features)\n",
    "\n",
    "# Add terminal features to payload\n",
    "payload.update(terminal_features)\n",
    "\n",
    "# del payload[\"feature_timestamp\"]\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"[Payload to be sent to Vertex AI endpoint]\")\n",
    "pp.pprint(payload)\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "result = endpoint_obj.predict(instances=[payload])\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "pp.pprint(f\"[Prediction result]: {result}\")\n",
    "print(\"-------------------------------------------------------\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
