{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libs\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "print(f\"TF version: {tf.version.VERSION}\")\n",
    "print(f\"TFDV version: {tfdv.version.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read artifact information from metadata store.\n",
    "import beam_dag_runner\n",
    "\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.types import standard_artifacts\n",
    "\n",
    "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
    "    beam_dag_runner.METADATA_PATH\n",
    ")\n",
    "with metadata.Metadata(metadata_connection_config) as store:\n",
    "    stats_artifacts = store.get_artifacts_by_type(\n",
    "        standard_artifacts.ExampleStatistics.TYPE_NAME\n",
    "    )\n",
    "    schema_artifacts = store.get_artifacts_by_type(\n",
    "        standard_artifacts.Schema.TYPE_NAME\n",
    "    )\n",
    "    anomalies_artifacts = store.get_artifacts_by_type(\n",
    "        standard_artifacts.ExampleAnomalies.TYPE_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure output paths\n",
    "# Exact paths to output artifacts can also be found on KFP Web UI if you are using kubeflow.\n",
    "stats_path = stats_artifacts[-1].uri\n",
    "train_stats_file = os.path.join(stats_path, \"train\", \"stats_tfrecord\")\n",
    "eval_stats_file = os.path.join(stats_path, \"eval\", \"stats_tfrecord\")\n",
    "print(\n",
    "    \"Train stats file:{}, Eval stats file:{}\".format(\n",
    "        train_stats_file, eval_stats_file\n",
    "    )\n",
    ")\n",
    "\n",
    "schema_file = os.path.join(schema_artifacts[-1].uri, \"schema.pbtxt\")\n",
    "print(f\"Generated schame file:{schema_file}\")\n",
    "anomalies_file = os.path.join(anomalies_artifacts[-1].uri, \"anomalies.pbtxt\")\n",
    "print(f\"Generated anomalies file:{anomalies_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generated statistics from StatisticsGen\n",
    "train_stats = tfdv.load_statistics(train_stats_file)\n",
    "eval_stats = tfdv.load_statistics(eval_stats_file)\n",
    "tfdv.visualize_statistics(\n",
    "    lhs_statistics=eval_stats,\n",
    "    rhs_statistics=train_stats,\n",
    "    lhs_name=\"EVAL_DATASET\",\n",
    "    rhs_name=\"TRAIN_DATASET\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generated schema from SchemaGen\n",
    "schema = tfdv.load_schema_text(schema_file)\n",
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data vaildation result from ExampleValidator\n",
    "anomalies = tfdv.load_anomalies_text(anomalies_file)\n",
    "tfdv.display_anomalies(anomalies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
