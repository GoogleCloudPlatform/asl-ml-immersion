{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L6Nm1C-wshE"
   },
   "source": [
    "# Model Context Protocol(MCP)\n",
    "\n",
    "The **Model Context Protocol (MCP)** is an **open standard protocol initiated by Anthropic**. Its core purpose is to **standardize how AI models, applications, and agents connect to and interact with external tools, data sources, and services**. This allows AI applications to **access real-time data, use tools, fetch data, and utilize prompts** from compliant external systems.\n",
    "\n",
    "Think of MCP as a \"**USB-C port for AI**\",\n",
    "providing a **standardized interface** to solve the M×N integration problem by enabling any compliant AI client to connect to any compliant MCP server. It follows a **client-server architecture** (Hosts, Clients, Servers) and is built on **JSON-RPC 2.0**, supporting transports like Stdio and HTTP with SSE.\n",
    "\n",
    "MCP servers expose capabilities including **Tools, Resources, and Prompts**. It **standardizes the execution** of instructions generated by methods like Function Calling.\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Why MCP is needed?\n",
    "\n",
    "The need for the Model Context Protocol (MCP) arose primarily from the **limitations of LLMs being isolated** from real-time data, user-specific context, and external systems. Before MCP, connecting AI applications to the vast landscape of tools, databases, and services required **custom, fragmented integrations for each pair** of application and tool. This resulted in the \"M×N integration problem,\" which was **time-consuming, difficult to scale, and led to limited functionality**.\n",
    "\n",
    "MCP was needed to provide a **standardized, universal interface**—often likened to a \"**USB-C port for AI**\"—to connect AI models to *any* compliant external system. It also addresses the need to **standardize the execution phase** of LLM-generated instructions (like those from Function Calling), ensuring consistency and scalability across diverse tools. This approach **simplifies development, promotes interoperability**, and allows AI applications to access the real-world context and capabilities necessary to be truly helpful.\n",
    "<hr/>\n",
    "\n",
    "![MCP](https://norahsakal.com/assets/images/mcp_overview-641a298352ff835488af36be3d8eee52.png)\n",
    "Source: [Norah Sakal](https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/)\n",
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-3k4PVFxepX"
   },
   "source": [
    "### Core Architecture\n",
    "\n",
    "The core architecture of MCP follows a client-server model. The key components are:\n",
    "<br/><br/>\n",
    "• MCP Hosts: These are AI applications or environments, such as LLM Apps or IDEs, that initiate connections and operate the MCP client.\n",
    "<br/><br/>\n",
    "• MCP Clients: Located within the host application, clients maintain a one-to-one connection with servers. They act as intermediaries, facilitating communication between the MCP host and servers, sending requests, seeking information about server services, and handling LLM routing and orchestration.\n",
    "<br/><br/>\n",
    "• MCP Servers: These are lightweight programs that act as a gateway, allowing the MCP client to interact with external services and execute tasks. Servers connect to data sources and tools (like Google Drive, Slack, or databases) and expose specific capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR9_hyA42HNC"
   },
   "source": [
    "## Function Calling vs MCP\n",
    "\n",
    "Function Calling and the Model Context Protocol (MCP) are distinct but **complementary** frameworks for integrating Large Language Models (LLMs) with external systems. They represent **two phases** in the process of enabling LLMs to interact with the real world.\n",
    "\n",
    "**Key Differences Summarized:**\n",
    "\n",
    "\n",
    "| Feature           | Function Calling                                 | MCP (Model Context Protocol)                                   |\n",
    "| :---------------- | :----------------------------------------------- | :------------------------------------------------------------- |\n",
    "| **Purpose**       | Translates prompts into structured instructions. | Standardizes execution and response handling of instructions. |     |\n",
    "| **Focus**         | Generating action-ready commands from natural language. | Managing tool discovery, invocation, and response handling. |\n",
    "| **Control**       | LLM provider (e.g., Google Gemini, OpenAI, Anthropic).     | External system/application handling LLM integration.    |             |\n",
    "| **Output/Protocol** | Varies by LLM vendor (JSON-based). | Uses a standardized protocol (JSON-RPC 2.0). |\n",
    "| **Role in Workflow**| \"Ordering the task\" (Translation phase). | \"Executing the task\" (Execution phase).    |\n",
    "| **Architecture**  | Part of the LLM's output structure. | Client-server architecture connecting hosts, clients, and servers. |\n",
    "| **Statefulness**  | Typically a stateless request/response outcome from the LLM | Can support stateful connections and interactive workflows |\n",
    "| **Standardization** | No universal standard (frameworks like LangChain help manage variations). | Provides a consistent execution framework and ensures interoperability across tools. |\n",
    "| **Complexity/Setup** | Simpler, more direct method. | Requires setup of MCP clients and servers, potentially higher initial complexity. |       |\n",
    "| **Security**      | Relies on external API security and execution control management. | Designed with inherent security measures (host-mediated, access controls, user approval). |\n",
    "\n",
    "**Working Together:**\n",
    "\n",
    "Function Calling and MCP work together seamlessly. The application acts as an intermediary, translating the LLM's function call output (which varies by vendor) into a standardized MCP request (using JSON-RPC) that the MCP server can understand and execute. MCP then handles the execution of the tool and returns the result in a structured format, which the application can feed back to the LLM or the user.\n",
    "\n",
    "Think of it like a universal adapter for AI applications, similar to USB-C for physical devices. While Function Calling allows LLMs to translate prompts into *what* needs to be done (the command), MCP standardizes *how* it gets done (the execution across different tools and data sources). This combined approach allows for more efficient, scalable, and flexible AI-powered systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjxNy3BCH3zz"
   },
   "source": [
    "# Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGckulE4H58R"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eC_PjZ-Q2GkV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet \\\n",
    "google-adk==0.3.0 \\\n",
    "httpx>=0.24.0 \\\n",
    "pydantic>=2.0.0 \\\n",
    "fastmcp>=0.0.1 \\\n",
    "colab-xterm==0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeJf-U_iJOkP"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeJiIbR2ItpW",
    "outputId": "ab5cdf98-dfd3-484c-adfa-a2b62568cc5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKwGrxSiJXAk"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tu6ca4rJJVxp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"  # @param {type:'string'}\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ.setdefault(\"GOOGLE_CLOUD_PROJECT\", PROJECT_ID)\n",
    "os.environ.setdefault(\"GOOGLE_CLOUD_LOCATION\", LOCATION)\n",
    "os.environ.setdefault(\"GOOGLE_GENAI_USE_VERTEXAI\", \"True\")\n",
    "\n",
    "%load_ext colabxterm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfJ-_siaLJUZ"
   },
   "source": [
    "# Demo\n",
    "\n",
    "* This Demo uses [FastMCP](https://gofastmcp.com/getting-started/welcome) to create an Inventory Management tool MCP Server.\n",
    "\n",
    "* An ADK based agent act as MCP host and uses a MCP client([ADK MCP Toolset](https://google.github.io/adk-docs/tools/mcp-tools/#step-1-attach-the-fastmcp-server-to-your-adk-agent-via-mcptoolset:~:text=to%20your%20ADK%20agent%20via%20MCPToolset-,%C2%B6,-Create%20agent.py%20in%20./adk_agent_samples/fastmcp_agent)) to communicate with the MCP Server and fetches the available tools.\n",
    "\n",
    "* The ADK agent uses the tools from MCP server to answer inventory related request from users.\n",
    "\n",
    "### Create Directory for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftwIFKXV_hIs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir mcp-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCIRgv0FMLAs"
   },
   "source": [
    "# Download dummy Inventory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCiZIjhVNuBo",
    "outputId": "5e8f32ee-908a-4069-fa22-6e186ecdd3dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/solidate/mcp-demo/refs/heads/main/sku_data.csv -O mcp-demo/sku_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZ1GEPMnMQX7"
   },
   "source": [
    "# MCP Server code usign FastMCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olS-8oqkKArg",
    "outputId": "cdff26b5-574f-4727-e05d-2e5c93997985",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile mcp-demo/operations.py\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import asyncio\n",
    "from fastmcp import FastMCP\n",
    "from pydantic import  Field\n",
    "from pydantic.types import Literal\n",
    "\n",
    "# Define the path to the CSV file relative to this script\n",
    "# Assuming operations.py and sku_data.csv are in the same directory 'agents/inventory/'\n",
    "CSV_FILE_PATH = os.path.join(os.path.dirname(__file__), 'sku_data.csv')\n",
    "\n",
    "\n",
    "global mcp\n",
    "mcp = FastMCP(\n",
    "    name=\"Inventory MCP Server\",\n",
    "    instructions=\"\"\"\n",
    "    This Server provides inventory related data and helps in\n",
    "    updating the quantity of a specific SKU.\n",
    "\n",
    "    Call list_skus() to get the list of all the SKUs or any details related the items/SKUs.\n",
    "    Call update_sku_qty(sku_id) to update the quantity of a specific SKU.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def list_skus(sku_name: str = Field(\"*\", description=\"Name of the SKU\")):\n",
    "    \"\"\"\n",
    "    Reads the SKU data from the CSV file and returns it as a list of dictionaries.\n",
    "    If you are asked for the available items or any enquiry about the items/SKUs, call this function and\n",
    "    return only the consumer freindly information like id, name and its cost and available quantity.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CSV_FILE_PATH):\n",
    "        return {\"error\": \"SKU data file not found.\"}\n",
    "\n",
    "    skus = []\n",
    "    try:\n",
    "        with open(CSV_FILE_PATH, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                skus.append(row)\n",
    "        return {\"skus\": skus}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to read SKU data: {str(e)}\"}\n",
    "\n",
    "@mcp.tool()\n",
    "def update_sku_qty(\n",
    "            sku_id: str = Field(..., description=\"The SKU ID of the product to update.\"),\n",
    "            quantity: int = Field(..., description=\"The quantity to be added or removed from the SKU.\", ge=0),\n",
    "            sign: int = Field(1, description=\"1 for adding and -1 for removing.\")\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Updates the quantity of a specific SKU in the CSV file.\n",
    "    If you are asked for placing or returning/cancelling an order, call this function.\n",
    "\n",
    "    Args:\n",
    "        sku_id (str): The SKU ID of the product to update.\n",
    "        quantity (int): The new quantity for the SKU.\n",
    "        sign (int): 1 for adding and -1 for removing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A message indicating success or failure.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CSV_FILE_PATH):\n",
    "        return {\"error\": \"SKU data file not found.\"}\n",
    "\n",
    "    if not isinstance(quantity, int):\n",
    "        return {\"error\": \"Invalid quantity. Must be a non-negative integer.\"}\n",
    "\n",
    "    rows = []\n",
    "    updated = False\n",
    "    fieldnames = []\n",
    "\n",
    "    try:\n",
    "        with open(CSV_FILE_PATH, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            fieldnames = reader.fieldnames\n",
    "            if not fieldnames: # Handle empty or malformed CSV\n",
    "                return {\"error\": \"CSV file is empty or has no header.\"}\n",
    "\n",
    "            quantity *= sign\n",
    "\n",
    "            for row in reader:\n",
    "                if row.get('SKU') == sku_id:\n",
    "                    row['QuantityOnHand'] = int(row['QuantityOnHand']) + int(quantity)\n",
    "                    # Potentially update 'Status' based on new quantity vs ReorderLevel\n",
    "                    if 'ReorderLevel' in row and quantity <= int(row.get('ReorderLevel', 0)):\n",
    "                        row['Status'] = 'Low Stock'\n",
    "                    elif 'ReorderLevel' in row and quantity > int(row.get('ReorderLevel', 0)):\n",
    "                        row['Status'] = 'In Stock'\n",
    "                    updated = True\n",
    "                    updated_qty = row['QuantityOnHand']\n",
    "                rows.append(row)\n",
    "\n",
    "        if not updated:\n",
    "            return {\"error\": f\"SKU ID '{sku_id}' not found.\"}\n",
    "\n",
    "        with open(CSV_FILE_PATH, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        return {\"message\": f\"Quantity for SKU '{sku_id}' updated to {updated_qty}.\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to update SKU quantity: {str(e)}\"}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(mcp.run_sse_async(\n",
    "                        host=\"0.0.0.0\",\n",
    "                        port=4200,\n",
    "                        path=\"/inventory\",\n",
    "                        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PtAwoGnMiCh"
   },
   "source": [
    "#### Execute the below command in the terminal before moving to the next step\n",
    "```bash\n",
    "python mcp-demo/operations.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZmEr-i0Mioq"
   },
   "source": [
    "# Create ADK based agent with MCP client\n",
    "* Here MCPToolset is used to communicate with SSE server url where MCP Server runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxsE_rGI_z9b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import asyncio\n",
    "from contextlib import AsyncExitStack\n",
    "from uuid import uuid4\n",
    "\n",
    "import click\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, SseServerParams\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "async def create_agent():\n",
    "    common_exit_stack = AsyncExitStack()\n",
    "\n",
    "    remote_tools, _ = await MCPToolset.from_server(\n",
    "        connection_params=SseServerParams(\n",
    "            # TODO: IMPORTANT! Change the path below to your remote MCP Server path\n",
    "            url=\"http://0.0.0.0:4200/inventory\"\n",
    "        ),\n",
    "        async_exit_stack=common_exit_stack,\n",
    "    )\n",
    "\n",
    "    agent = LlmAgent(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        name=\"inventory_assistant\",\n",
    "        description=\"You are a specialized assistant for inventory management.\",\n",
    "        instruction=(\n",
    "            \"Help user get answer to their queries about inventory and update \"\n",
    "            \"the items.\"\n",
    "        ),\n",
    "        tools=remote_tools,\n",
    "    )\n",
    "    return agent, common_exit_stack\n",
    "\n",
    "\n",
    "async def ask_agent(query):\n",
    "    session_service = InMemorySessionService()\n",
    "    inventory_agent, exit_stack = await create_agent()\n",
    "\n",
    "    # Create the session here, just before it's used\n",
    "    session = session_service.create_session(\n",
    "        state={}, app_name=\"mcp_inventory_app\", user_id=str(uuid4())\n",
    "    )\n",
    "\n",
    "    runner = Runner(\n",
    "        app_name=\"mcp_inventory_app\",\n",
    "        agent=inventory_agent,\n",
    "        session_service=session_service,\n",
    "    )\n",
    "    user_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "    print(\"Running agent...\")\n",
    "    events_async = runner.run_async(\n",
    "        session_id=session.id, user_id=session.user_id, new_message=user_content\n",
    "    )\n",
    "    async for event in events_async:\n",
    "        print(\"-\" * 10)\n",
    "        print(event)\n",
    "        if event.is_final_response():\n",
    "            final_response = \"\".join(part.text for part in event.content.parts)\n",
    "            break\n",
    "\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"Final response:\")\n",
    "    print(\"-\" * 10)\n",
    "    print(final_response)\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Closing MCP server connection...\")\n",
    "    await exit_stack.aclose()\n",
    "    print(\"Cleanup complete.\")\n",
    "\n",
    "\n",
    "async def ask_inventory_agent(query):\n",
    "    loop = asyncio.get_running_loop()\n",
    "    await loop.create_task(ask_agent(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhDG2A8eHlGZ",
    "outputId": "71896688-c730-417b-ebf1-94a848bd2754",
    "tags": []
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"What all items are available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDSiRFB5GwGp",
    "outputId": "368e82df-8ae7-4481-9dd8-34f2fcba2ef0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"How many mouse are available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXB4Nisydm0S",
    "outputId": "e366baa4-e803-40c1-a4e2-108446d5610b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"Order 5 wireless mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CDI4qVmIUd2",
    "outputId": "173c8a36-ccfe-4e05-861b-12f3d7b82872",
    "tags": []
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"Sell 5 units for SKU002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVWNUWCPF9n9",
    "outputId": "ee8f6801-1a59-4391-a40e-0dbfd4fac829",
    "tags": []
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"How many mouse are available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZs1Ct4yG3I6",
    "outputId": "b7da66fc-b090-4a67-d63c-7a0c7f5b24ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"Sell 5 units for SKU002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0C4OMmfIl_T",
    "outputId": "9b6b3ebc-75f0-42fd-eb2b-91f7902c5b75"
   },
   "outputs": [],
   "source": [
    "await ask_inventory_agent(\"Restock 5 units for SKU002\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
