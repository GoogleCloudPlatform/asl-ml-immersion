{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN Encoder-Decoder for Translation with Keras3\n",
    "\n",
    "**Learning Objectives**\n",
    "1.  Learn how to build an efficient `tf.data.Dataset` pipeline for a seq2seq task.\n",
    "2.  Learn how to preprocess text using the `keras.layers.TextVectorization` layer.\n",
    "3.  Learn how to train an encoder-decoder model in Keras using the Functional API.\n",
    "4.  Learn how to create separate encoder and decoder models for inference.\n",
    "5.  Learn how to implement a translation (decoding) function from scratch.\n",
    "6.  Learn how to use the BLEU score to evaluate a translation model.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll build a Spanish-to-English translation model using a modern RNN encoder-decoder architecture with Keras 3.\n",
    "\n",
    "We will start by building an efficient and scalable input pipeline with the `tf.data.Dataset` API. A key part of our workflow will be using the `TextVectorization` layer to handle all text preprocessing—from standardization and tokenization to integer-encoding—directly within our model.\n",
    "\n",
    "Next, we will use the Keras Functional API to build and train our RNN encoder-decoder model. After training, we will create two specialized models—a dedicated encoder and a decoder—from the layers of our trained model. These specialized models are essential for performing inference, allowing us to implement a function that generates translations word by word.\n",
    "\n",
    "Finally, we'll evaluate the quality of our model's translations using the industry-standard BLEU score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 01:02:06.827142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760490126.855757   23474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760490126.864620   23474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import evaluate\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import utils_preproc\n",
    "from keras.layers import GRU, Dense, Embedding, Input\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MODEL_PATH = \"translate_models/baseline\"\n",
    "DATA_URL = (\n",
    "    \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    ")\n",
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a language dataset provided by http://www.manythings.org/anki/. The dataset contains Spanish-English  translation pairs in the format:\n",
    "\n",
    "```\n",
    "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "The dataset is a curated list of 120K translation pairs from http://tatoeba.org/, a platform for community contributed translations by native speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation data stored at: /home/jupyter/.keras/datasets/spa-eng_extracted/spa-eng/spa.txt\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = keras.utils.get_file(\"spa-eng.zip\", origin=DATA_URL, extract=True)\n",
    "\n",
    "path_to_file = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"spa-eng_extracted/spa-eng/spa.txt\"\n",
    ")\n",
    "print(\"Translation data stored at:\", path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    path_to_file, sep=\"\\t\", header=None, names=[\"english\", \"spanish\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>How boring!</td>\n",
       "      <td>¡Qué aburrimiento!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>I love sports.</td>\n",
       "      <td>Adoro el deporte.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55586</th>\n",
       "      <td>Would you like to swap jobs?</td>\n",
       "      <td>¿Te gustaría que intercambiemos los trabajos?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            english  \\\n",
       "1025                    How boring!   \n",
       "4338                 I love sports.   \n",
       "55586  Would you like to swap jobs?   \n",
       "\n",
       "                                             spanish  \n",
       "1025                              ¡Qué aburrimiento!  \n",
       "4338                               Adoro el deporte.  \n",
       "55586  ¿Te gustaría que intercambiemos los trabajos?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tf.data Pipeline\n",
    "To begin, we'll construct our training and evaluation datasets using the `tf.data` API, which is the standard for building efficient and scalable input pipelines in TensorFlow. This approach allows us to handle data in a memory-efficient way and seamlessly integrate it with Keras.\n",
    "\n",
    "Our process will be as follows:\n",
    "\n",
    "1. Load the data: We create a tf.data.Dataset directly from our pandas DataFrame using tf.data.Dataset.from_tensor_slices. This creates a dataset where each element is a pair of (Spanish, English) sentences.\n",
    "\n",
    "2. Split the data: We'll use the .take() and .skip() methods to create our training and validation sets. This is a clean and efficient way to split the data without having to load everything into memory at once.\n",
    "\n",
    "3. Define a standardization function: We create a custom_standardization function to preprocess our raw text. This function replicates the logic of the original preprocess_sentence function by lowercasing text, adding spaces around punctuation, and, most importantly, adding <start> and <end> tokens to each sentence. It is built using tf.strings operations, which allows it to be embedded directly into our TextVectorization layer and run efficiently on the GPU/TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 01:02:10.121561: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "BUFFER_SIZE = 32000\n",
    "BATCH_SIZE = 64\n",
    "TEST_PROP = 0.2\n",
    "NUM_EXAMPLES = 30000\n",
    "\n",
    "# Create a single dataset from your pandas DataFrame\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (data[\"spanish\"][:NUM_EXAMPLES], data[\"english\"][:NUM_EXAMPLES])\n",
    ")\n",
    "\n",
    "# Create the training and validation splits using take() and skip()\n",
    "TRAIN_SIZE = int(NUM_EXAMPLES * (1 - TEST_PROP))\n",
    "train_raw = full_dataset.take(TRAIN_SIZE)\n",
    "val_raw = full_dataset.skip(TRAIN_SIZE)\n",
    "\n",
    "# Define the custom standardization function for TextVectorization\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"Replicates the original preprocess_sentence function using tf.strings.\"\"\"\n",
    "    # Lowercase and strip leading/trailing whitespace\n",
    "    s = tf.strings.lower(input_string)\n",
    "    s = tf.strings.strip(s)\n",
    "\n",
    "    # Add spaces around punctuation\n",
    "    s = tf.strings.regex_replace(s, r\"([?.!,¿])\", r\" \\1 \")\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    s = tf.strings.regex_replace(s, r'[\" \"]+', \" \")\n",
    "\n",
    "    # Filter out unwanted characters, replacing them with a space\n",
    "    s = tf.strings.regex_replace(s, r\"[^a-zA-Z?.!,¿]+\", \" \")\n",
    "\n",
    "    # Strip again to remove any leading/trailing spaces created by cleaning\n",
    "    s = tf.strings.strip(s)\n",
    "\n",
    "    # Add the <start> and <end> tokens\n",
    "    s = tf.strings.join([\"<start>\", s, \"<end>\"], separator=\" \")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Adapt the TextVectorization Layers\n",
    "With our raw text datasets ready, we need to convert the sentences from strings into integer sequences that our model can understand. In Keras 3, the modern and efficient way to do this is with the `keras.layers.TextVectorization` layer. This layer handles tokenization, vocabulary creation, and integer-encoding directly within our model's graph.\n",
    "\n",
    "We will create two separate TextVectorization layers: one for the source language (Spanish) and one for the target language (English). We pass our custom_standardization function to the standardize argument to ensure the text is preprocessed according to our specific rules (including adding `<start>` and `<end>` tokens) before tokenization.\n",
    "\n",
    "The most crucial step is calling the `.adapt()` method. The `adapt` method reads through the text from our training dataset and builds a vocabulary of all the unique words. It's during this step that the layer learns the mapping from each word to a unique integer index. We do this for both the source and target vectorization layers on their respective text data.\n",
    "\n",
    "***NOTE: This cell takes 10-15 to run while it's adapting the pre-processing layer to our dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and adapt the TextVectorization layers\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# Adapt the layers to the training data\n",
    "source_text = train_raw.map(lambda x, y: x)\n",
    "target_text = train_raw.map(lambda x, y: y)\n",
    "\n",
    "source_vectorization.adapt(source_text)\n",
    "target_vectorization.adapt(target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Final Datasets\n",
    "Now that our TextVectorization layers have learned the vocabularies, we can build our final input pipelines.\n",
    "\n",
    "First, we store the vocabulary sizes for later use in our model's Embedding layers. Then, we define two helper functions:\n",
    "\n",
    "1. `vectorize_text`: This function takes the raw text sentences and applies the appropriate TextVectorization layer to convert them into integer sequences.\n",
    "\n",
    "2. `create_dataset`: This function prepares the integerized sequences for our encoder-decoder model. The decoder needs two versions of the target sequence during training: one for input (to predict the next word) and one for output (to compare against the prediction for calculating loss). This function creates:\n",
    "   - target_in: The target sequence with the last token removed.\n",
    "   - target_out: The target sequence with the first (<start>) token removed.  \n",
    "\n",
    "Finally, we chain together several `tf.data` methods to construct our final train_dataset and eval_dataset. We `.shuffle()` the training data, `.batch()` both datasets, apply our preprocessing functions using `.map()`, and call `.prefetch()` for better performance. We also inspect the shape of the first batch to confirm our pipeline is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape: (64, 10)\n",
      "Target in shape: (64, 8)\n",
      "Target out shape: (64, 8)\n"
     ]
    }
   ],
   "source": [
    "# Set vocabulary sizes\n",
    "INPUT_VOCAB_SIZE = source_vectorization.vocabulary_size()\n",
    "TARGET_VOCAB_SIZE = target_vectorization.vocabulary_size()\n",
    "\n",
    "\n",
    "def vectorize_text(source, target):\n",
    "    source = source_vectorization(source)\n",
    "    target = target_vectorization(target)\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def create_dataset(source, target):\n",
    "    target_in = target[:, :-1]\n",
    "    target_out = target[:, 1:]\n",
    "    return (source, target_in), target_out\n",
    "\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "train_dataset = (\n",
    "    train_raw.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(vectorize_text)\n",
    "    .map(create_dataset)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "eval_dataset = (\n",
    "    val_raw.batch(BATCH_SIZE)\n",
    "    .map(vectorize_text)\n",
    "    .map(create_dataset)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Set max lengths for the Embedding layers\n",
    "# We do this by inspecting the element_spec of the dataset\n",
    "for (source, target_in), target_out in train_dataset.take(1):\n",
    "    max_length_inp = source.shape[1]\n",
    "    max_length_targ = target_in.shape[1]\n",
    "    print(\"Source shape:\", source.shape)\n",
    "    print(\"Target in shape:\", target_in.shape)\n",
    "    print(\"Target out shape:\", target_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview a Batch of Data\n",
    "To verify that our data pipeline is working correctly, let's take one batch from our train_dataset and inspect the first example. We'll convert the integer tensors back to text to see what the model will receive during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example from a Training Batch ---\n",
      "\n",
      "Source (Spanish):\n",
      "  Tensor: [  2  16   9  14 131 686   4   3   0   0   0]\n",
      "  Text:   <start> l es un buen estudiante . <end>\n",
      "\n",
      "Target Input (English - for Decoder):\n",
      "  Tensor: [  2  13   9  11  76 622   4]\n",
      "  Text:   <start> he is a good student .\n",
      "\n",
      "Target Output (English - for Loss Calculation):\n",
      "  Tensor: [ 13   9  11  76 622   4   3]\n",
      "  Text:   he is a good student . <end>\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabularies from the vectorization layers\n",
    "source_vocab = source_vectorization.get_vocabulary()\n",
    "source_index_lookup = {i: word for i, word in enumerate(source_vocab)}\n",
    "\n",
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = {i: word for i, word in enumerate(target_vocab)}\n",
    "\n",
    "# Helper function to convert a tensor of token IDs back to a string\n",
    "\n",
    "\n",
    "def to_text(tensor, lookup_dict):\n",
    "    # Join the words, filtering out the padding token (ID 0)\n",
    "    return \" \".join([lookup_dict[i] for i in tensor.numpy() if i != 0])\n",
    "\n",
    "\n",
    "# Take one batch from the training dataset and inspect the first example\n",
    "for (source_batch, target_in_batch), target_out_batch in train_dataset.take(1):\n",
    "    # Get the first example from the batch\n",
    "    source_example = source_batch[0]\n",
    "    target_in_example = target_in_batch[0]\n",
    "    target_out_example = target_out_batch[0]\n",
    "\n",
    "    print(\"--- Example from a Training Batch ---\")\n",
    "    print(\"\\nSource (Spanish):\")\n",
    "    print(f\"  Tensor: {source_example.numpy()}\")\n",
    "    print(f\"  Text:   {to_text(source_example, source_index_lookup)}\")\n",
    "\n",
    "    print(\"\\nTarget Input (English - for Decoder):\")\n",
    "    print(f\"  Tensor: {target_in_example.numpy()}\")\n",
    "    print(f\"  Text:   {to_text(target_in_example, target_index_lookup)}\")\n",
    "\n",
    "    print(\"\\nTarget Output (English - for Loss Calculation):\")\n",
    "    print(f\"  Tensor: {target_out_example.numpy()}\")\n",
    "    print(f\"  Text:   {to_text(target_out_example, target_index_lookup)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RNN encoder-decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an encoder-decoder architecture, however we embed our words into a latent space prior to feeding them into the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_UNITS = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Encoder\n",
    "We will build our translator using a standard encoder-decoder architecture. The encoder's job is to process the entire input sentence and compress its meaning into a fixed-size vector, often called the \"thought vector\" or \"context vector.\"\n",
    "\n",
    "We'll use the Keras Functional API to construct the encoder, which gives us a clear way to define the flow of data. Our encoder will have two main layers:\n",
    "\n",
    "1. Embedding Layer: This layer takes the integer-encoded vocabulary and learns a dense vector representation (an embedding) for each word. These embeddings can capture semantic relationships between words.\n",
    "\n",
    "2. GRU (Gated Recurrent Unit) Layer: This is a type of Recurrent Neural Network (RNN) that processes the sequence of word embeddings one by one. We configure it with return_state=True to get the final hidden state of the GRU after it has processed the entire input sentence. This final hidden state is the \"thought vector\" that encapsulates the meaning of the input sentence and will be passed to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
    "\n",
    "encoder_inputs_embedded = Embedding(\n",
    "    input_dim=INPUT_VOCAB_SIZE,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    name=\"encoder_embedding\",\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_rnn = GRU(\n",
    "    units=HIDDEN_UNITS,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    recurrent_initializer=\"glorot_uniform\",\n",
    "    name=\"encoder_gru\",\n",
    ")\n",
    "\n",
    "encoder_outputs, encoder_state = encoder_rnn(encoder_inputs_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Decoder\n",
    "The decoder takes the \"thought vector\" from the encoder and generates the translated sentence word by word.\n",
    "\n",
    "Its architecture mirrors the encoder, containing Embedding and GRU layers. The crucial difference is that we initialize the decoder's GRU layer with the final hidden state of the encoder `(initial_state=encoder_state)`. This is how the decoder receives the context from the source sentence, which it then uses to generate the correct translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
    "\n",
    "decoder_inputs_embedded = Embedding(\n",
    "    input_dim=TARGET_VOCAB_SIZE,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    name=\"decoder_embedding\",\n",
    ")(decoder_inputs)\n",
    "\n",
    "decoder_rnn = GRU(\n",
    "    units=HIDDEN_UNITS,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    recurrent_initializer=\"glorot_uniform\",\n",
    "    name=\"decoder_gru\",\n",
    ")\n",
    "\n",
    "decoder_outputs, decoder_state = decoder_rnn(\n",
    "    decoder_inputs_embedded, initial_state=encoder_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of the encoder-decoder architecture is a softmax `Dense` layer that will create the next word probability vector or next word `predictions` from the `decoder_output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(TARGET_VOCAB_SIZE, activation=\"softmax\", name=\"dense\")\n",
    "\n",
    "predictions = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Compile the Model\n",
    "To create the complete trainable model, we instantiate a Model object and specify the encoder and decoder inputs, and the final predictions as the output.\n",
    "\n",
    "We then compile the model, configuring it for training. We use the `adam` optimizer and the `sparse_categorical_crossentropy` loss function. This loss is ideal for our task because our targets are integers (the word indices) and the model's output is a probability distribution over the vocabulary.\n",
    "\n",
    "Finally, we call `.summary()` to print a useful overview of the model's architecture, including the layers, output shapes, and the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,970,688</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,079,552</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │ encoder_embeddin… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)]            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │ decoder_embeddin… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │            │ encoder_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)]            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,322,425</span> │ decoder_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4217</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,970,688\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,079,552\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_gru (\u001b[38;5;33mGRU\u001b[0m)   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m3,938,304\u001b[0m │ encoder_embeddin… │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │                   │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)]            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_gru (\u001b[38;5;33mGRU\u001b[0m)   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m3,938,304\u001b[0m │ decoder_embeddin… │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │            │ encoder_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)]            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m4,322,425\u001b[0m │ decoder_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m4217\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,249,273</span> (58.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,249,273\u001b[0m (58.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,249,273</span> (58.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,249,273\u001b[0m (58.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the model!\n",
    "\n",
    "***NOTE: Update the number of `EPOCHS` to 10/15 to get a decent translation performance. This will increase the training time***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 1s/step - loss: 2.5296 - val_loss: 2.3763\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=eval_dataset,\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing the Translation (Inference) Function\n",
    "\n",
    "Now that our model is trained, we need a way to use it for translation. We can't simply call `model.predict()` on a Spanish sentence because the model expects both a source (Spanish) and a target (English) sentence as input. During training, we used the ground-truth target sentence in a technique called \"teacher forcing.\" For inference, we don't have the target sentence—that's what we need to generate!\n",
    "\n",
    "The solution is to generate the translation word by word in a loop. The process works like this:\n",
    "\n",
    "1.  Take the input sentence (e.g., \"No estamos comiendo.\") and pass it through the encoder to get its final hidden state (the \"thought vector\").\n",
    "2.  Start the decoder with the `<start>` token.\n",
    "3.  Feed the `<start>` token and the encoder's state into the decoder to predict the first word of the translation.\n",
    "4.  Take the predicted word, feed it back into the decoder as input for the next step, and use the new decoder state.\n",
    "5.  Repeat this process until the decoder predicts the `<end>` token, signaling that the translation is complete.\n",
    "\n",
    "To implement this, we will create two new, specialized models using the layers from the model we just trained:\n",
    "\n",
    "*   An **`encoder_model`** that takes a raw string sentence, vectorizes it, and returns the encoder's final hidden state.\n",
    "*   A **`decoder_model`** that takes the current predicted sequence and a hidden state, and returns the prediction for the next word, along with the updated hidden state.\n",
    "\n",
    "The following cells will define these two models and the `decode_sequences` function that uses them to perform the translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Inference Encoder Model ---\n",
    "# This model will convert raw Spanish sentences into the encoder's final state.\n",
    "\n",
    "# Input layer for raw strings\n",
    "encoder_string_input = keras.Input(\n",
    "    shape=(1,), dtype=\"string\", name=\"encoder_string_input\"\n",
    ")\n",
    "\n",
    "# Vectorize the strings using the adapted layer\n",
    "encoder_vectorized = source_vectorization(encoder_string_input)\n",
    "\n",
    "# Reuse the trained Embedding layer\n",
    "encoder_embedding_layer = model.get_layer(\"encoder_embedding\")\n",
    "encoder_embedded = encoder_embedding_layer(encoder_vectorized)\n",
    "\n",
    "# Reuse the trained GRU layer\n",
    "encoder_gru_layer = model.get_layer(\"encoder_gru\")\n",
    "_, encoder_state_output = encoder_gru_layer(encoder_embedded)\n",
    "\n",
    "# Create the final encoder model for inference\n",
    "encoder_model = keras.Model(\n",
    "    inputs=encoder_string_input,\n",
    "    outputs=encoder_state_output,\n",
    "    name=\"inference_encoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Inference Decoder Model ---\n",
    "# This model's structure is similar to the original, as it works with token IDs.\n",
    "\n",
    "# Input layers for the decoder\n",
    "decoder_input = keras.Input(shape=(None,), name=\"decoder_input\")\n",
    "decoder_state_input = keras.Input(\n",
    "    shape=(HIDDEN_UNITS,), name=\"decoder_state_input\"\n",
    ")\n",
    "\n",
    "# Reuse trained layers from the main model\n",
    "decoder_embedding_layer = model.get_layer(\"decoder_embedding\")\n",
    "decoder_gru_layer = model.get_layer(\"decoder_gru\")\n",
    "decoder_dense_layer = model.get_layer(\"dense\")\n",
    "\n",
    "# Build the decoder graph\n",
    "decoder_embedded = decoder_embedding_layer(decoder_input)\n",
    "decoder_outputs, decoder_state_output = decoder_gru_layer(\n",
    "    decoder_embedded, initial_state=decoder_state_input\n",
    ")\n",
    "decoder_predictions = decoder_dense_layer(decoder_outputs)\n",
    "\n",
    "# Create the final decoder model for inference\n",
    "decoder_model = keras.Model(\n",
    "    inputs=[decoder_input, decoder_state_input],\n",
    "    outputs=[decoder_predictions, decoder_state_output],\n",
    "    name=\"inference_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the Translation\n",
    "\n",
    "With our specialized encoder and decoder models ready, we can now define the main `decode_sequences` function that ties everything together to perform the translation.\n",
    "\n",
    "This function implements the step-by-step decoding process:\n",
    "\n",
    "1.  **Encode the input**: The raw input sentences are passed to the `encoder_model` to get the initial \"thought vector\" or hidden state.\n",
    "\n",
    "2.  **Initialize the sequence**: A target sequence is created, containing only the `<start>` token for each sentence in the batch.\n",
    "\n",
    "3.  **Iteratively decode**: In a loop, the `decoder_model` is called with the current target sequence and the hidden state to predict the next token. For simplicity, we use `argmax` to select the most probable token as our prediction.\n",
    "\n",
    "4.  **Append and update**: The predicted token is appended to our result, and the process is repeated with the new token and the updated hidden state from the decoder.\n",
    "\n",
    "5.  **Stop condition**: The loop continues until the special `<end>` token is generated or the maximum sequence length is reached.\n",
    "\n",
    "Finally, we'll test our function with a few example sentences to see the translation results in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the vocabulary and start/end token IDs from the adapted TextVectorization layer\n",
    "targ_vocab = target_vectorization.get_vocabulary()\n",
    "targ_index_lookup = dict(zip(range(len(targ_vocab)), targ_vocab))\n",
    "start_token_id = target_vectorization.get_vocabulary().index(\"<start>\")\n",
    "end_token_id = target_vectorization.get_vocabulary().index(\"<end>\")\n",
    "\n",
    "\n",
    "def decode_sequences(input_sentences, max_decode_length=50):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        input_sentences: A list of raw strings in the source language.\n",
    "    Returns:\n",
    "        A list of translated sentences.\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(input_sentences)[0]\n",
    "\n",
    "    # Encode the input strings to get the initial state.\n",
    "    states_value = encoder_model(input_sentences)\n",
    "\n",
    "    # Initialize the target sequence with the <start> token ID.\n",
    "    target_seq = tf.fill([batch_size, 1], start_token_id)\n",
    "    decoded_sentences = [\"\" for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(max_decode_length):\n",
    "        output_tokens, decoder_state = decoder_model([target_seq, states_value])\n",
    "\n",
    "        # Sample a token (we use argmax for simplicity)\n",
    "        sampled_token_index = tf.argmax(output_tokens[:, -1, :], axis=-1)\n",
    "\n",
    "        for j in range(batch_size.numpy()):\n",
    "            token = targ_index_lookup[sampled_token_index[j].numpy()]\n",
    "            if token == \"<end>\":\n",
    "                continue  # Don't add the end token to the output\n",
    "            decoded_sentences[j] += token + \" \"\n",
    "\n",
    "        # Update the target sequence for the next iteration\n",
    "        target_seq = tf.expand_dims(sampled_token_index, axis=-1)\n",
    "\n",
    "        # Update the decoder state\n",
    "        states_value = decoder_state\n",
    "\n",
    "    return [s.strip() for s in decoded_sentences]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "sentences = [\n",
    "    \"No estamos comiendo.\",\n",
    "    \"Está llegando el invierno.\",\n",
    "]\n",
    "\n",
    "machine_translations = decode_sequences(tf.constant(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "INPUT:\n",
      "No estamos comiendo.\n",
      "REFERENCE TRANSLATION:\n",
      "We're not eating.\n",
      "MACHINE TRANSLATION:\n",
      "we re not crazy .\n",
      "-\n",
      "INPUT:\n",
      "Está llegando el invierno.\n",
      "REFERENCE TRANSLATION:\n",
      "Winter is coming.\n",
      "MACHINE TRANSLATION:\n",
      "it s the bus .\n",
      "-\n",
      "INPUT:\n",
      "El invierno se acerca.\n",
      "REFERENCE TRANSLATION:\n",
      "Winter is coming.\n",
      "MACHINE TRANSLATION:\n",
      "the economy is over .\n",
      "-\n",
      "INPUT:\n",
      "Tom no comio nada.\n",
      "REFERENCE TRANSLATION:\n",
      "Tom ate nothing.\n",
      "MACHINE TRANSLATION:\n",
      "tom can t help .\n",
      "-\n",
      "INPUT:\n",
      "Su pierna mala le impidió ganar la carrera.\n",
      "REFERENCE TRANSLATION:\n",
      "His bad leg prevented him from winning the race.\n",
      "MACHINE TRANSLATION:\n",
      "her is your room .\n",
      "-\n",
      "INPUT:\n",
      "Su respuesta es erronea.\n",
      "REFERENCE TRANSLATION:\n",
      "Your answer is wrong.\n",
      "MACHINE TRANSLATION:\n",
      "the house is good .\n",
      "-\n",
      "INPUT:\n",
      "¿Qué tal si damos un paseo después del almuerzo?\n",
      "REFERENCE TRANSLATION:\n",
      "How about going for a walk after lunch?\n",
      "MACHINE TRANSLATION:\n",
      "how old is your ?\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"No estamos comiendo.\",\n",
    "    \"Está llegando el invierno.\",\n",
    "    \"El invierno se acerca.\",\n",
    "    \"Tom no comio nada.\",\n",
    "    \"Su pierna mala le impidió ganar la carrera.\",\n",
    "    \"Su respuesta es erronea.\",\n",
    "    \"¿Qué tal si damos un paseo después del almuerzo?\",\n",
    "]\n",
    "\n",
    "reference_translations = [\n",
    "    \"We're not eating.\",\n",
    "    \"Winter is coming.\",\n",
    "    \"Winter is coming.\",\n",
    "    \"Tom ate nothing.\",\n",
    "    \"His bad leg prevented him from winning the race.\",\n",
    "    \"Your answer is wrong.\",\n",
    "    \"How about going for a walk after lunch?\",\n",
    "]\n",
    "\n",
    "machine_translations = decode_sequences(tf.constant(sentences))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(\"-\")\n",
    "    print(\"INPUT:\")\n",
    "    print(sentences[i])\n",
    "    print(\"REFERENCE TRANSLATION:\")\n",
    "    print(reference_translations[i])\n",
    "    print(\"MACHINE TRANSLATION:\")\n",
    "    print(machine_translations[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric (BLEU)\n",
    "\n",
    "Unlike say, image classification, there is no one right answer for a machine translation. However our current loss metric, cross entropy, only gives credit when the machine translation matches the exact same word in the same order as the reference translation. \n",
    "\n",
    "Many attempts have been made to develop a better metric for natural language evaluation. The most popular currently is Bilingual Evaluation Understudy (BLEU).\n",
    "\n",
    "- It is quick and inexpensive to calculate.\n",
    "- It allows flexibility for the ordering of words and phrases.\n",
    "- It is easy to understand.\n",
    "- It is language independent.\n",
    "- It correlates highly with human evaluation.\n",
    "- It has been widely adopted.\n",
    "\n",
    "The score is from 0 to 1, where 1 is an exact match.\n",
    "\n",
    "It works by counting matching n-grams between the machine and reference texts, regardless of order. BLUE-4 counts matching n grams from 1-4 (1-gram, 2-gram, 3-gram and 4-gram). It is common to report both BLUE-1 and BLUE-4\n",
    "\n",
    "It still is imperfect, since it gives no credit to synonyms and so human evaluation is still best when feasible. However BLEU is commonly considered the best among bad options for an automated metric.\n",
    "\n",
    "The Hugging Face evaluate framework has an implementation that we will use.\n",
    "\n",
    "We can't run calculate BLEU during training, because at that time the correct decoder input is used. Instead we'll calculate it now.\n",
    "\n",
    "For more info: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess(sentence):\n",
    "    filtered = list(filter(lambda x: x != \"\" and x != \"<end>\", sentence))\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now average the `bleu_1` and `bleu_4` scores for all the sentence pairs in the eval set. The next cell takes around 1 minute (8 minutes for full dataset eval) to run, the bulk of which is decoding the sentences in the validation set. Please wait until completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EVALUATE = 1000  # `len(input_tensor_val)` for full eval.\n",
    "\n",
    "reference = []\n",
    "candidate = []\n",
    "\n",
    "for idx in tqdm(range(NUM_EVALUATE)):\n",
    "    reference_sentence = utils_preproc.int2word(\n",
    "        targ_lang, target_tensor_val[idx][1:]\n",
    "    )\n",
    "\n",
    "    decoded_sentence = decode_sequences(\n",
    "        input_tensor_val[idx : idx + 1], targ_lang, max_length_targ\n",
    "    )[0]\n",
    "\n",
    "    candidate.append(postprocess(decoded_sentence))\n",
    "    reference.append([postprocess(reference_sentence)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_1 = bleu.compute(predictions=candidate, references=reference, max_order=1)\n",
    "bleu_4 = bleu.compute(predictions=candidate, references=reference, max_order=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bleu_1[\"bleu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bleu_4[\"bleu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Francois Chollet: https://github.com/keras-team/keras-io/blob/master/examples/nlp/lstm_seq2seq.py\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
