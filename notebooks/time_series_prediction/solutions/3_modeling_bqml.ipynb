{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Prediction with BQML and AutoML\n",
    "\n",
    "**Objectives**\n",
    " 1. Learn how to use BQML to create a classification time-series model using `CREATE MODEL`.\n",
    " 2. Learn how to use BQML to create a linear regression time-series model.\n",
    " 3. Learn how to use AutoML Tables to build a time series model from data in BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "%env PROJECT = {PROJECT}\n",
    "%env REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from IPython import get_ipython\n",
    "\n",
    "bq = bigquery.Client(project=PROJECT)\n",
    "\n",
    "\n",
    "def create_dataset():\n",
    "    dataset = bigquery.Dataset(bq.dataset(\"stock_market\"))\n",
    "    try:\n",
    "        bq.create_dataset(dataset)  # Will fail if dataset already exists.\n",
    "        print(\"Dataset created\")\n",
    "    except:\n",
    "        print(\"Dataset already exists\")\n",
    "\n",
    "\n",
    "def create_features_table():\n",
    "    error = None\n",
    "    try:\n",
    "        bq.query(\n",
    "            \"\"\"\n",
    "        CREATE TABLE stock_market.eps_percent_change_sp500\n",
    "        AS\n",
    "        SELECT *\n",
    "        FROM `stock_market.eps_percent_change_sp500`\n",
    "        \"\"\"\n",
    "        ).to_dataframe()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "    if error is None:\n",
    "        print(\"Table created\")\n",
    "    elif \"Already Exists\" in error:\n",
    "        print(\"Table already exists.\")\n",
    "    else:\n",
    "        print(error)\n",
    "        raise Exception(\"Table was not created.\")\n",
    "\n",
    "\n",
    "create_dataset()\n",
    "create_features_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the dataset\n",
    "\n",
    "In the previous lab we created the data we will use modeling and saved them as tables in BigQuery. Let's examine that table again to see that everything is as we expect. Then, we will build a model using BigQuery ML using this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  stock_market.eps_percent_change_sp500\n",
    "LIMIT\n",
    "  10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BQML\n",
    "\n",
    "### Create classification model for `direction`\n",
    "\n",
    "To create a model\n",
    "1. Use `CREATE MODEL` and provide a destination table for resulting model. Alternatively we can use `CREATE OR REPLACE MODEL` which allows overwriting an existing model.\n",
    "2. Use `OPTIONS` to specify the model type (linear_reg or logistic_reg). There are many more options [we could specify](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create#model_option_list), such as regularization and learning rate, but we'll accept the defaults.\n",
    "3. Provide the query which fetches the training data \n",
    "\n",
    "Have a look at [Step Two of this tutorial](https://cloud.google.com/bigquery/docs/bigqueryml-natality) to see another example.\n",
    "\n",
    "**The query will take about two minutes to complete**\n",
    "\n",
    "\n",
    "We'll start with creating a classification model to predict the `direction` of each stock. \n",
    "\n",
    "We'll take a random split using the `symbol` value. With about 500 different values, using `ABS(MOD(FARM_FINGERPRINT(symbol), 15)) = 1` will give 30 distinct `symbol` values which corresponds to about 171,000 training examples. After taking 70% for training, we will be building a model on about 110,000 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "CREATE OR REPLACE MODEL\n",
    "  stock_market.direction_model OPTIONS(model_type = \"logistic_reg\",\n",
    "    input_label_cols = [\"direction\"]) AS\n",
    "  -- query to fetch training data\n",
    "SELECT\n",
    "  symbol,\n",
    "  Date,\n",
    "  Open,\n",
    "  close_MIN_prior_5_days,\n",
    "  close_MIN_prior_20_days,\n",
    "  close_MIN_prior_260_days,\n",
    "  close_MAX_prior_5_days,\n",
    "  close_MAX_prior_20_days,\n",
    "  close_MAX_prior_260_days,\n",
    "  close_AVG_prior_5_days,\n",
    "  close_AVG_prior_20_days,\n",
    "  close_AVG_prior_260_days,\n",
    "  close_STDDEV_prior_5_days,\n",
    "  close_STDDEV_prior_20_days,\n",
    "  close_STDDEV_prior_260_days,\n",
    "  direction\n",
    "FROM\n",
    "  `stock_market.eps_percent_change_sp500`\n",
    "WHERE\n",
    "  tomorrow_close IS NOT NULL\n",
    "  AND ABS(MOD(FARM_FINGERPRINT(symbol), 15)) = 1\n",
    "  AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) <= 15 * 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training statistics and examine training info\n",
    "\n",
    "After creating our model, we can evaluate the performance using the [`ML.EVALUATE` function](https://cloud.google.com/bigquery-ml/docs/bigqueryml-natality#step_four_evaluate_your_model). With this command, we can find the precision, recall, accuracy F1-score and AUC of our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL `stock_market.direction_model`,\n",
    "    (\n",
    "    SELECT\n",
    "      symbol,\n",
    "      Date,\n",
    "      Open,\n",
    "      close_MIN_prior_5_days,\n",
    "      close_MIN_prior_20_days,\n",
    "      close_MIN_prior_260_days,\n",
    "      close_MAX_prior_5_days,\n",
    "      close_MAX_prior_20_days,\n",
    "      close_MAX_prior_260_days,\n",
    "      close_AVG_prior_5_days,\n",
    "      close_AVG_prior_20_days,\n",
    "      close_AVG_prior_260_days,\n",
    "      close_STDDEV_prior_5_days,\n",
    "      close_STDDEV_prior_20_days,\n",
    "      close_STDDEV_prior_260_days,\n",
    "      direction\n",
    "    FROM\n",
    "      `stock_market.eps_percent_change_sp500`\n",
    "    WHERE\n",
    "      tomorrow_close IS NOT NULL\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(symbol), 15)) = 1\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) > 15 * 70\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) <= 15 * 85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine the training statistics collected by Big Query. To view training results we use the [`ML.TRAINING_INFO`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-train) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.TRAINING_INFO(MODEL `stock_market.direction_model`)\n",
    "ORDER BY iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to simple benchmark\n",
    "\n",
    "Another way to asses the performance of our model is to compare with a simple benchmark. We can do this by seeing what kind of accuracy we would get using the naive strategy of just predicted the majority class. For the training dataset, the majority class is 'STAY'. The following query we can see how this naive strategy would perform on the eval set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "WITH\n",
    "  eval_data AS (\n",
    "  SELECT\n",
    "    symbol,\n",
    "    Date,\n",
    "    Open,\n",
    "    close_MIN_prior_5_days,\n",
    "    close_MIN_prior_20_days,\n",
    "    close_MIN_prior_260_days,\n",
    "    close_MAX_prior_5_days,\n",
    "    close_MAX_prior_20_days,\n",
    "    close_MAX_prior_260_days,\n",
    "    close_AVG_prior_5_days,\n",
    "    close_AVG_prior_20_days,\n",
    "    close_AVG_prior_260_days,\n",
    "    close_STDDEV_prior_5_days,\n",
    "    close_STDDEV_prior_20_days,\n",
    "    close_STDDEV_prior_260_days,\n",
    "    direction\n",
    "  FROM\n",
    "    `stock_market.eps_percent_change_sp500`\n",
    "  WHERE\n",
    "    tomorrow_close IS NOT NULL\n",
    "    AND ABS(MOD(FARM_FINGERPRINT(symbol), 15)) = 1\n",
    "    AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) > 15 * 70\n",
    "    AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) <= 15 * 85)\n",
    "SELECT\n",
    "  direction,\n",
    "  (COUNT(direction)* 100 / (\n",
    "    SELECT\n",
    "      COUNT(*)\n",
    "    FROM\n",
    "      eval_data)) AS percentage\n",
    "FROM\n",
    "  eval_data\n",
    "GROUP BY\n",
    "  direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the naive strategy of just guessing the majority class would have accuracy of 0.5509 on the eval dataset, just below our BQML model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create regression model for `normalized change`\n",
    "\n",
    "We can also use BigQuery to train a regression model to predict the normalized change for each stock. To do this in BigQuery we need only change the OPTIONS when calling `CREATE OR REPLACE MODEL`. This will give us a more precise prediction rather than just predicting if the stock will go up, down, or stay the same. Thus, we can treat this problem as either a regression problem or a classification problem, depending on the business needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "CREATE OR REPLACE MODEL\n",
    "  stock_market.price_model OPTIONS(model_type = \"linear_reg\",\n",
    "    input_label_cols = [\"normalized_change\"]) AS\n",
    "  -- query to fetch training data\n",
    "SELECT\n",
    "  symbol,\n",
    "  Date,\n",
    "  Open,\n",
    "  close_MIN_prior_5_days,\n",
    "  close_MIN_prior_20_days,\n",
    "  close_MIN_prior_260_days,\n",
    "  close_MAX_prior_5_days,\n",
    "  close_MAX_prior_20_days,\n",
    "  close_MAX_prior_260_days,\n",
    "  close_AVG_prior_5_days,\n",
    "  close_AVG_prior_20_days,\n",
    "  close_AVG_prior_260_days,\n",
    "  close_STDDEV_prior_5_days,\n",
    "  close_STDDEV_prior_20_days,\n",
    "  close_STDDEV_prior_260_days,\n",
    "  normalized_change\n",
    "FROM\n",
    "  `stock_market.eps_percent_change_sp500`\n",
    "WHERE\n",
    "  normalized_change IS NOT NULL\n",
    "  AND ABS(MOD(FARM_FINGERPRINT(symbol), 15)) = 1\n",
    "  AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) <= 15 * 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before we can examine the evaluation metrics for our regression model and examine the training statistics in Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL `stock_market.price_model`,\n",
    "    (\n",
    "    SELECT\n",
    "      symbol,\n",
    "      Date,\n",
    "      Open,\n",
    "      close_MIN_prior_5_days,\n",
    "      close_MIN_prior_20_days,\n",
    "      close_MIN_prior_260_days,\n",
    "      close_MAX_prior_5_days,\n",
    "      close_MAX_prior_20_days,\n",
    "      close_MAX_prior_260_days,\n",
    "      close_AVG_prior_5_days,\n",
    "      close_AVG_prior_20_days,\n",
    "      close_AVG_prior_260_days,\n",
    "      close_STDDEV_prior_5_days,\n",
    "      close_STDDEV_prior_20_days,\n",
    "      close_STDDEV_prior_260_days,\n",
    "      normalized_change\n",
    "    FROM\n",
    "      `stock_market.eps_percent_change_sp500`\n",
    "    WHERE\n",
    "      normalized_change IS NOT NULL\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(symbol), 15)) = 1\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) > 15 * 70\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(symbol), 15 * 100)) <= 15 * 85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "#standardSQL\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.TRAINING_INFO(MODEL `stock_market.price_model`)\n",
    "ORDER BY iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a Time Series model using AutoML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1. Create a Dataset\n",
    "\n",
    "In the GCP Navigation Menu, navigate to **Vertex AI -> Datasets**.\n",
    "\n",
    "Select **Create** and give it a name like `stock_market`. In the **Select a data type and objective** section, select **Tabular** and under Tabular select, **Regression/Classification**. Click **Create** at the bottom.\n",
    "\n",
    "<img src='../assets/create_dataset.png' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2. Import the Data\n",
    "\n",
    "Once you have created the dataset, you can add data to it using BigQuery. Under **Select a data source** select **Select a table or view from BigQuery**. In the BigQuery path field, browse for `eps_percent_change_sp500`.\n",
    "\n",
    "<img src='../assets/import_data.png' width='50%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Train the model \n",
    "\n",
    "Once the data has been imported into the dataset. You can get basic statistics for each of the feature columns, by clicking **GENERATE STATISTICS** (Note: This will take a couple of minutes). Since the data has been imported we can now proceed and train a classification model. Select **Train a new model** from the left column. Set the objective as \"Classification\". Ensure that the model training method is set to AutoML. Click **Continue**\n",
    "\n",
    "<img src='../assets/set_training_objective.png' width='80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Model details, select the column `direction` as the Target Column. This is the label column we want to train our model on. Click **Continue**\n",
    "\n",
    "<img src='../assets/select_target_label.png' width='80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Training options, exclude all columns **except** for the following\n",
    "```\n",
    "symbol\n",
    "Date\n",
    "Open\n",
    "close_MIN_prior_5_days\n",
    "close_MIN_prior_20_days\n",
    "close_MIN_prior_260_days\n",
    "close_MAX_prior_5_days\n",
    "close_MAX_prior_20_days\n",
    "close_MAX_prior_260_days\n",
    "close_AVG_prior_5_days\n",
    "close_AVG_prior_20_days\n",
    "close_AVG_prior_260_days\n",
    "close_STDDEV_prior_5_days\n",
    "close_STDDEV_prior_20_days\n",
    "close_STDDEV_prior_260_days\n",
    "```\n",
    "These are the same columns we have used in our BQML model. This will help us compare the performance between BQML models and AutoML models.\n",
    "<img src='../assets/select_training_columns.png' width='80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Compute and pricing, set the **Budget** as 1. We get a decent performance for our model using just one node hour of training. Having **Enable early stopping** selected ensures that the model training will stop if there is no improvement. Now, you can select **START TRAINING**. Your model should start training.\n",
    "\n",
    "<img src='../assets/select_node_hours.png' width='80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Evaluate your model.\n",
    "\n",
    "Training can take many hours. But once training is complete you can inspect the evaluation metrics of your model. Since this is a classification task, we can also adjust the threshold and explore how different thresholds will affect your evaluation metrics. Also on that page, we can explore the feature importance of the various features used in the model and view confusion matrix for our model predictions.\n",
    "\n",
    "<img src='../assets/analyze_eval_metrics.png' width='80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 5. Predict with the trained model. \n",
    "\n",
    "Once the model is done training, navigate to the `Deploy and test` tab and Deploy the model to an endpoint, so we can test prediction. \n",
    "\n",
    "<img src='../assets/deploy_model_endpoint.png' width='80%'>\n",
    "\n",
    "When calling predictions, you can call batch prediction jobs by specifying a BigQuery table or csv file. Or you can do online prediction for a single instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "asl_kernel",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "ASL Kernel (Local)",
   "language": "python",
   "name": "asl_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
