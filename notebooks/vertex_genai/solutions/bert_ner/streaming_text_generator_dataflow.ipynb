{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8a4i3PAFVQd",
    "tags": []
   },
   "source": [
    "# Stream generator Dataflow -> PubSub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "%pip install --quiet faker"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import logging\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import apache_beam as beam\n",
    "from apache_beam import Create, FlatMap, Map, ParDo, Filter, Flatten, Partition, MapTuple, FlatMapTuple\n",
    "from apache_beam import Keys, Values\n",
    "from apache_beam.transforms.util import WithKeys\n",
    "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from apache_beam.ml.inference.base import RunInference\n",
    "from apache_beam.ml.inference.gemini_inference import GeminiModelHandler, generate_from_string\n",
    "from collections.abc import Callable\n",
    "from collections.abc import Iterable\n",
    "from collections.abc import Sequence\n",
    "from typing import Any\n",
    "from typing import Optional\n",
    "from google import genai\n",
    "from google.genai import errors\n",
    "from apache_beam.ml.inference import utils\n",
    "from apache_beam.ml.inference.base import PredictionResult\n",
    "from apache_beam.ml.inference.base import RemoteModelHandler\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.options.pipeline_options import DebugOptions\n",
    "from apache_beam.runners import DataflowRunner"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "PROJECT_ID = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "REGION = \"us-central1\"\n",
    "%env GOOGLE_CLOUD_PROJECT={PROJECT_ID}\n",
    "BUCKET_NAME=f'dataflow_demo_{PROJECT_ID}'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATAFLOW_BUCKET=f\"bert-ner-demo-io-storage-{PROJECT_ID}\" \n",
    "OUTPUT_GCS_BUCKET = f\"gs://{DATAFLOW_BUCKET}/output/\"\n",
    "TEMP_LOCATION=f\"gs://{DATAFLOW_BUCKET}/temp/\"\n",
    "STAGING_LOCATION=f\"gs://{DATAFLOW_BUCKET}/staging/\"\n",
    "OUTPUT_TOPIC=f\"projects/{PROJECT_ID}/topics/input_messages\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "!gsutil mb -l {REGION} gs://{DATAFLOW_BUCKET}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writefile ./requirements.txt\n",
    "faker"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "import uuid\n",
    "import time\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.transforms.periodicsequence import PeriodicImpulse\n",
    "from apache_beam.utils.timestamp import Timestamp\n",
    "from apache_beam.io import WriteToPubSub\n",
    "from apache_beam import Create\n",
    "\n",
    "# Define the templates provided\n",
    "TEMPLATES = [\n",
    "    \"The meeting will be hosted by {NAME} at {ADDRESS} .\",\n",
    "    \"Please contact {NAME} at {EMAIL} for more details.\",\n",
    "    \"My office is located at {ADDRESS} .\",\n",
    "    \"You can reach us at {PHONE_NUMBER} or send a mail to {EMAIL} .\",\n",
    "    \"{NAME} changed their phone number to {PHONE_NUMBER} yesterday.\",\n",
    "    \"Ship the package to {ADDRESS} immediately.\",\n",
    "    \"Is {EMAIL} the correct address for {NAME} ?\",\n",
    "    \"Write down this address: {ADDRESS} .\",\n",
    "    \"Call {PHONE_NUMBER} and ask for {NAME} .\",\n",
    "]\n",
    "\n",
    "class GenerateRandomMessage(beam.DoFn):\n",
    "    \"\"\"\n",
    "    A DoFn that ignores the input element, generates random data\n",
    "    fills a template, and outputs a JSON byte string.\n",
    "    \"\"\"\n",
    "    def setup(self):\n",
    "        # Import here to ensure pickling works on Dataflow workers\n",
    "        from faker import Faker\n",
    "        self.fake = Faker()\n",
    "\n",
    "    def process(self, element):\n",
    "        # 1. Pick a random template\n",
    "        template = random.choice(TEMPLATES)\n",
    "\n",
    "        # 2. Generate data for all potential placeholders\n",
    "        # formatting address to remove newlines for cleaner sentences\n",
    "        clean_address = self.fake.address().replace('\\n', ', ')\n",
    "        \n",
    "        replacements = {\n",
    "            \"NAME\": self.fake.name(),\n",
    "            \"ADDRESS\": clean_address,\n",
    "            \"EMAIL\": self.fake.email(),\n",
    "            \"PHONE_NUMBER\": self.fake.phone_number()\n",
    "        }\n",
    "\n",
    "        # 3. Format the string\n",
    "        # Using **replacements unpacks the dict to match {KEYS} in the template\n",
    "        message_text = template.format(**replacements)\n",
    "\n",
    "        # 4. Construct the payload\n",
    "        payload = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"message\": message_text\n",
    "        }\n",
    "\n",
    "        # 5. Log for local debugging (optional)\n",
    "        logging.info(f\"Generated: {payload}\")\n",
    "\n",
    "        # 6. Return as bytes (Required for Pub/Sub)\n",
    "        yield json.dumps(payload).encode(\"utf-8\")\n",
    "\n",
    "#pipeline_options = PipelineOptions(pipeline_args, streaming=True)\n",
    "p = beam.Pipeline(InteractiveRunner())\n",
    "messages = (\n",
    "    p\n",
    "    #Generate a continuous stream of numbers.\n",
    "    | \"GenerateTicks\" >> PeriodicImpulse(\n",
    "            start_timestamp=Timestamp.now(), \n",
    "            stop_timestamp=Timestamp.of(2147483647), # Run practically forever\n",
    "            fire_interval=0.5, \n",
    "            apply_windowing=True\n",
    "        ) \n",
    "    # Map the ticks to our random message generator\n",
    "    | \"CreateMessage\" >> beam.ParDo(GenerateRandomMessage())\n",
    "    # Write the result to Pub/Sub\n",
    "    | \"WritePubSub\" >> WriteToPubSub(topic=OUTPUT_TOPIC)\n",
    ")\n",
    "\n",
    "# Uncomment if you want to use Interactive Runner:\n",
    "# ib.show(messages)\n",
    "\n",
    "requirements_file=\"./requirements.txt\"\n",
    "\n",
    "#Uncomment if you want to use Dataflow Runner:\n",
    "options = pipeline_options.PipelineOptions(\n",
    "    flags={},\n",
    "    project=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    staging_location=STAGING_LOCATION,\n",
    "    temp_location=TEMP_LOCATION,\n",
    "    machine_type='n1-standard-4',\n",
    "    max_num_workers=1,\n",
    "    requirements_file=requirements_file,\n",
    "    disk_size_gb=50)\n",
    "\n",
    "pipeline_result = DataflowRunner().run_pipeline(p, options=options)\n",
    "pipeline_result.wait_until_finish()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Apache Beam 2.69.0 (Local)",
   "language": "python",
   "name": "apache-beam-2.69.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
