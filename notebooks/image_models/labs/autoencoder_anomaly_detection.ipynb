{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder for Anomaly Detection\n",
    "## Learning Objectives\n",
    "1. Learn how to build a Deep Convolutional Autoencoder\n",
    "2. Learn how to use a trained autoencoder for anomaly detection\n",
    "\n",
    "In this lab, you will learn how to build an autoencoder model. Autoencoder is a popular unsupervised model which consists of an encoder and a decoder.<br>\n",
    "An autoencoder is a special type of neural network trained to copy its input to its output. For example, given an image of a handwritten digit, an autoencoder first encodes the image into a lower dimensional latent representation, then decodes the latent representation back to an image. An autoencoder learns to compress the data while minimizing the reconstruction error.\n",
    "\n",
    "Autoencoders can be used in many ways. In this lab, we will use an autoencoder for anomaly detection, leveraging that an autoencoder will have a harder time reconstructing an anomalous input compared to an input taken from the data distribution it has been trained on.\"\n",
    "\n",
    "To learn more about autoencoders, please consider reading chapter 14 from [Deep Learning](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Data\n",
    "\n",
    "We are going to use the MNIST dataset, which consists of black and white images of handwritten digits. Each image has 28 x 28 pixels and a single channel indicating the level of gray between black and white, yielding a tensor representation with shape(28, 28, 1). Keras comes preloaded with this dataset, which we load in the next cell:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist_digits[0], cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Autoencoder model\n",
    "Let's start building an autoencoder model. \n",
    "\n",
    "Autoencoder is a self-supervised model, which uses the same data for input and label. \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/6895245/164359926-f72472ca-f2de-4098-bf2b-3e649749f721.png)\n",
    "It tries to reduce the dimensionality of inputs to a fixed-sized latent space (encoder) and 'reconstruct' the input from the embedding (decoder). So we can regard the encoder part as a dimensionality reduction model like PCA. But whereas PCA learns a linear transformation that projects input into lower-dimensional space, autoencoders learn non-linear transformation using Neural Networks.\n",
    "\n",
    "### Encoder\n",
    "Let's build the encoder part at first. Encoder goes from the inputs to the latent space.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/6895245/164373070-f7860451-1720-4e4b-aa91-460c4aa98020.png)\n",
    "\n",
    "**Exercise**: Implement `buil_encoder` function so that it builds and returns a `Sequential` of an encoder with two [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D?version=nightly) layers, [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) layer and a [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer. <br> \n",
    "**Hint**: You can use the arguments of the function for Conv2D layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(\n",
    "    input_shape,\n",
    "    latent_dim,\n",
    "    filters_1=32,\n",
    "    filters_2=64,\n",
    "    kernel_size_1=3,\n",
    "    kernel_size_2=3,\n",
    "    strides_1=2,\n",
    "    strides_2=2,\n",
    "):\n",
    "    encoder = tf.keras.Sequential([])  # TODO\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 2  # for easy visualization\n",
    "INPUT_SHAPE = (28, 28, 1)  # Size of input data\n",
    "\n",
    "encoder = build_encoder(INPUT_SHAPE, LATENT_DIM)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "The decoder goes from the latent space back to the reconstructed image.\n",
    "In order to reconstruct the original shape (28,28,1), we use [`Conv3DTranspose` layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) (a.k.a Deconvolution).\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/6895245/164372979-29797db4-d108-4955-8056-ec668465c3f4.png)\n",
    "\n",
    "**Exercise**: Complete the `build_decoder` function below so that that it returns a `Sequential` with layer architecture to be the exact reverse of the of the encoder layers. <br>\n",
    "**Hint**: You can get the decoder layer information from the encoder object: e.g. `encoder.layers[-1].input.shape[1]` will return the input shape of the encoder last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_decoder(latent_dim, encoder):\n",
    "    decoder = tf.keras.Sequential([])  # TODO\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_decoder(LATENT_DIM, encoder)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct entire autoencoder\n",
    "\n",
    "The autoencoder consists of the encoder and the decoder blocks. Let's simply stack these two and build the entire autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_shape, latent_dim):\n",
    "    encoder = build_encoder(input_shape, latent_dim)\n",
    "    decoder = build_decoder(latent_dim, encoder)\n",
    "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "    autoencoder.build(input_shape=(None, *input_shape))\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder = build_autoencoder(INPUT_SHAPE, LATENT_DIM)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization goal of the autoencoder is to minimize the reconstruction error between input and output. So let's chose MSE as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.Adam(), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train autoencoder\n",
    "Let's run the training by calling `.fit()`.\n",
    "Here, please notice that both feature and label have the same shape, i.e., (28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(mnist_digits, mnist_digits, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks the reconstruction loss is decreasing gradually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained an autoencoder model with `LATENT_DIM=2`. Let's visualize the 2 dimensional latent space (output of encoder), and see how it found the pattern from input data.\n",
    "\n",
    "The function bellow will plot the input images in the latent space by passing them to the encoder. It will also add the indication of the actual image labels (which were not used during the autoencoder training). We observe that the autoencoder was able to group images with the same label into relatively well defined cluster of points in the latent space. In a way, the autoencoder has \"guessed\" the image labels from the raw images without having the knowledge of the labels during training!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(encoder, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean = encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    for label in range(10):  # mnist, 10 digits\n",
    "        cx = np.mean(z_mean[labels == label, 0])\n",
    "        cy = np.mean(z_mean[labels == label, 1])\n",
    "        plt.text(\n",
    "            cx, cy, str(label), color=\"white\", fontsize=25, fontweight=\"bold\"\n",
    "        )\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "plot_label_clusters(encoder, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see clusters of digits! That means our encoder part found some patern and embedded information in this 2 dimensional latent space.\n",
    "\n",
    "## Visualize decoder\n",
    "Now let's take a look at the decoder part as well.\n",
    "The helper function below creates grid pairs of two dimensional latent space  (`grid_x` and `grid_y`) in a specified range, then passes them to the decoder and plots the decoder model's output.<br>\n",
    "It helps us understand how the decoder generate output images from latent spaces.\n",
    "\n",
    "You can change the `ranges` argument in `[x_min, x_max, y_min, y_max]` format based on the actual range of the clusters in a latent space of the encoder output that is shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(decoder, n=30, ranges=[-1, 1, -1, 1], figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(ranges[0], ranges[1], n)\n",
    "    grid_y = np.linspace(ranges[2], ranges[3], n)[::-1]\n",
    "\n",
    "    samples = [[x, y] for y in grid_y for x in grid_x]\n",
    "    x_decoded = decoder.predict(samples)\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = x_decoded[i * n + j].reshape(digit_size, digit_size)\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_space(decoder, n=30, ranges=[-10, 10, -3, 10], figsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good! Our autoencoder model successfully reconstructs the images from two-dimensional latent space.\n",
    "\n",
    "Next, let's take a look at how we can use autoencoder to solve the Anomaly Detection problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "Now that we demonstrated how autoencoder works, let's utilize this model for anomaly detection.\n",
    "\n",
    "But why does this work for anomaly detection?\n",
    "\n",
    "Autoencoder learns the pattern of data by compressing the information and reconstructing it. So if it is successfully trained with 'normal' data, it should be able to rebuild a similar image to 'normal' inputs as we've seen. But if the input was 'anomaly,' it won't reconstruct a similar image since the pattern of anomaly data is very different from normal data.\n",
    "\n",
    "So in the anomaly case, the error between input and output should be larger than the normal case. We can utilize this characteristic of autoencoder for anomaly detection problems.\n",
    "\n",
    "### Build AutoEncoder for Anomaly Detection\n",
    "\n",
    "Before actually using an autoencoder for anomaly detection, let's create a more performant model by specifying a larger latent dimension.\n",
    "\n",
    "A larger latent dimension means the model can embed richer information in a larger space (like 32).\n",
    "\n",
    "**Exercise**: In the cell below, use build_autoencoder to instantiate an auto-encoder model. Then write the code to compile and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder = None  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile()  # TODO\n",
    "history = autoencoder.fit()  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Anomalies\n",
    "\n",
    "In the next cell, we will detect anomalies by computing the reconstruction error of a given input, and checking if it crosses a threshold, that we establish by computing the mean and the standard deviation of the reconstruction error on the dataset according to the following formula:\n",
    "\n",
    "`threshold = mean(reconstruction_error) + std(reconstruction_error) + sigma`\n",
    "\n",
    "where sigma is an hyper-parameter that we need to set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 2000  # Number of samples to caliculate threshold\n",
    "\n",
    "reconstructions = autoencoder.predict(x_train[:num_sample])\n",
    "\n",
    "train_loss = tf.reduce_mean(\n",
    "    tf.keras.losses.mae(reconstructions, x_train[:num_sample]), axis=(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize histgram of loss value\n",
    "plt.hist(train_loss[None, :], bins=50)\n",
    "plt.xlabel(\"Train loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a threshold value that is two standard deviations above the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Anomaly Threshold\n",
    "sigma = 2\n",
    "\n",
    "threshold = 0  # TODO: Define a threshold properly\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize histgram of loss value and anomaly threshold\n",
    "fig = plt.figure()\n",
    "plt.hist(train_loss[None, :], bins=50)\n",
    "plt.xlabel(\"Train loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.vlines(threshold, 0, 160, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "At prediction time we\n",
    "\n",
    "1. reconstruct the input using the autoencoder\n",
    "1. compute the reconstruction error for that input\n",
    "1. classify the input as an anomaly if the reconstruction error is above the threshold we have fixed\n",
    "\n",
    "**Exercise**: In the cell below, define the logic of anomaly detection using threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection function\n",
    "def predict(model, data, threshold):\n",
    "    reconstructions = model(data)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.keras.losses.mae(reconstructions, data), axis=(1, 2)\n",
    "    )\n",
    "    return None  # TODO: Define the logic of anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function below visualizes input, reconstructed output, and the result of anomaly detection with a comparison of the actual loss value and the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting Utility Function\n",
    "def plot_reconstruction(model, data, threshold):\n",
    "    is_anomaly, loss, reconstruction = predict(\n",
    "        model, tf.expand_dims(data, 0), threshold\n",
    "    )\n",
    "\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    lossMSG = f\"loss:{loss:.4f}\"\n",
    "    thMSG = f\"threshold:{threshold:.4f}\"\n",
    "    text_anomaly = (\n",
    "        f\"Anomaly ({lossMSG} > {thMSG})\"\n",
    "        if is_anomaly\n",
    "        else f\"Normal ({lossMSG} <= {thMSG})\"\n",
    "    )\n",
    "    title = f.suptitle(text_anomaly)\n",
    "    c = \"r\" if is_anomaly else \"g\"\n",
    "    plt.setp(title, color=c)\n",
    "\n",
    "    axarr[0].imshow(data, cmap=\"Greys_r\")\n",
    "    axarr[0].set_title(\"Original Image\")\n",
    "    axarr[1].imshow(reconstruction[0], cmap=\"Greys_r\")\n",
    "    axarr[1].set_title(\"Reconstructed Image\")\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal dataset\n",
    "Let's pass some normal data from the dataset and see how our autoencoder model responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in x_train[num_sample - 10 : num_sample]:\n",
    "    plot_reconstruction(autoencoder, d, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks Like our autoencoder is reconstructing images very well, and the loss value is less than the threshold in most cases.<br>\n",
    "This is what we expected!\n",
    "\n",
    "### Try Anomaly Data\n",
    "Then what happens when it gets 'unusual' data? Let's create some perturbations below and see what happens. We try:\n",
    "- 90-degree rotated images\n",
    "- negatively inversed images\n",
    "- images with white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 90-degree rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in x_train[num_sample - 10 : num_sample]:\n",
    "    plot_reconstruction(autoencoder, np.rot90(d), threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks a lot of rotated images are detected as anomalies since rotated images are not contained in training and threshold calculation.\n",
    "\n",
    "But since the `0` value is invariable to angles, rotated `0` can be detected as normal.\n",
    "\n",
    "Next, let's look at what happens if we create negatives from the original images and provide them to our model.\n",
    "\n",
    "#### negatively inversed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in x_train[num_sample - 10 : num_sample]:\n",
    "    plot_reconstruction(autoencoder, 1 - d, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are detected as anomalies with considerable loss value! And we can see our model cannot construct the original image at all.\n",
    "\n",
    "Then how about the noisy data?\n",
    "\n",
    "#### images with white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise_and_scale(d):\n",
    "    noise = np.random.normal(0, 0.05, size=(28, 28, 1))\n",
    "    _d = d + noise\n",
    "    return _d - np.min(_d) / (np.max(_d) - np.min(_d))\n",
    "\n",
    "\n",
    "for d in x_train[num_sample - 10 : num_sample]:\n",
    "    plot_reconstruction(autoencoder, add_noise_and_scale(d), threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are also detected as anomalies!\n",
    "\n",
    "Interestingly, since our autoencoder was trained with clean images, it tries to 'denoise' and generates clean images as outputs. As a result, the error between the inputs and clean outputs becomes large, and they are detected as anomalies.\n",
    "\n",
    "Is that mean we can also utilize autoencoders for denoising purposes? Yes, we can do it with [denoising autoencoders](https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf).<br>\n",
    "But then don't forget to use clean images for training data to make autoencoders capture the pattern of clean data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We learned how to build an autoencoder model by stacking an encoder and a decoder in this lab.<br>\n",
    "Also, we learned how to utilize an autoencoder for anomaly detection purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "Copyright 2022 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
