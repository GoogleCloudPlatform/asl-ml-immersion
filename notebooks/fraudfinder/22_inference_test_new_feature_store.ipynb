{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ur8xi4C7S06n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Fraudfinder - Inference Demo (New Feature Store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Fraudfinder](https://github.com/googlecloudplatform/fraudfinder) is a series of labs on how to build a real-time fraud detection system on Google Cloud. Throughout the Fraudfinder labs, you will learn how to read historical bank transaction data stored in data warehouse, read from a live stream of new transactions, perform exploratory data analysis (EDA), do feature engineering, ingest features into a feature store, train a model using feature store, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do real-time inference on your model with feature store, and monitor your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "This notebook shows how to use Feature Store and Model Endpoint for Realtime Inference\n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "* Invoke a Vetex AI Feature Store and Vetex AI Endpoint to test Realtime predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration settings from the setup notebook\n",
    "\n",
    "Set the constants used in this notebook and load the config settings from the `00_environment_setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BUCKET_NAME          = \"qwiklabs-asl-02-111b5e486eb8-fraudfinder\"\n",
      "PROJECT              = \"qwiklabs-asl-02-111b5e486eb8\"\n",
      "REGION               = \"us-central1\"\n",
      "ID                   = \"9m3ic\"\n",
      "FEATURESTORE_ID      = \"fraudfinder_9m3ic\"\n",
      "MODEL_NAME           = \"ff_model\"\n",
      "ENDPOINT_NAME        = \"ff_model_endpoint\"\n",
      "TRAINING_DS_SIZE     = \"1000\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "config = !gsutil cat gs://{BUCKET_NAME}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf",
    "tags": []
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries\n",
    "Next you will import the libraries needed for this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Vertex AI SDK\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "REGION=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "#from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.aiplatform_v1 import (FeatureOnlineStoreAdminServiceClient,\n",
    "                                        FeatureOnlineStoreServiceClient,\n",
    "                                        FeatureRegistryServiceClient)\n",
    "from google.cloud.aiplatform_v1.types import feature as feature_pb2\n",
    "from google.cloud.aiplatform_v1.types import feature_group as feature_group_pb2\n",
    "from google.cloud.aiplatform_v1.types import \\\n",
    "    feature_online_store as feature_online_store_pb2\n",
    "from google.cloud.aiplatform_v1.types import \\\n",
    "    feature_online_store_admin_service as \\\n",
    "    feature_online_store_admin_service_pb2\n",
    "from google.cloud.aiplatform_v1.types import \\\n",
    "    feature_online_store_service as feature_online_store_service_pb2\n",
    "from google.cloud.aiplatform_v1.types import \\\n",
    "    feature_registry_service as feature_registry_service_pb2\n",
    "from google.cloud.aiplatform_v1.types import feature_view as feature_view_pb2\n",
    "from google.cloud.aiplatform_v1.types import \\\n",
    "    featurestore_service as featurestore_service_pb2\n",
    "from google.cloud.aiplatform_v1.types import io as io_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex AI SDK\n",
    "vertex_ai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_from_sub(project_id, subscription_name, messages=10):\n",
    "    \"\"\"\n",
    "    Read messages from a Pub/Sub subscription\n",
    "    Args:\n",
    "        project_id: project ID\n",
    "        subscription_name: the name of a Pub/Sub subscription in your project\n",
    "        messages: number of messages to read\n",
    "    Returns:\n",
    "        msg_data: list of messages in your Pub/Sub subscription as a Python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    import ast\n",
    "\n",
    "    from google.api_core import retry\n",
    "    from google.cloud import pubsub_v1\n",
    "\n",
    "    subscriber = pubsub_v1.SubscriberClient()\n",
    "    subscription_path = subscriber.subscription_path(project_id, subscription_name)\n",
    "\n",
    "    # Wrap the subscriber in a 'with' block to automatically call close() to\n",
    "    # close the underlying gRPC channel when done.\n",
    "    with subscriber:\n",
    "        # The subscriber pulls a specific number of messages. The actual\n",
    "        # number of messages pulled may be smaller than max_messages.\n",
    "        response = subscriber.pull(\n",
    "            subscription=subscription_path,\n",
    "            max_messages=messages,\n",
    "            retry=retry.Retry(deadline=300),\n",
    "        )\n",
    "\n",
    "        if len(response.received_messages) == 0:\n",
    "            print(\"no messages\")\n",
    "            return\n",
    "\n",
    "        ack_ids = []\n",
    "        msg_data = []\n",
    "        for received_message in response.received_messages:\n",
    "            msg = ast.literal_eval(received_message.message.data.decode(\"utf-8\"))\n",
    "            msg_data.append(msg)\n",
    "            ack_ids.append(received_message.ack_id)\n",
    "\n",
    "        # Acknowledges the received messages so they will not be sent again.\n",
    "        subscriber.acknowledge(subscription=subscription_path, ack_ids=ack_ids)\n",
    "\n",
    "        print(\n",
    "            f\"Received and acknowledged {len(response.received_messages)} messages from {subscription_path}.\"\n",
    "        )\n",
    "\n",
    "        return msg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID=\"4917679004925820928\"\n",
    "NEW_FEATURE_STORE_ID=\"the_look_demo_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4917679004925820928\n"
     ]
    }
   ],
   "source": [
    "print(ENDPOINT_ID)\n",
    "from google.cloud import aiplatform as aiplatform\n",
    "# Instantiate Vertex AI Endpoint object\n",
    "endpoint_obj = aiplatform.Endpoint(ENDPOINT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received and acknowledged 1 messages from projects/qwiklabs-asl-02-111b5e486eb8/subscriptions/ff-tx-sub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TX_ID': '30997f4d1e1a434c8ca086fd240a3a32b2f52e4e',\n",
       "  'TX_TS': '2025-09-15 12:44:17',\n",
       "  'CUSTOMER_ID': '2525341863476968',\n",
       "  'TERMINAL_ID': '39692472',\n",
       "  'TX_AMOUNT': 65.47}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_tx = read_from_sub(\n",
    "    project_id=PROJECT_ID, subscription_name=\"ff-tx-sub\", messages=1\n",
    ")\n",
    "\n",
    "messages_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "\n",
    "# Instantiate Vertex AI Feature Store object\n",
    "\n",
    "data_client = FeatureOnlineStoreServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(compact=True)\n",
    "\n",
    "def fs_features_lookup(ff_feature_store, features_type, features_key):\n",
    "\n",
    "    FEATURE_VIEW_ID = f\"fv_{features_type}_continuous\"\n",
    "    FEATURE_VIEW_FULL_ID=f\"projects/{PROJECT_ID}/locations/{REGION}/featureOnlineStores/{ff_feature_store}/featureViews/{FEATURE_VIEW_ID}\"\n",
    "    \n",
    "    features_map = {}\n",
    "    \n",
    "    print(FEATURE_VIEW_FULL_ID)\n",
    "    \n",
    "    try:\n",
    "        fe_continuous_data = data_client.fetch_feature_values(\n",
    "            request=feature_online_store_service_pb2.FetchFeatureValuesRequest(\n",
    "                feature_view=FEATURE_VIEW_FULL_ID,\n",
    "                data_key=feature_online_store_service_pb2.FeatureViewDataKey(key=features_key),\n",
    "                data_format=feature_online_store_service_pb2.FeatureViewDataFormat.PROTO_STRUCT,\n",
    "            )\n",
    "        )\n",
    "        features_map.update({k: v for k, v in fe_continuous_data.proto_struct.items()})\n",
    "    except Exception as exp:\n",
    "        print(f\"Requested entity {features_key} was not found\")\n",
    "\n",
    "    FEATURE_VIEW_ID = f\"fv_{features_type}_batch\"\n",
    "    FEATURE_VIEW_TERMINAL_FULL_ID=f\"projects/{PROJECT_ID}/locations/{REGION}/featureOnlineStores/{ff_feature_store}/featureViews/{FEATURE_VIEW_ID}\"\n",
    "    \n",
    "    try:\n",
    "        fe_batch_data = data_client.fetch_feature_values(\n",
    "            request=feature_online_store_service_pb2.FetchFeatureValuesRequest(\n",
    "                feature_view=FEATURE_VIEW_TERMINAL_FULL_ID,\n",
    "                data_key=feature_online_store_service_pb2.FeatureViewDataKey(key=features_key),\n",
    "                data_format=feature_online_store_service_pb2.FeatureViewDataFormat.PROTO_STRUCT,\n",
    "            )\n",
    "        )\n",
    "        features_map.update({k: v for k, v in fe_batch_data.proto_struct.items()})\n",
    "    except Exception as exp:\n",
    "        print(f\"Requested entity {features_key} was not found\")\n",
    "    return features_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/qwiklabs-asl-02-111b5e486eb8/locations/us-central1/featureOnlineStores/the_look_demo_unique/featureViews/fv_terminal_continuous\n",
      "projects/qwiklabs-asl-02-111b5e486eb8/locations/us-central1/featureOnlineStores/the_look_demo_unique/featureViews/fv_customer_continuous\n",
      "{'feature_timestamp': 1758538801583581.0,\n",
      " 'terminal_id_avg_amount_15min_window': 20.25,\n",
      " 'terminal_id_avg_amount_30min_window': 20.25,\n",
      " 'terminal_id_avg_amount_60min_window': 20.25,\n",
      " 'terminal_id_nb_tx_14day_window': 258.0,\n",
      " 'terminal_id_nb_tx_15min_window': 1.0,\n",
      " 'terminal_id_nb_tx_1day_window': 23.0,\n",
      " 'terminal_id_nb_tx_30min_window': 1.0,\n",
      " 'terminal_id_nb_tx_7day_window': 190.0,\n",
      " 'terminal_id_risk_14day_window': 0.03875967489935082,\n",
      " 'terminal_id_risk_1day_window': 0.043478071834470285,\n",
      " 'terminal_id_risk_7day_window': 0.03157893074793119}\n",
      "{'customer_id_avg_amount_14day_window': 94.1525,\n",
      " 'customer_id_avg_amount_15min_window': 86.36,\n",
      " 'customer_id_avg_amount_1day_window': 106.51,\n",
      " 'customer_id_avg_amount_30min_window': 86.36,\n",
      " 'customer_id_avg_amount_60min_window': 86.36,\n",
      " 'customer_id_avg_amount_7day_window': 91.576,\n",
      " 'customer_id_nb_tx_14day_window': 24.0,\n",
      " 'customer_id_nb_tx_15min_window': 1.0,\n",
      " 'customer_id_nb_tx_1day_window': 1.0,\n",
      " 'customer_id_nb_tx_30min_window': 1.0,\n",
      " 'feature_timestamp': 1758538801478487.0}\n"
     ]
    }
   ],
   "source": [
    "terminal_features = fs_features_lookup(NEW_FEATURE_STORE_ID, \"terminal\", '66252258') # Change key values\n",
    "customer_features = fs_features_lookup(NEW_FEATURE_STORE_ID, \"customer\", '6603179080122591')\n",
    "pp.pprint(terminal_features)\n",
    "pp.pprint(customer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/qwiklabs-asl-02-111b5e486eb8/locations/us-central1/featureOnlineStores/the_look_demo_unique/featureViews/fv_customer_continuous\n",
      "Requested entity 2525341863476968 was not found\n",
      "-------------------------------------------------------\n",
      "customer_features:\n",
      "{'customer_id_avg_amount_14day_window': 72.307959184,\n",
      " 'customer_id_avg_amount_1day_window': 74.143333333,\n",
      " 'customer_id_avg_amount_7day_window': 73.550833333,\n",
      " 'customer_id_nb_tx_14day_window': 49.0,\n",
      " 'customer_id_nb_tx_1day_window': 3.0,\n",
      " 'feature_timestamp': 1758538801478487.0}\n",
      "projects/qwiklabs-asl-02-111b5e486eb8/locations/us-central1/featureOnlineStores/the_look_demo_unique/featureViews/fv_terminal_continuous\n",
      "-------------------------------------------------------\n",
      "terminal features:\n",
      "{'feature_timestamp': 1758538801583581.0,\n",
      " 'terminal_id_avg_amount_15min_window': 79.41,\n",
      " 'terminal_id_avg_amount_30min_window': 79.41,\n",
      " 'terminal_id_avg_amount_60min_window': 87.25999999999999,\n",
      " 'terminal_id_nb_tx_14day_window': 172.0,\n",
      " 'terminal_id_nb_tx_15min_window': 1.0,\n",
      " 'terminal_id_nb_tx_1day_window': 26.0,\n",
      " 'terminal_id_nb_tx_30min_window': 1.0,\n",
      " 'terminal_id_nb_tx_7day_window': 136.0,\n",
      " 'terminal_id_risk_14day_window': 0.023255800432674167,\n",
      " 'terminal_id_risk_1day_window': 0.0,\n",
      " 'terminal_id_risk_7day_window': 0.022058807309700508}\n",
      "-------------------------------------------------------\n",
      "[Payload to be sent to Vertex AI endpoint]\n",
      "{'customer_id_avg_amount_14day_window': 72.307959184,\n",
      " 'customer_id_avg_amount_15min_window': 0,\n",
      " 'customer_id_avg_amount_1day_window': 74.143333333,\n",
      " 'customer_id_avg_amount_30min_window': 0,\n",
      " 'customer_id_avg_amount_60min_window': 0,\n",
      " 'customer_id_avg_amount_7day_window': 73.550833333,\n",
      " 'customer_id_nb_tx_14day_window': 49.0,\n",
      " 'customer_id_nb_tx_15min_window': 0,\n",
      " 'customer_id_nb_tx_1day_window': 3.0,\n",
      " 'customer_id_nb_tx_30min_window': 0,\n",
      " 'customer_id_nb_tx_60min_window': 0,\n",
      " 'customer_id_nb_tx_7day_window': 0,\n",
      " 'terminal_id_avg_amount_15min_window': 79.41,\n",
      " 'terminal_id_avg_amount_30min_window': 79.41,\n",
      " 'terminal_id_avg_amount_60min_window': 87.25999999999999,\n",
      " 'terminal_id_nb_tx_14day_window': 172.0,\n",
      " 'terminal_id_nb_tx_15min_window': 1.0,\n",
      " 'terminal_id_nb_tx_1day_window': 26.0,\n",
      " 'terminal_id_nb_tx_30min_window': 1.0,\n",
      " 'terminal_id_nb_tx_60min_window': 0,\n",
      " 'terminal_id_nb_tx_7day_window': 136.0,\n",
      " 'terminal_id_risk_14day_window': 0.023255800432674167,\n",
      " 'terminal_id_risk_1day_window': 0.0,\n",
      " 'terminal_id_risk_7day_window': 0.022058807309700508,\n",
      " 'tx_amount': 65.47}\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "(\"[Prediction result]: Prediction(predictions=[{'classes': ['0', '1'], \"\n",
      " \"'scores': [0.953736424446106, 0.04626360535621643]}], \"\n",
      " \"deployed_model_id='7562290342750322688', metadata=None, \"\n",
      " \"model_version_id='1', \"\n",
      " \"model_resource_name='projects/25570882233/locations/us-central1/models/7419586927604531200', \"\n",
      " 'explanations=None)')\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(compact=True)\n",
    "\n",
    "# Payload for manual test:\n",
    "# payload_json = {\n",
    "#     \"TX_ID\": \"61210be0744c43232990152d3eb2c2deb6035d8b\",\n",
    "#     \"TX_TS\": \"2025-09-06 17:27:51\",\n",
    "#     \"CUSTOMER_ID\": \"7389471951168361\",\n",
    "#     \"TERMINAL_ID\": \"45087784\",\n",
    "#     \"TX_AMOUNT\": 32.77\n",
    "# }\n",
    "\n",
    "default_features = {\n",
    "    'customer_id_avg_amount_14day_window': 0,\n",
    "    'customer_id_avg_amount_15min_window': 0,\n",
    "    'customer_id_avg_amount_1day_window': 0,\n",
    "    'customer_id_avg_amount_30min_window': 0,\n",
    "    'customer_id_avg_amount_60min_window': 0,\n",
    "    'customer_id_avg_amount_7day_window': 0,\n",
    "    'customer_id_nb_tx_14day_window': 0,\n",
    "    'customer_id_nb_tx_7day_window': 0,\n",
    "    'customer_id_nb_tx_15min_window': 0,\n",
    "    'customer_id_nb_tx_1day_window': 0,\n",
    "    'customer_id_nb_tx_30min_window': 0,\n",
    "    'customer_id_nb_tx_60min_window': 0,\n",
    "    'terminal_id_avg_amount_15min_window': 0,\n",
    "    'terminal_id_avg_amount_30min_window': 0,\n",
    "    'terminal_id_avg_amount_60min_window':0,\n",
    "    'terminal_id_nb_tx_14day_window': 0,\n",
    "    'terminal_id_nb_tx_15min_window': 0,\n",
    "    'terminal_id_nb_tx_1day_window': 0,\n",
    "    'terminal_id_nb_tx_30min_window': 0,\n",
    "    'terminal_id_nb_tx_60min_window': 0,\n",
    "    'terminal_id_nb_tx_7day_window': 0,\n",
    "    'terminal_id_risk_14day_window': 0,\n",
    "    'terminal_id_risk_1day_window': 0,\n",
    "    'terminal_id_risk_7day_window': 0\n",
    "}\n",
    "\n",
    "# Reading 1-st message\n",
    "payload_json = messages_tx[0]\n",
    "\n",
    "payload=default_features\n",
    "payload[\"tx_amount\"] = payload_json[\"TX_AMOUNT\"]\n",
    "\n",
    "# look up the customer features from New Vertex AI Feature Store\n",
    "customer_features = fs_features_lookup(NEW_FEATURE_STORE_ID, \"customer\", payload_json[\"CUSTOMER_ID\"])\n",
    "# print the customer features from Vertex AI Feature Store\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"customer_features:\")\n",
    "pp.pprint(customer_features)\n",
    "\n",
    "# look up the treminal features from New Vertex AI Feature Store\n",
    "terminal_features = fs_features_lookup(NEW_FEATURE_STORE_ID, \"terminal\",payload_json[\"TERMINAL_ID\"])\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"terminal features:\")\n",
    "pp.pprint(terminal_features)\n",
    "\n",
    "# Add customer features to payload\n",
    "payload.update(customer_features)\n",
    "\n",
    "# Add terminal features to payload\n",
    "payload.update(terminal_features)\n",
    "\n",
    "del payload['feature_timestamp']\n",
    "\n",
    "payload = preprocess(payload)\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"[Payload to be sent to Vertex AI endpoint]\")\n",
    "pp.pprint(payload)\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "result = endpoint_obj.predict(instances = [payload])\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "pp.pprint(f\"[Prediction result]: {result}\")\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
