{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Safeguarding with Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Large language models (LLMs) can translate language, summarize text, generate creative writing, generate code, power chatbots and virtual assistants, and complement search engines and recommendation systems. The incredible versatility of LLMs is also what makes it difficult to predict exactly what kinds of unintended or unforeseen outputs they might produce. \n",
    "\n",
    "Given these risks and complexities, the Gemini is designed with [Google's AI Principles](https://ai.google/responsibility/principles/) in mind. However, it is important for developers to understand and test their models to deploy safely and responsibly. To aid developers, Vertex AI Studio has built-in content filtering, safety ratings, and the ability to define safety filter thresholds that are right for their use cases and business.\n",
    "\n",
    "For more information, see the [Google Cloud Generative AI documentation on Responsible AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you learn how to inspect the safety ratings returned from Gemini using the Python SDK and how to set a safety threshold to filter responses from Gemini.\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Call Gemini via Gen AI SDK and inspect safety ratings of the responses\n",
    "- Define a threshold for filtering safety ratings according to your needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "### Define Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !gcloud config get-value project  # noqa: E999\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeH2sddasR1a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup GenerateContentConfig for Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.0-flash\"\n",
    "client = genai.Client(vertexai=True, location=\"us-central1\")\n",
    "\n",
    "# Set parameters to reduce variability in responses\n",
    "generation_config = GenerateContentConfig(\n",
    "    safety_settings=[\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "            threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "            threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "            threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "            threshold=HarmBlockThreshold.BLOCK_NONE,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlHF7Oqw0zBc"
   },
   "source": [
    "## Generate text and show safety ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7wSHFUtV48I"
   },
   "source": [
    "Start by generating a pleasant-sounding text response using Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "i-fAS7XV05Bp",
    "outputId": "e581098d-a910-4620-ac8d-49f5d07db430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call Gemini\n",
    "nice_prompt = \"Say three nice things about me\"\n",
    "responses = client.models.generate_content_stream(\n",
    "    model=MODEL, contents=nice_prompt, config=generation_config\n",
    ")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the safety ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EPQRdiG1BVv"
   },
   "source": [
    "Look at the `safety_ratings` of the streaming responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1z82p_bPSK5p",
    "outputId": "45afc240-7b97-4c32-a72c-baefce6b70d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "response.candidates[0].to_json_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the safety ratings: category and probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bd5SnfOSR0n"
   },
   "source": [
    "You can see the safety ratings, including each `category` type and its associated `probability` label.\n",
    "\n",
    "The `category` types include:\n",
    "\n",
    "* Hate speech: `HARM_CATEGORY_HATE_SPEECH`\n",
    "* Dangerous content: `HARM_CATEGORY_DANGEROUS_CONTENT`\n",
    "* Harassment: `HARM_CATEGORY_HARASSMENT`\n",
    "* Sexually explicit statements: `HARM_CATEGORY_SEXUALLY_EXPLICIT`\n",
    "\n",
    "The `probability` labels are:\n",
    "\n",
    "* `NEGLIGIBLE` - content has a negligible probability of being unsafe\n",
    "* `LOW` - content has a low probability of being unsafe\n",
    "* `MEDIUM` - content has a medium probability of being unsafe\n",
    "* `HIGH` - content has a high probability of being unsafe\n",
    "\n",
    "The `probability_score` means the probability score in [0,1] about each safety categoy.<br>\n",
    "Here you should be seeing very low values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a prompt that might trigger one of these categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcw5s7Jo1Axm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "impolite_prompt = \"Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark:\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL, contents=impolite_prompt, config=generation_config\n",
    ")\n",
    "\n",
    "response.candidates[0].to_json_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you may not be seeing higher probability category since Gemini it self does a great job handling potentially harmful prompt, you may observe the probability_score is higher than the previous prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrPLIhgZ4etq"
   },
   "source": [
    "### Defining thresholds for safety ratings\n",
    "\n",
    "You may want to adjust the default safety filter thresholds depending on your business policies or use case. The Gemini provides you a way to pass in a threshold for each category.\n",
    "\n",
    "The list below shows the possible threshold labels:\n",
    "\n",
    "* `BLOCK_ONLY_HIGH` - block when high probability of unsafe content is detected\n",
    "* `BLOCK_MEDIUM_AND_ABOVE` - block when medium or high probablity of content is detected\n",
    "* `BLOCK_LOW_AND_ABOVE` - block when low, medium, or high probability of unsafe content is detected\n",
    "* `BLOCK_NONE` - always show, regardless of probability of unsafe content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set safety thresholds\n",
    "Below, the safety thresholds have been set to the most sensitive threshold: `BLOCK_LOW_AND_ABOVE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = GenerateContentConfig(\n",
    "    safety_settings=[\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "            threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "            threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "            threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "            threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test thresholds\n",
    "\n",
    "Here you will reuse the impolite prompt from earlier together with the most sensitive safety threshold. It should block the response even with the `LOW` probability label.\n",
    "\n",
    "Try multiple times until you see a blocked response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "impolite_prompt = \"Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark:\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL, contents=impolite_prompt, config=generation_config\n",
    ")\n",
    "\n",
    "response.candidates[0].to_json_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [Thu Ya Kyaw](https://github.com/iamthuya)'s work.<br>\n",
    "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
