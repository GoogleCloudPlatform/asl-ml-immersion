{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Debugging and Optimizing Agents: A Guide to Tracing in Agent Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview) helps you build and deploy agent-based AI applications that use LLMs and custom tools. Understanding your agent's decision-making process is essential for debugging and optimization, and [Cloud Trace](https://cloud.google.com/trace) is a great tool for exploring this tracing data to get insights.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/agent-engine/images/cloud-trace-agent.png\">\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "- **Learn Key Concepts**: Learn about the fundamental building blocks of tracing.\n",
    "- **Deploy Your Agent**: Make your tracing-enabled agent available in a production-like environment on Agent Engine.\n",
    "- **Enable Tracing**: Enable tracing in a simple agent\n",
    "- **Examine Traces**: Use the Cloud Console and Cloud Trace SDK to access and analyze a specific trace.\n",
    "\n",
    "By the end of this notebook, you'll be able to leverage tracing to build more robust and efficient AI agents on Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d38b3d918526"
   },
   "source": [
    "## Concepts\n",
    "\n",
    "Here are some of the key concepts and terminology related to tracing, which will be helpful to understand as we explore traces generated by an agent in Agent Engine:\n",
    "\n",
    "Below is an example of a trace in JSON format, showing a single span. This span represents a call to a large language model (LLM). Notice how the trace data captures important details:\n",
    "\n",
    "### Example trace\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"name\": \"llm\",\n",
    "   \"context\": {\n",
    "       \"trace_id\": \"ed7b336d-e71a-46f0-a334-5f2e87cb6cfc\",\n",
    "       \"span_id\": \"ad67332a-38bd-428e-9f62-538ba2fa90d4\"\n",
    "   },\n",
    "   \"span_kind\": \"LLM\",\n",
    "   \"parent_id\": \"f89ebb7c-10f6-4bf8-8a74-57324d2556ef\",\n",
    "   \"start_time\": \"2023-09-07T12:54:47.597121-06:00\",\n",
    "   \"end_time\": \"2023-09-07T12:54:49.321811-06:00\",\n",
    "   \"status_code\": \"OK\",\n",
    "   \"status_message\": \"\",\n",
    "   \"attributes\": {\n",
    "       \"llm.input_messages\": [\n",
    "           {\n",
    "               \"message.role\": \"system\",\n",
    "               \"message.content\": \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"\n",
    "           },\n",
    "           {\n",
    "               \"message.role\": \"user\",\n",
    "               \"message.content\": \"Hello?\"\n",
    "           }\n",
    "       ],\n",
    "       \"output.value\": \"assistant: Yes I am here\",\n",
    "       \"output.mime_type\": \"text/plain\"\n",
    "   },\n",
    "   \"events\": [],\n",
    "}\n",
    "```\n",
    "\n",
    "### Trace\n",
    "\n",
    "You can think of a [trace](https://opentelemetry.io/docs/concepts/signals/traces/) like a timeline of requests as they travel through your application. A trace is composed of individual spans, with the first span representing the overall request. Each span provides details about a specific operation within the request.\n",
    "\n",
    "### Span\n",
    "\n",
    "A [span](https://opentelemetry.io/docs/concepts/signals/traces/#spans) represents a single unit of work, like a function call or an interaction with an LLM. It captures information such as the operation's name, start and end times, and any relevant attributes (metadata). Spans can be nested, showing parent-child relationships between operations.\n",
    "\n",
    "### Span Attribute\n",
    "\n",
    "[Span attributes](https://opentelemetry.io/docs/concepts/signals/traces/#attributes) are key-value pairs that provide additional context about a span. For instance, an LLM span might have attributes like the model name, prompt text, and token count.\n",
    "\n",
    "### Span Kind\n",
    "\n",
    "[Span kind](https://opentelemetry.io/docs/concepts/signals/traces/#span-kind) categorizes the type of operation a span represents. Common kinds include:\n",
    "\n",
    "- `CHAIN`: Links between LLM application steps or the start of a request.\n",
    "- `LLM`: A call to a large language model.\n",
    "- `TOOL`: An interaction with an external tool (API, database, etc.).\n",
    "- `AGENT`: A reasoning block that combines LLM and tool interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1FOTFPztdxd",
    "outputId": "1fd370de-a970-45e4-dba5-9b6fb595fbb3"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --user --quiet \\\n",
    "google-cloud-aiplatform[agent_engines,adk,langchain,ag2,llama_index]>=1.88.0 \\\n",
    "cloudpickle==3.0.0 \\\n",
    "\"pydantic>=2.10\" \\\n",
    "google-cloud-trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "6a4652f6-ef46-4183-e17e-bf2f911af496"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "BUCKET_NAME = PROJECT_ID\n",
    "STAGING_BUCKET = f\"gs://{BUCKET_NAME}\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "## Build and deploy an agent\n",
    "\n",
    "Let's dive into building a simple agent that utilizes tracing. This agent will use a few custom tools to demonstrate how tracing can provide insights into its workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c5e77496259"
   },
   "source": [
    "### Import libraries\n",
    "\n",
    "Before you start building your agent, you'll import the necessary libraries. These include the Vertex AI SDK, pandas for data analysis, and the Cloud Trace SDK for working with trace data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a2198c40f52",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import trace_v1 as trace\n",
    "from vertexai import agent_engines\n",
    "from vertexai.agent_engines._agent_engines import _utils\n",
    "from vertexai.preview.reasoning_engines import LangchainAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f73957911c3"
   },
   "source": [
    "### Define tools\n",
    "\n",
    "You'll define a few Python functions to act as tools for your agent. These tools will simulate actions or API calls that a real-world agent might perform. For this example, you'll create tools to classify a customer support ticket, query a knowledge base, and escalate a ticket to a human agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e7c7732f26f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_ticket(ticket_text: str) -> str:\n",
    "    \"\"\"Classifies a support ticket into a category.\"\"\"\n",
    "    # Simulate a call to a classification model\n",
    "    categories = {\n",
    "        \"general\": \"Questions and information\",\n",
    "        \"billing\": \"Payment and invoices\",\n",
    "        \"technical\": \"API and SDK developer documentation\",\n",
    "    }\n",
    "    if \"payment\" in ticket_text:\n",
    "        category = \"billing\"\n",
    "        description = categories[category]\n",
    "    elif \"settings\" in ticket_text:\n",
    "        category = \"technical\"\n",
    "        description = categories[category]\n",
    "    else:\n",
    "        category = \"general\"\n",
    "        description = categories[category]\n",
    "\n",
    "    return f\"This ticket is in the {category} category for questions related to {description}\"\n",
    "\n",
    "\n",
    "def search_knowledge_base(category: str) -> list[dict]:\n",
    "    \"\"\"Searches a knowledge base for relevant articles and documentation links.\"\"\"\n",
    "    # Simulate a knowledge base search\n",
    "    articles = {\n",
    "        \"general\": [\n",
    "            {\n",
    "                \"title\": \"Contacting support\",\n",
    "                \"url\": \"https://example.com/contact\",\n",
    "            }\n",
    "        ],\n",
    "        \"billing\": [\n",
    "            {\n",
    "                \"title\": \"How to update your payment information\",\n",
    "                \"url\": \"https://example.com/billing/update\",\n",
    "            },\n",
    "        ],\n",
    "        \"technical\": [\n",
    "            {\n",
    "                \"title\": \"Troubleshooting common login issues\",\n",
    "                \"url\": \"https://example.com/technical/help\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "    return articles.get(category, [])\n",
    "\n",
    "\n",
    "def escalate_to_human(ticket_text: str) -> str:\n",
    "    \"\"\"Initiates escalation to a human agent for outage reports.\"\"\"\n",
    "    return \"Your ticket has been escalated to a human agent. Please expect a response within 1-2 hours.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd55dbf42903"
   },
   "source": [
    "### Define agent and enable tracing\n",
    "\n",
    "Now, let's define your agent using the LangChain template in Agent Engine and the Vertex AI SDK. Enable tracing by setting the `enable_tracing` parameter to `True`, which allows you to capture detailed information about the agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78fb7ab21e3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = LangchainAgent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    model_kwargs={\"temperature\": 0},\n",
    "    tools=[classify_ticket, search_knowledge_base, escalate_to_human],\n",
    "    enable_tracing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d714e7d8432"
   },
   "source": [
    "### Test your agent locally (with traces!)\n",
    "\n",
    "Let's test your agent locally by sending it a query. Since you've enabled tracing, you'll be able to see how the agent processes this request and interacts with its tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2e9ac4ab9e9",
    "outputId": "2e57e250-0334-4500-d56b-af234e6ab868"
   },
   "outputs": [],
   "source": [
    "agent.query(\n",
    "    input=\"\"\"\n",
    "    Classify the following ticket into a category and give me a relevant documentation link.\n",
    "\n",
    "    Support ticket text:\n",
    "    I need to update my billing information since my payment method has expired.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82b1fbdafe7c"
   },
   "source": [
    "### Get your first trace\n",
    "\n",
    "Before diving deeper into trace analysis, let's use the Cloud Trace SDK to retrieve a specific trace generated by your local agent. This will give you a concrete example to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4894bb6a2d1"
   },
   "outputs": [],
   "source": [
    "client = trace.TraceServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea72cdb247ec"
   },
   "outputs": [],
   "source": [
    "result = [\n",
    "    r\n",
    "    for r in client.list_traces(\n",
    "        request=trace.types.ListTracesRequest(\n",
    "            project_id=PROJECT_ID,\n",
    "            # Return all traces containing `labels {key: \"openinference.span.kind\" value: \"AGENT\"}`\n",
    "            filter=\"openinference.span.kind:AGENT\",\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c56a32df5305",
    "outputId": "02b7519a-8c88-4100-bbf9-09c31595dfad"
   },
   "outputs": [],
   "source": [
    "trace_data = client.get_trace(\n",
    "    project_id=PROJECT_ID, trace_id=result[0].trace_id\n",
    ").spans[0]\n",
    "trace_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19aa87abae0a"
   },
   "source": [
    "After you deploy your agent and make remote queries in the following sections, you'll dive into the details for working with trace data in the Cloud Console or using the Python SDK for Cloud Trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdGcHqUv8THp"
   },
   "source": [
    "### Deploy your agent\n",
    "\n",
    "Now that you've seen how tracing works locally, let's deploy your agent to Agent Engine. This will allow you to send it queries in a production-like environment and observe its behavior through traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrTI0_1j8E7w",
    "outputId": "97a2dc3a-87f8-4f96-9a01-ecec57f5fc03"
   },
   "outputs": [],
   "source": [
    "remote_agent = agent_engines.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[agent_engines,adk,langchain,ag2,llama_index]>=1.88.0\",\n",
    "        \"cloudpickle==3.0.0\",\n",
    "        \"pydantic>=2.10\",\n",
    "        \"google-cloud-trace\",\n",
    "    ],\n",
    "    display_name=\"Agent Tracing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "019c774a18fd"
   },
   "source": [
    "### Query your deployed agent\n",
    "\n",
    "With your agent deployed, you can interact with it remotely. Let's send a query and generate some trace data to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7Iih52E0qsf",
    "outputId": "d29e5228-d545-48ba-ddc2-72279aa95fea"
   },
   "outputs": [],
   "source": [
    "# List all agent engines\n",
    "all_agent_engines = agent_engines.list()\n",
    "print(\"All Agent Engines:\")\n",
    "for agent in all_agent_engines:\n",
    "    print(f\"- {agent.display_name} : {agent.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aoh2elAf0rMM"
   },
   "outputs": [],
   "source": [
    "RESOURCE_ID = \"FILL IN YOUR RESOURCE ID\"\n",
    "from vertexai import agent_engines\n",
    "\n",
    "remote_agent = agent_engines.get(RESOURCE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZjdFQ_Z_J43",
    "outputId": "ea7c14cd-da58-43df-9869-ab056f572e3f"
   },
   "outputs": [],
   "source": [
    "remote_agent.query(\n",
    "    input=\"\"\"\n",
    "    Classify the following ticket into a category and route the customer accordingly:\n",
    "\n",
    "    Support ticket text:\n",
    "    I am unable to make any API calls and I need to report an outage in the system\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "761e2e6121f6"
   },
   "source": [
    "## Working with traces using `pandas`\n",
    "\n",
    "For more programmatic analysis, you can use the pandas library to work with trace data. You'll fetch traces, convert them to DataFrames, and then use pandas' functionality to explore the trace data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e68cf66f2b2c"
   },
   "outputs": [],
   "source": [
    "result = [\n",
    "    r\n",
    "    for r in client.list_traces(\n",
    "        request=trace.types.ListTracesRequest(\n",
    "            project_id=PROJECT_ID,\n",
    "            # Return all traces containing `labels {key: \"openinference.span.kind\" value: \"AGENT\"}`\n",
    "            filter=\"openinference.span.kind:AGENT\",\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ee427fa9cb3"
   },
   "outputs": [],
   "source": [
    "trace_data = client.get_trace(\n",
    "    project_id=PROJECT_ID, trace_id=result[0].trace_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "73a61c86fc7c",
    "outputId": "94dfc5a8-92a0-49e9-fd1f-dd49f30cb182"
   },
   "outputs": [],
   "source": [
    "spans = pd.DataFrame.from_records(\n",
    "    [_utils.to_dict(span) for span in trace_data.spans]\n",
    ")\n",
    "spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "a5fdff97b29f",
    "outputId": "4f03f6ed-b255-40e9-ab9e-5b5554010de8"
   },
   "outputs": [],
   "source": [
    "spans[spans[\"name\"] == \"ChatVertexAI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "691fe8935660",
    "outputId": "9d29d8bf-aa28-461d-e456-09eb7699bc0f"
   },
   "outputs": [],
   "source": [
    "spans[spans[\"name\"] == \"ChatVertexAI\"].labels.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "450a154ab035"
   },
   "source": [
    "## Exploring traces with the Python SDK for Cloud Trace\n",
    "\n",
    "The Cloud Trace Python SDK provides even more flexibility for working with trace data. We'll use it to demonstrate how to filter traces by date, time, labels, and view types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1e6ec298a2e"
   },
   "source": [
    "**Filter by date and time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7593b0dd5ab1",
    "outputId": "94d60d03-65a1-4445-b13e-80b3510fd3ea"
   },
   "outputs": [],
   "source": [
    "# Calculate the start and end times\n",
    "now = datetime.utcnow()\n",
    "yesterday = now - timedelta(hours=24)\n",
    "\n",
    "# Format the dates as ISO 8601 strings with 'Z' for UTC\n",
    "end_time = now.isoformat() + \"Z\"\n",
    "start_time = yesterday.isoformat() + \"Z\"\n",
    "\n",
    "# Request a filtered list of traces by date and time\n",
    "result = client.list_traces(\n",
    "    request=trace.types.ListTracesRequest(\n",
    "        project_id=PROJECT_ID,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "    )\n",
    ")\n",
    "\n",
    "for count, r in enumerate(result):\n",
    "    if count >= 5:\n",
    "        break\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0241dfa7e78e"
   },
   "source": [
    "**Filter by label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42f9490f60e5",
    "outputId": "27f57c85-350a-44ff-8cd3-c76054077474"
   },
   "outputs": [],
   "source": [
    "result = client.list_traces(\n",
    "    request=trace.types.ListTracesRequest(\n",
    "        project_id=PROJECT_ID,\n",
    "        # Return traces where any root span's name starts with AgentExecutor\n",
    "        filter=\"root:AgentExecutor\",\n",
    "    )\n",
    ")\n",
    "\n",
    "for count, r in enumerate(result):\n",
    "    if count >= 5:\n",
    "        break\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b13e8cc93b5d"
   },
   "source": [
    "**Filter by view type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "154dfc32ae35",
    "outputId": "97ce4713-5625-4934-df9c-4246b0749e3e"
   },
   "outputs": [],
   "source": [
    "result = client.list_traces(\n",
    "    request=trace.types.ListTracesRequest(\n",
    "        project_id=PROJECT_ID,\n",
    "        # view=trace.types.ListTracesRequest.ViewType.ROOTSPAN,\n",
    "        view=trace.types.ListTracesRequest.ViewType.MINIMAL,\n",
    "        # view=trace.types.ListTracesRequest.ViewType.COMPLETE,\n",
    "    )\n",
    ")\n",
    "\n",
    "for count, r in enumerate(result):\n",
    "    if count >= 5:\n",
    "        break\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "After you've finished experimenting, it's a good practice to clean up your cloud resources. You can delete the deployed Agent Engine instance to avoid any unexpected charges on your Google Cloud account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6327bf9c6ca9"
   },
   "outputs": [],
   "source": [
    "remote_agent.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
