{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac6099d-c03b-46cc-bd0a-dd96f824a8de",
   "metadata": {
    "id": "0ac6099d-c03b-46cc-bd0a-dd96f824a8de"
   },
   "source": [
    "# Interpretability of Language Model with Learning Interpretability Tool ðŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d79e19-968e-49d7-8abb-35ad2f985513",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to use explainability methods for a BERT-based text classification model with the [Learning Interpretability Tool (ðŸ”¥LIT)](https://pair-code.github.io/lit/).\n",
    "\n",
    "LIT is a visual, interactive ML model-understanding tool that supports text, image, and tabular data.<br>\n",
    "You can use LIT to ask and answer questions like:\n",
    "- What kind of examples does my model perform poorly on?\n",
    "- Why did my model make this prediction? Can it attribute it to adversarial behavior, or undesirable priors from the training set?\n",
    "- Does my model behave consistently if I change things like textual style, verb tense, or pronoun gender?\n",
    "\n",
    "LIT contains many built-in capabilities but is also customizable, with the ability to add custom interpretability techniques, metrics calculations, counterfactual generators, visualizations, and more.\n",
    "\n",
    "In this notebook, we'll explore the built-in interpretability methods - [LIME](#Explore-the-LIME-explanation) , [Gradient Norm](#Gradient-Norm), [Gradient-dot-Input](#Gradient-dot-Input), and [Integrated Gradients](#Add-Integrated-Gradients).\n",
    "\n",
    "### Learning objectives: \n",
    "* Learn the overview of the Learning Interpretability ToolðŸ”¥\n",
    "* Configure the LIT dataset and Model objects.\n",
    "* Customize the Model for interpretability methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09254b64-3602-4f7a-aff9-6d826b8c2b8f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916615f-68cf-4946-b31f-ce4fb3b48e5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4916615f-68cf-4946-b31f-ce4fb3b48e5a",
    "outputId": "51608304-59de-4546-8bf4-717262d39bbb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708d01f-9f6a-46f0-b4eb-85dc8afa23c6",
   "metadata": {
    "id": "0708d01f-9f6a-46f0-b4eb-85dc8afa23c6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import shutil\n",
    "from collections.abc import Iterable, Sequence\n",
    "\n",
    "import keras\n",
    "import keras_hub\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from lit_nlp import notebook\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "from lit_nlp.api import layout\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.api import types as lit_types\n",
    "\n",
    "JsonDict = lit_types.JsonDict\n",
    "Spec = lit_types.Spec\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b1c31-d2af-4f77-9d7c-816428bbf496",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d1b1c31-d2af-4f77-9d7c-816428bbf496",
    "outputId": "ddf67176-5507-4d7d-bfd7-038ac06b95f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927aaaf-b6db-4c7d-80ea-e83dee8ad3cc",
   "metadata": {
    "id": "0927aaaf-b6db-4c7d-80ea-e83dee8ad3cc"
   },
   "source": [
    "## Build a BERT-based Sentiment Analysis model\n",
    "\n",
    "This notebook trains a sentiment analysis model to classify movie reviews as *positive* or *negative*, based on the text of the review.\n",
    "\n",
    "You'll use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eedf91-b731-467a-a162-8c469685a952",
   "metadata": {
    "id": "51eedf91-b731-467a-a162-8c469685a952"
   },
   "source": [
    "### Download the IMDB dataset\n",
    "\n",
    "Let's download and extract the dataset, then explore the directory structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2faa77-fe1b-46d4-a77d-04a194699423",
   "metadata": {
    "id": "2d2faa77-fe1b-46d4-a77d-04a194699423",
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "path = \"/home/jupyter/\"\n",
    "dataset = keras.utils.get_file(\n",
    "    \"aclImdb_v1.tar.gz\", url, untar=True, cache_dir=path, cache_subdir=\"\"\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(\n",
    "    os.path.dirname(dataset), \"aclImdb_v1_extracted/aclImdb\"\n",
    ")\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# remove unused folders to make it easier to load the data\n",
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9735ca6-cd37-4e94-aa0c-26e66f262d66",
   "metadata": {
    "id": "c9735ca6-cd37-4e94-aa0c-26e66f262d66"
   },
   "source": [
    "Next, you will use the `text_dataset_from_directory` utility to create a labeled `tf.data.Dataset`.\n",
    "\n",
    "The IMDB dataset has already been divided into train and test, but it lacks a validation set. Let's create a validation set using an 80:20 split of the training data by using the `validation_split` argument below.\n",
    "\n",
    "Note:  When using the `validation_split` and `subset` arguments, make sure to either specify a random seed, or to pass `shuffle=False`, so that the validation and training splits have no overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cada35-c136-491d-bbc6-33c522004685",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45cada35-c136-491d-bbc6-33c522004685",
    "outputId": "1c6e3ab8-c6af-4f06-db6d-0f99b8b830e8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "UTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = keras.utils.text_dataset_from_directory(\n",
    "    path + \"aclImdb_v1_extracted/aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    path + \"aclImdb_v1_extracted/aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    path + \"aclImdb_v1_extracted/aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548fc4e-c2eb-4ecf-88e2-67dc696bf58e",
   "metadata": {
    "id": "9548fc4e-c2eb-4ecf-88e2-67dc696bf58e"
   },
   "source": [
    "### Train BERT model with Keras NLP\n",
    "\n",
    "For the purpose of this lab, we will be loading a small model called tiny BERT, already pre-trained for sentiment analysis purpose. The tiny BERT has the same general architecture as the original BERT but the has fewer and/or smaller Transformer blocks.\n",
    "\n",
    "For other model types, see the [Keras NLP documentation](https://keras.io/api/keras_nlp/models/bert/bert_classifier/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c07033-70a7-4a40-9d45-5a8ae914aba8",
   "metadata": {
    "id": "66c07033-70a7-4a40-9d45-5a8ae914aba8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = keras_hub.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased_sst2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc13b0-7e28-409a-8902-0b0d3920e37c",
   "metadata": {},
   "source": [
    "We use adamw optimizer with a warm-up period. See [this paper](https://arxiv.org/abs/1905.05583) for a general guideline of BERT finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5730a4-a354-404b-8b74-5b041af0cd5a",
   "metadata": {
    "id": "7c5730a4-a354-404b-8b74-5b041af0cd5a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "warmup_tgt = 3e-5\n",
    "scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "    0.0,\n",
    "    num_train_steps,\n",
    "    warmup_target=warmup_tgt,\n",
    "    warmup_steps=num_warmup_steps,\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34cc4b3-4a58-412e-97d0-4912c942e5ae",
   "metadata": {
    "id": "f34cc4b3-4a58-412e-97d0-4912c942e5ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e9ecb-db92-4aae-a031-fd6bfa3754c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "029e9ecb-db92-4aae-a031-fd6bfa3754c1",
    "outputId": "fc2b5f5f-a01d-495c-ed64-bdf634512ef4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"./model\"\n",
    "\n",
    "history = classifier.fit(x=train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b92e8a-fd0e-40de-a1e1-a91de3c0b256",
   "metadata": {
    "id": "d5b92e8a-fd0e-40de-a1e1-a91de3c0b256"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960b150-272c-4de9-972c-57356d918a1f",
   "metadata": {
    "id": "0960b150-272c-4de9-972c-57356d918a1f"
   },
   "source": [
    "## Use the Learning Interpretability Tool\n",
    "\n",
    "Let's start using the Learning Interpretability Tool. We use LIT for our Keras model, but please note that LIT itself is framework agnostic.\n",
    "\n",
    "<img src=\"https://pair-code.github.io/lit/documentation/_images/lit-system-diagram.svg\" width=\"1084\">\n",
    "\n",
    "In this notebook, We'll configure two LIT objects: Dataset and Model.\n",
    "\n",
    "### Dataset\n",
    "Datasets are lists of examples, with associated type information following LITâ€™s type system.\n",
    "\n",
    "- `spec()` should return a flat dict that describes the fields in each example. Note that each item is typed using LIT types. See [the documentation about the LIT types](https://pair-code.github.io/lit/documentation/api.html#available-types) for more details.\n",
    "- `self._examples` should be a list of flat dicts, conforming to `spec()`\n",
    "\n",
    "In this case, we convert `tf.data.Dataset` object to LIT Dataset by iterating through it.\n",
    "\n",
    "LIT operates on all examples loaded in the datasets you include in your LIT server. Therefore, you should take care to use dataset sizes that can fit into memory on your backend server and can be displayed in the browser.\n",
    "\n",
    "Implementations should subclass [Dataset](https://github.com/PAIR-code/lit/blob/main/lit_nlp/api/dataset.py). Usually, this is just a few lines of code like the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea1c05-723f-4c7b-becb-f813a6d565bc",
   "metadata": {
    "id": "17ea1c05-723f-4c7b-becb-f813a6d565bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_DATA = 100  # Get small samples\n",
    "LABELS = [\"negative\", \"positive\"]\n",
    "\n",
    "\n",
    "class ImdbSentimentData(lit_dataset.Dataset):\n",
    "\n",
    "    def __init__(self, dataset: tf.data.Dataset):\n",
    "        data_array = list(\n",
    "            dataset.shuffle(dataset.cardinality()).as_numpy_iterator()\n",
    "        )\n",
    "        texts, targets = [], []\n",
    "        for features, labels in data_array:\n",
    "            texts.extend([f.decode() for f in features if len(f.decode())])\n",
    "            targets.extend(labels)\n",
    "        # Store as a list of dicts, conforming to self.spec()\n",
    "        self._examples = [\n",
    "            {\n",
    "                \"text\": text,\n",
    "                \"label\": LABELS[1] if target else LABELS[0],\n",
    "            }\n",
    "            for text, target in zip(texts[:NUM_DATA], targets[:NUM_DATA])\n",
    "        ]\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"label\": lit_types.CategoryLabel(vocab=LABELS),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586f8a6-706e-4fa1-8a50-71734badd5a3",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Models are functions that take inputs and produce outputs, with associated type information following LITâ€™s type system. \n",
    "\n",
    "The core API consists of three methods:\n",
    "- `input_spec()` should return a flat dict that describes necessary input fields. Here we define `\"text\"` and `\"label\"`.\n",
    "- `output_spec()` should return a flat dict that describes the modelâ€™s predictions and any additional outputs. In our case, we use the `MulticlassPreds` type.\n",
    "- `predict()` should take a sequence of inputs (satisfying `input_spec()`) and yields a parallel sequence of outputs matching `output_spec()`.\n",
    "\n",
    "Implementations should subclass [Model](https://github.com/PAIR-code/lit/blob/main/lit_nlp/api/model.py). \n",
    "\n",
    "With this simple Model setup, we can use a black-box interpretability method, LIME, since it just pays attention to inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7866b-43b9-4bb6-b6e1-3b7e07d15911",
   "metadata": {
    "id": "9db7866b-43b9-4bb6-b6e1-3b7e07d15911",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertSentimentModel(lit_model.Model):\n",
    "\n",
    "    def __init__(self, model: keras.Model):\n",
    "        self._model = model\n",
    "\n",
    "    def predict(self, inputs: Iterable[JsonDict]) -> Iterable[JsonDict]:\n",
    "        examples = [d[\"text\"] for d in inputs]\n",
    "        tokens = self._model.preprocessor(examples)\n",
    "        logits = self._model(tokens)\n",
    "        probs = keras.activations.sigmoid(logits)\n",
    "        return [{\"prob\": prob.numpy()} for prob in probs]\n",
    "\n",
    "    def input_spec(self) -> Spec:\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"label\": lit_types.CategoryLabel(required=False, vocab=LABELS),\n",
    "        }\n",
    "\n",
    "    def output_spec(self) -> Spec:\n",
    "        return {\n",
    "            \"prob\": lit_types.MulticlassPreds(vocab=LABELS, parent=\"label\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac33808-5fc6-4bbe-be62-2b7c40696949",
   "metadata": {},
   "source": [
    "Now let's create a LIT widget in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bd33b-2740-453e-843f-0a6eadaee0e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a9bd33b-2740-453e-843f-0a6eadaee0e6",
    "outputId": "6996d79a-ae5f-4a6a-bee0-bf17a57d1a5c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the LIT widget with the model and dataset to analyze.\n",
    "datasets = {\"acllmdb\": ImdbSentimentData(test_ds)}\n",
    "models = {\"BERT classifier\": BertSentimentModel(classifier)}\n",
    "layouts = {\"default\": \"default\"}\n",
    "\n",
    "# Uncomment below when you rerun the widget.\n",
    "# widget.stop()\n",
    "widget = notebook.LitWidget(models, datasets, port=8890)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb6102-b772-4027-bdb3-12e604fa9286",
   "metadata": {},
   "source": [
    "You can render the widget using the `render()` method.<br>\n",
    "The widget can be embedded in the notebook, but let's add `open_in_new_tab=True` and check the widget on another tab.\n",
    "\n",
    "Feel free to play around with the UI and check how the concepts we defined above are linked to the LIT UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a423cb4d-87e5-4dd2-8bba-1c45dff1c221",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "a423cb4d-87e5-4dd2-8bba-1c45dff1c221",
    "outputId": "7fea223f-cabe-43dc-e2f5-39138d9f7c4f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Render the widget\n",
    "widget.render(height=600, open_in_new_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9282849-d149-4c5f-b2d4-0f31c050f1d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Customize the Layout\n",
    "\n",
    "The UI looks handy, doesn't it?<br>\n",
    "But you might want to change the layout a bit. No worries! The LIT UI is customizable.<br>\n",
    "\n",
    "Let's switch to a richer layout from the prebuild layout catalog. <br>\n",
    "We'll keep the original UI in case you want to switch back by passing multiple layouts in a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315295b-6a3d-421b-b96c-5a86b30e7f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layouts = {\n",
    "    \"rich_layout\": layout.THREE_PANEL_LAYOUT,\n",
    "    \"default\": notebook.LIT_NOTEBOOK_LAYOUT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb366850-63c9-435d-92d6-a6f4a72d3008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "widget.stop()\n",
    "widget = notebook.LitWidget(models, datasets, layouts=layouts, port=8890)\n",
    "widget.render(height=600, open_in_new_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678959f2-f8c1-4581-b713-75ea91281c04",
   "metadata": {},
   "source": [
    "If you want to customize the UI, refer to the [documentation](https://pair-code.github.io/lit/documentation/api.html#customizing-the-layout) and the [UI definition](https://github.com/PAIR-code/lit/blob/main/lit_nlp/api/layout.py#L173) we just used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc329e-a850-4549-bff8-c3334210b181",
   "metadata": {},
   "source": [
    "### Explore the LIME explanation\n",
    "Now, let's investigate the LIME explanation using the UI we just rendered.\n",
    "\n",
    "[LIME](https://arxiv.org/abs/1602.04938) is a widely used black-box (or model-agnostic) explainability method. Since it is a black-box method, we can use LIME for any ML models (or, more generally, any functions that have inputs and outputs) to get the saliency.\n",
    "\n",
    "1. Select a text input from the left panel.\n",
    "2. On the upper-right panel, check the predicted probabilities for the `negative` and `positive` classes, the label (indicated as `T`), and the predicted class (`P`).\n",
    "3. On the lower right panel, select the `Explanations` tab.\n",
    "4. Click the arrow symbol on the right-hand side of `LIME.`\n",
    "5. Saliency scores appear on each word. If the coloring is too pale, raise the `Gamma` score until you can see the color clearly.\n",
    "6. Confirm that the predicted class is already set as `Class to explain`.\n",
    "6. Mouse over an important word (colored in a vivid red or blue color), and check the score. A positive score means a positive contribution to the label (to the `positive` class in the screenshot below), and a negative score means a negative contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386365c-b1c2-4315-b6e4-ed253e227162",
   "metadata": {},
   "source": [
    "<img width=\"800\" src=\"https://github.com/user-attachments/assets/05623753-bdf8-4aec-88c6-3e7d0718576a\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00957a5-f0fb-47dd-bc02-9099a942870a",
   "metadata": {
    "id": "e00957a5-f0fb-47dd-bc02-9099a942870a"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac8692-c62d-4193-a913-2439c46e7c21",
   "metadata": {},
   "source": [
    "## Add Gradient-based Saliency Methods\n",
    "\n",
    "Black-box methods like LIME are flexible and easy to use since they don't require access to model internals. However, we can understand the model behavior more delicately by utilizing model internals, like gradients.\n",
    "\n",
    "The core idea of gradient-based interpretability is to compute the gradient of outputs, $y$, with respect to each input, $x$.\n",
    "\n",
    "In text classification, outputs are logits produced by the last layer of the model, and inputs are token embeddings (in image classification, inputs should be image pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c34b7-e274-49ef-8f39-62960e8341f2",
   "metadata": {},
   "source": [
    "### Dissect the Model\n",
    "\n",
    "Let's look at our BERT model and dissect it for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c79ca-23fd-4fe7-8cbc-7f851b912125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(classifier, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456931a3-af6d-465a-a2a2-e6ce4167ddb7",
   "metadata": {},
   "source": [
    "Let's take a look at the layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186f606-694f-4ad1-a23b-126283c274f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6614d7c-5c26-4187-9551-141cf1d01905",
   "metadata": {},
   "source": [
    "It looks like the main model is nested in the `BertBackbone` layer (`classifier.layers[3]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa861ca-11a8-4964-94b7-ef00516d8543",
   "metadata": {
    "id": "caa861ca-11a8-4964-94b7-ef00516d8543",
    "outputId": "65eaae3a-a2fc-4092-b338-89f50acfec34",
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.layers[3].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85789e-4406-48b2-ad29-44cda40c4a13",
   "metadata": {},
   "source": [
    "Let's plot the nested `BertBackbone` to see the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688348da-ddcd-4402-9d8d-d55315422226",
   "metadata": {
    "id": "688348da-ddcd-4402-9d8d-d55315422226",
    "outputId": "b1290b4e-904e-46dd-e54d-767b600857f3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(\n",
    "    classifier.layers[3], show_shapes=True, show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b414cab-6057-473b-b216-4cb3bc17b72e",
   "metadata": {},
   "source": [
    "We want to get token embeddings. It seems like the output of the `token_embedding` layer (`classifier.layers[3].layers[1]`) produces the token embeddings. However, the final embedding is produced by the `add_1` layer (`classifier.layers[3].layers[5]`) by combining positional encoding.<br>\n",
    "Also, a Layer Normalization layer (`classifier.layers[3].layers[6]`) follows it. This embedding seems to be a good target for gradient-based interpretability.\n",
    "\n",
    "Let's define a standalone module until this layer. Here, we can find nested layers. Let's visualize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d881e9-dc4b-4e59-941e-720930db6a8f",
   "metadata": {
    "id": "25d881e9-dc4b-4e59-941e-720930db6a8f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model = keras.Model(\n",
    "    inputs=classifier.input, outputs=classifier.layers[3].layers[6].output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b9e7b-0a09-4b70-8cea-1b2f24398769",
   "metadata": {
    "id": "b76b9e7b-0a09-4b70-8cea-1b2f24398769",
    "outputId": "e1694dc2-7727-479a-91dd-64bbbf2421c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892f70d-7c07-47bb-9f27-65f19dccc4fd",
   "metadata": {},
   "source": [
    "The main BERT model follows it. Here, we similarly define a remaining BERT backbone as a standalone module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d6f95-6327-4cfd-a077-13022ce9197a",
   "metadata": {
    "id": "b20d6f95-6327-4cfd-a077-13022ce9197a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_backbone = keras.Model(\n",
    "    inputs=[\n",
    "        classifier.layers[3].layers[7].input,\n",
    "        classifier.layers[3].layers[8].output,\n",
    "    ],\n",
    "    outputs=classifier.layers[3].layers[-1].output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12e2bf-4e92-4c6a-b9d7-bac832fb3391",
   "metadata": {
    "id": "6d12e2bf-4e92-4c6a-b9d7-bac832fb3391",
    "outputId": "cc46d0b0-a6e6-473c-aa31-bae8a6ccbfca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(bert_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5f3205-033b-48ec-8734-e9e043e4ef4f",
   "metadata": {},
   "source": [
    "Last, we define a classification head, which produces the final logits value from which we calculate the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23139e-2e1f-415c-86e8-d3094f8bbb1e",
   "metadata": {
    "id": "ad23139e-2e1f-415c-86e8-d3094f8bbb1e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_head = keras.Model(\n",
    "    inputs=classifier.layers[-2].input, outputs=classifier.layers[-1].output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569b145-e302-4388-b991-df0167ff8ddd",
   "metadata": {
    "id": "f569b145-e302-4388-b991-df0167ff8ddd",
    "outputId": "5548ebc0-a489-4340-f36f-e60a983b6c98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(cls_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9223c-8236-4397-9689-7bd261de02f8",
   "metadata": {},
   "source": [
    "We can call these three modules in order to calculate logits from texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3db03-9d56-4c40-af53-9de056e31a6b",
   "metadata": {
    "id": "54f3db03-9d56-4c40-af53-9de056e31a6b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ImdbSentimentData(test_ds)\n",
    "text = data.examples[0][\"text\"]\n",
    "\n",
    "tokens = classifier._preprocessor(keras.ops.convert_to_tensor([text]))\n",
    "embeddings = embedding_model(tokens)\n",
    "bert_output = bert_backbone([embeddings, tokens[\"padding_mask\"]])\n",
    "logits = cls_head(bert_output)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a7771-eff9-4f70-a618-8e1b927cebe0",
   "metadata": {},
   "source": [
    "### Compute Gradients\n",
    "In TensorFlow, we can use `tf.GradientTape` context manager to use autograd capability.\n",
    "\n",
    "If you are using other frameworks, please refer to the documentation about autograd to do the same procedure (e.g. [Pytorch](https://pytorch.org/tutorials/beginner/former_torchies/autograd_tutorial.html), [JAX](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbf2dd-e0e2-4f21-8a91-46052dcfd47f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d4d5c-42b6-4ff9-8330-7d93dcaab4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbeea4-d10a-4287-8a65-7307fab6abd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1df18-76d0-4241-a47e-afdaca1d20ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[[i, idx] for i, idx in enumerate(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4d7cb-d333-43ab-91bc-8cc451b36161",
   "metadata": {
    "id": "a5f4d7cb-d333-43ab-91bc-8cc451b36161",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(embeddings)\n",
    "    bert_output = bert_backbone([embeddings, tokens[\"padding_mask\"]])\n",
    "    logits = cls_head(bert_output)\n",
    "\n",
    "    indices = tf.argmax(logits, axis=-1)\n",
    "    pred = tf.gather_nd(logits, [[i, idx] for i, idx in enumerate(indices)])\n",
    "\n",
    "input_emb_grads = tape.gradient(pred, embeddings)\n",
    "input_emb_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259afd3b-3505-4e7d-900f-d5a2fc879e90",
   "metadata": {},
   "source": [
    "### Update LIT Model\n",
    "\n",
    "Looks great! \n",
    "\n",
    "Based on this setup, we can add two gradient-based methods, Gradient Norm and Gradient-dot-Input:\n",
    "\n",
    "#### Gradient Norm\n",
    "Gradient Norm is a simple method in which salience scores are proportional to the L2 norm of the gradient, i.e., the score for a token $i$ is:\n",
    "\n",
    "$S(i)\\propto  \\|  \\nabla _{x_i} \\hat{y} \\| _2$\n",
    "\n",
    "#### Gradient-dot-Input\n",
    "In Gradient-dot-Input, salience scores are proportional to the dot product of the input embeddings and their gradients, i.e., for token $i$, we compute:\n",
    "\n",
    "$S(i)\\propto  x_i \\nabla_{x_i} \\hat{y} $\n",
    "\n",
    "\n",
    "Since we already defined $\\hat{y}$ in the previous model, there are two additional elements we have to produce: $\\nabla _{x_i}$ and $x_i$. \n",
    "- $x_i$: token embedding. This is only required by Gradient-dot-Input.\n",
    "- $\\nabla _{x_i}$: Gradient of each token embedding. This is necessary for both Gradient Norm and Gradient-dot-Input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ecd83-66f8-460a-a7de-86ec75c4bc4d",
   "metadata": {},
   "source": [
    "Let's update the LIT model module to reflect these elements. \n",
    "\n",
    "Here are the key updates we make:\n",
    "- in `__init__()`, we define additional modules discussed above.\n",
    "- `output_spec()` output now contains three additional key-value specs:\n",
    "  - `\"tokens\"`: a list of tokens of shape `(num_tokens)`. For spec, we use `Tokens` LIT type with `parent=\"text\"` to link with the input text.\n",
    "  - `\"input_embedding\"`: token embeddings ($x_i$) of shape `(num_tokens, emb_dim)`. For the spec, we use `TokenEmbeddings` LIT type with `align=\"tokens\"`.\n",
    "  - `\"input_emb_grad\"`: gradients of token embeddings ($\\nabla _{x_i}$) of shape `(num_tokens, emb_dim)`. For the spec, we use `TokenGradients` LIT type with `align=\"tokens\"` and  `grad_for=\"input_embedding\"` to define the link.\n",
    "- `predict()` now computes gradients using the three sub-modules and `tf.GradientTape` discussed above and returns the three additional elements corresponding to the `output_spec()` spec definition. <br>\n",
    "Note that we slice the `tokens`, `impute_embedding` and `input_emb_grad` with `[START_OFFSET : slen - END_OFFSET]` where:\n",
    "  - `START_OFFSET=1` to trim the first `[CLS]` token that doesn't correspond with any elements in the input sentence,\n",
    "  - `END_OFFSET=1` to trim the `[SEP]` token BERT uses after the first sentence. Note that BERT can take a pair of sentences. `[SEP]` is a separator between them, while we only use a single sentence in this text classification example.\n",
    "  - `slen` is the length of input tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5277650-f29c-4219-941a-2f6a541a0d54",
   "metadata": {
    "id": "f5277650-f29c-4219-941a-2f6a541a0d54",
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_OFFSET = 1  # offset [CLS] token\n",
    "END_OFFSET = 1  # offset [SEP] token\n",
    "\n",
    "\n",
    "class BertSentimentModel(lit_model.Model):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "        ########## MODEL SLICES ##########\n",
    "        self._embedding_model = keras.Model(\n",
    "            inputs=model.input, outputs=model.layers[3].layers[6].output\n",
    "        )\n",
    "        self._bert_backbone = keras.Model(\n",
    "            inputs=[\n",
    "                model.layers[3].layers[7].input,\n",
    "                model.layers[3].layers[8].output,\n",
    "            ],\n",
    "            outputs=model.layers[3].layers[-1].output,\n",
    "        )\n",
    "        self._cls_head = keras.Model(\n",
    "            inputs=classifier.layers[-2].input,\n",
    "            outputs=classifier.layers[-1].output,\n",
    "        )\n",
    "        ##################################\n",
    "\n",
    "    def _detokenize(self, indices):\n",
    "        return [\n",
    "            self._model.preprocessor.tokenizer.vocabulary[idx]\n",
    "            for idx in indices\n",
    "        ]\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"Predict on a stream of examples.\"\"\"\n",
    "        examples = [d[\"text\"] for d in inputs]\n",
    "        tokenized = self._model.preprocessor(examples)\n",
    "        seq_lens = keras.ops.sum(\n",
    "            keras.ops.cast(tokenized[\"padding_mask\"], \"int32\"), axis=-1\n",
    "        )\n",
    "        embeddings = self._embedding_model(tokenized)\n",
    "\n",
    "        ########## COMPUTE GRADIENTS ##########\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(embeddings)\n",
    "            bert_output = self._bert_backbone(\n",
    "                [embeddings, tokenized[\"padding_mask\"]]\n",
    "            )\n",
    "            logits = self._cls_head(bert_output)\n",
    "\n",
    "            if \"label\" in inputs[0].keys():\n",
    "                indices = [\n",
    "                    1 if inp[\"label\"] == LABELS[1] else 0 for inp in inputs\n",
    "                ]\n",
    "            else:\n",
    "                indices = tf.argmax(logits, axis=-1)\n",
    "\n",
    "            pred = tf.gather_nd(\n",
    "                logits, [[i, idx] for i, idx in enumerate(indices)]\n",
    "            )\n",
    "\n",
    "        probs = keras.activations.softmax(logits)\n",
    "\n",
    "        input_emb_grads = tape.gradient(pred, embeddings)\n",
    "        ######################################\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"prob\": prob.numpy(),\n",
    "                ########## NEW OUTPUTS ##########\n",
    "                \"tokens\": self._detokenize(\n",
    "                    tokens[START_OFFSET : slen - END_OFFSET]\n",
    "                ),\n",
    "                \"input_embedding\": emb[\n",
    "                    START_OFFSET : slen - END_OFFSET\n",
    "                ].numpy(),\n",
    "                \"input_emb_grad\": grad[\n",
    "                    START_OFFSET : slen - END_OFFSET\n",
    "                ].numpy(),\n",
    "                #################################\n",
    "            }\n",
    "            for prob, tokens, emb, grad, slen in zip(\n",
    "                probs,\n",
    "                tokenized[\"token_ids\"],\n",
    "                embeddings,\n",
    "                input_emb_grads,\n",
    "                seq_lens,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def input_spec(self):\n",
    "        \"\"\"Describe the inputs to the model.\"\"\"\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"label\": lit_types.CategoryLabel(required=False, vocab=LABELS),\n",
    "        }\n",
    "\n",
    "    def output_spec(self):\n",
    "        \"\"\"Describe the model outputs.\"\"\"\n",
    "        return {\n",
    "            \"prob\": lit_types.MulticlassPreds(vocab=LABELS, parent=\"label\"),\n",
    "            ########## NEW OUTPUT SPECS ##########\n",
    "            \"tokens\": lit_types.Tokens(parent=\"text\"),\n",
    "            \"input_embedding\": lit_types.TokenEmbeddings(align=\"tokens\"),\n",
    "            \"input_emb_grad\": lit_types.TokenGradients(\n",
    "                align=\"tokens\", grad_for=\"input_embedding\"\n",
    "            ),\n",
    "            ######################################\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510bc1b-e8b9-45e2-a60c-7eca5b0f2815",
   "metadata": {},
   "source": [
    "Let's render LIT again and check how these changes are reflected in the UI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11633154-f2ef-4011-8079-49b6553dd0ca",
   "metadata": {
    "id": "11633154-f2ef-4011-8079-49b6553dd0ca",
    "outputId": "0a4c881a-a145-4019-e89e-e631b7284bef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the LIT widget with the model and dataset to analyze.\n",
    "models = {\"BERT classifier\": BertSentimentModel(classifier)}\n",
    "\n",
    "widget.stop()\n",
    "widget = notebook.LitWidget(models, datasets, layouts=layouts, port=8890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c86b5-c819-4f2c-b874-7c678a763d4b",
   "metadata": {
    "id": "826c86b5-c819-4f2c-b874-7c678a763d4b",
    "outputId": "d1ee69cc-1793-4081-bfe9-3f51882ebfa9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "widget.render(height=600, open_in_new_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44b742-df4a-4e97-8e82-b12be9008654",
   "metadata": {},
   "source": [
    "## Add Integrated Gradients\n",
    "\n",
    "The integrated gradient method is a more robust method for estimating feature contribution based on integrating gradients along a path in embedding space. <br>\n",
    "See [Sundararajan et al. 2017](https://arxiv.org/abs/1703.01365) for additional details on the algorithm. This method may give better results than grad-norm and grad-dot-input but also requires more involved instrumentation of the model.\n",
    "\n",
    "There are the key updates to use Integrated Gradients:\n",
    "- `input_spec()` now includes `input_embedding` as an optional key-value (`required=False`), which is the same name as the output `input_embedding` spec. <br>\n",
    "In Integrated Gradients, LIT computes multiple inputs (token embeddings in this case) perturbations on which we compute gradients, and integrates over them. This optional input is the gate of those perturbations, which will only be passed when we use Integrated Gradients.\n",
    "- `output_spec()` is almost the same as the previous example, except for the additional `grad_target_field_key=\"label\"` to link with the label field from the input.\n",
    "- `predict()` now has a conditional operation for Integrated Gradients (i.e., in case the `input_embedding` key is included in inputs). We simply swap the perturbations with the raw embeddings calculated from the original inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f18da-bf3f-41ab-9122-c16b21e3d005",
   "metadata": {
    "id": "f37f18da-bf3f-41ab-9122-c16b21e3d005",
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_OFFSET = 1  # offset [CLS] token\n",
    "END_OFFSET = 1  # offset [SEP] token\n",
    "\n",
    "\n",
    "class BertSentimentModel(lit_model.Model):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "        self._embedding_model = keras.Model(\n",
    "            inputs=model.input, outputs=model.layers[3].layers[6].output\n",
    "        )\n",
    "        self._bert_backbone = keras.Model(\n",
    "            inputs=[\n",
    "                model.layers[3].layers[7].input,\n",
    "                model.layers[3].layers[8].output,\n",
    "            ],\n",
    "            outputs=model.layers[3].layers[-1].output,\n",
    "        )\n",
    "        self._cls_head = keras.Model(\n",
    "            inputs=classifier.layers[-2].input,\n",
    "            outputs=classifier.layers[-1].output,\n",
    "        )\n",
    "\n",
    "    def _detokenize(self, indices):\n",
    "        return [\n",
    "            self._model.preprocessor.tokenizer.vocabulary[idx]\n",
    "            for idx in indices\n",
    "        ]\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"Predict on a stream of examples.\"\"\"\n",
    "        examples = [d[\"text\"] for d in inputs]\n",
    "        tokenized = self._model.preprocessor(examples)\n",
    "        seq_lens = keras.ops.sum(\n",
    "            keras.ops.cast(tokenized[\"padding_mask\"], \"int32\"), axis=-1\n",
    "        )\n",
    "        embeddings = self._embedding_model(tokenized)\n",
    "        ########## CONDITIONAL OPERATION FOR IG PERTURBATIONS ##########\n",
    "        if \"input_embedding\" in inputs[0].keys():\n",
    "            pertubations = keras.ops.convert_to_tensor(\n",
    "                [inp[\"input_embedding\"] for inp in inputs]\n",
    "            )\n",
    "            step_size, ptb_len, emd_dim = pertubations.shape\n",
    "            pertubations = keras.ops.reshape(\n",
    "                pertubations, (step_size * ptb_len, emd_dim)\n",
    "            )\n",
    "            update_indices = [\n",
    "                [s, l + START_OFFSET]\n",
    "                for s in range(step_size)\n",
    "                for l in range(ptb_len)\n",
    "            ]\n",
    "            embeddings = tf.tensor_scatter_nd_update(\n",
    "                embeddings, update_indices, pertubations\n",
    "            )\n",
    "        ###############################################################\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(embeddings)\n",
    "            bert_output = self._bert_backbone(\n",
    "                [embeddings, tokenized[\"padding_mask\"]]\n",
    "            )\n",
    "            logits = self._cls_head(bert_output)\n",
    "            if \"label\" in inputs[0].keys():\n",
    "                indices = [\n",
    "                    1 if inp[\"label\"] == LABELS[1] else 0 for inp in inputs\n",
    "                ]\n",
    "            else:\n",
    "                indices = tf.argmax(logits, axis=-1)\n",
    "            pred = tf.gather_nd(\n",
    "                logits, [[i, idx] for i, idx in enumerate(indices)]\n",
    "            )\n",
    "\n",
    "        probs = tf.keras.activations.softmax(logits)\n",
    "\n",
    "        input_emb_grads = tape.gradient(pred, embeddings)\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"prob\": prob.numpy(),\n",
    "                \"tokens\": self._detokenize(\n",
    "                    tokens[START_OFFSET : slen - END_OFFSET]\n",
    "                ),\n",
    "                \"input_embedding\": emb[\n",
    "                    START_OFFSET : slen - END_OFFSET\n",
    "                ].numpy(),\n",
    "                \"input_emb_grad\": grad[\n",
    "                    START_OFFSET : slen - END_OFFSET\n",
    "                ].numpy(),\n",
    "            }\n",
    "            for prob, tokens, emb, grad, slen in zip(\n",
    "                probs,\n",
    "                tokenized[\"token_ids\"],\n",
    "                embeddings,\n",
    "                input_emb_grads,\n",
    "                seq_lens,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def input_spec(self):\n",
    "        \"\"\"Describe the inputs to the model.\"\"\"\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"label\": lit_types.CategoryLabel(required=False, vocab=LABELS),\n",
    "            ########## NEW INPUT SPEC FOR IG PERTURBATIONS ##########\n",
    "            \"input_embedding\": lit_types.TokenEmbeddings(\n",
    "                required=False, align=\"tokens\"\n",
    "            ),\n",
    "            #########################################################\n",
    "        }\n",
    "\n",
    "    def output_spec(self):\n",
    "        \"\"\"Describe the model outputs.\"\"\"\n",
    "        return {\n",
    "            \"prob\": lit_types.MulticlassPreds(vocab=LABELS, parent=\"label\"),\n",
    "            \"tokens\": lit_types.Tokens(parent=\"text\"),\n",
    "            \"input_embedding\": lit_types.TokenEmbeddings(align=\"tokens\"),\n",
    "            \"input_emb_grad\": lit_types.TokenGradients(\n",
    "                align=\"tokens\",\n",
    "                grad_for=\"input_embedding\",\n",
    "                ########## ADDITIONAL ARGUMENT FOR IG ##########\n",
    "                grad_target_field_key=\"label\",\n",
    "                ################################################\n",
    "            ),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bda6f3-7573-4c66-b1da-70dc94e0ca84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the LIT widget with the model and dataset to analyze.\n",
    "models = {\"BERT classifier\": BertSentimentModel(classifier)}\n",
    "\n",
    "widget.stop()\n",
    "widget = notebook.LitWidget(models, datasets, layouts=layouts, port=8890)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d42583-e6ff-4379-ab4f-5d9bac67a6b5",
   "metadata": {},
   "source": [
    "Let's render the LIT UI again. \n",
    "\n",
    "Click the arrow on In Integrated Gradients to compute the saliency with it since it requires additional computation.\n",
    "\n",
    "Also, from the configuration button, you can change the step size (number of perturbations you'll approximate integral with) between 5 and 100â€”the higher the value, the more accurate, but the more computationally expensive.\n",
    "<img width=\"700\" alt=\"image\" src=\"https://github.com/user-attachments/assets/1f41aaeb-df8a-4d06-9191-de7853f1bfc0\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c886dfb-5931-4d4e-a10f-042dd2c29649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "widget.render(height=600, open_in_new_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfb575-db8d-4dbc-afd0-f364ce35a03f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Optional) Directly Call Interpretability modules\n",
    "\n",
    "You may want to get saliency values directly outside of the LIT UI. You can call each component using the same model object.\n",
    "\n",
    "For example, for Integrated Gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34f59f-3f66-4038-816a-6d2ac19d391e",
   "metadata": {
    "id": "cd34f59f-3f66-4038-816a-6d2ac19d391e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lit_nlp.components import gradient_maps\n",
    "\n",
    "ig = gradient_maps.IntegratedGradients()\n",
    "\n",
    "saliency = ig.run(\n",
    "    ImdbSentimentData(test_ds).examples[:1],\n",
    "    BertSentimentModel(classifier),\n",
    "    ImdbSentimentData(test_ds),\n",
    ")\n",
    "saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b04100-1860-4b30-b06b-8cf8448a6651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        saliency[0][\"input_emb_grad\"].tokens,\n",
    "        saliency[0][\"input_emb_grad\"].salience,\n",
    "    ],\n",
    "    index=[\"token\", \"salience\"],\n",
    ")\n",
    "\n",
    "salience_series = saliency[0][\"input_emb_grad\"].salience\n",
    "abs_max = max(abs(salience_series.max()), abs(salience_series.min()))\n",
    "df.style.background_gradient(\n",
    "    axis=1,\n",
    "    gmap=df.loc[\"salience\", :].apply(pd.to_numeric),\n",
    "    vmin=-abs_max,\n",
    "    vmax=abs_max,\n",
    "    cmap=\"seismic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae7ab4-5dff-4570-a387-acb7751c4787",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What's next?\n",
    "\n",
    "To learn more about LIT and AI Explanations, check out the resources here.\n",
    "\n",
    "- [LIT documentation](https://pair-code.github.io/lit/)\n",
    "- [LIT github](https://github.com/PAIR-code/lit)\n",
    "- [Integrated gradients paper](https://arxiv.org/abs/1703.01365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312e6d3-7339-4bea-b010-3bb64e1f5a10",
   "metadata": {},
   "source": [
    "Copyright 2025 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f517a13-8039-4461-86cb-ab9527dc8950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
