{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Keras Functional API and Feature Engineering\n",
    "\n",
    "**Learning Objectives**\n",
    "  1. Understand embeddings and how to create them with preprocessing layers\n",
    "  1. Understand wide and deep models and when to use them\n",
    "  1. Understand the Keras functional API and how to build a wide and deep model with it\n",
    "  1. Understand how to apply custom Feature Engineering method using Lambda layers.\n",
    "  \n",
    "### Introduction\n",
    "\n",
    "In the last notebook, we learned about the Keras Sequential API. The [Keras Functional API](https://www.tensorflow.org/guide/keras#functional_api) provides an alternative way of building models that is more flexible. With the Functional API, we can build models with more complex topologies, multiple input or output layers, shared layers or non-sequential data flows (e.g. residual layers).\n",
    "\n",
    "In this notebook, first, we'll use what we learned about preprocessing layers to build a Wide & Deep model, and then apply additioanl feature engineering method using Lambda layers.\n",
    "\n",
    "## Building Wide & Deep models in Keras Functional API\n",
    "Recall that the idea behind Wide & Deep models is to join the two methods of learning through memorization and generalization by making a wide linear model and a deep learning model to accommodate both. You can have a look at the original research paper here: [Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792).\n",
    "\n",
    "<img src='assets/wide_deep.png' width='80%'>\n",
    "<sup>(image: https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)</sup>\n",
    "\n",
    "The wide part of the model is associated with the memory element. In this case, we train a linear model with a wide set of crossed features and learn the correlation of this related data with the assigned label. The deep part of the model is associated with the generalization element where we use embedding vectors for features. The best embeddings are then learned through the training process. While both of these methods can work well alone, Wide & Deep models excel by combining these techniques together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import (\n",
    "    CategoryEncoding,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Discretization,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    HashedCrossing,\n",
    "    Input,\n",
    "    Lambda,\n",
    ")\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data \n",
    "\n",
    "We will use the taxifare dataset, using the CSV files that we created in the first notebook of this sequence. Those files have been saved into `../data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tf.data to read the CSV files\n",
    "\n",
    "We wrote these functions for reading data from the CSV files above in the [previous notebook](2_dataset_api.ipynb). For this lab we will also include some additional engineered features in our model. \n",
    "\n",
    "Note that we parse the feature in a tuple, so that we can separately pass them to differnt preprocessing flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_csv(row):\n",
    "    ds = tf.strings.split(row, \",\")\n",
    "    # Label: fare_amount\n",
    "    label = tf.strings.to_number(ds[0])\n",
    "    # Feature: pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude\n",
    "    feature = tf.strings.to_number(ds[2:6])  # use some features only\n",
    "    # Passing feature in tuple so that we can handle them separately.\n",
    "    return (feature[0], feature[1], feature[2], feature[3]), label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size, mode=\"eval\"):\n",
    "    ds = tf.data.TextLineDataset(pattern)\n",
    "    ds = ds.map(parse_csv).repeat()\n",
    "    if mode == \"train\":\n",
    "        ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Wide and Deep model in Keras\n",
    "\n",
    "To build a wide-and-deep network, we connect the sparse (i.e. wide) features directly to the output node, but pass the dense (i.e. deep) features through a set of fully connected layers. Here's how that model architecture looks using the Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inputs\n",
    "First, we'll create our input object using [keras.Input](https://keras.io/api/layers/core_layers/input/). Note that we define separate Input gates for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_COLS = [\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "]\n",
    "\n",
    "inputs = {\n",
    "    colname: Input(name=colname, shape=(1,), dtype=\"float32\")\n",
    "    for colname in INPUT_COLS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can connect the layers one by one, and define a preprocessing flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnn_hidden_units = [32, 8]\n",
    "NBUCKETS = 16\n",
    "\n",
    "# Define Bucketization boundaries\n",
    "latbuckets = np.linspace(start=40.5, stop=41.0, num=NBUCKETS).tolist()\n",
    "lonbuckets = np.linspace(start=-74.2, stop=-73.7, num=NBUCKETS).tolist()\n",
    "\n",
    "# Bucketization with Discretization layer\n",
    "plon = Discretization(lonbuckets, name=\"plon_bkt\")(inputs[\"pickup_longitude\"])\n",
    "plat = Discretization(latbuckets, name=\"plat_bkt\")(inputs[\"pickup_latitude\"])\n",
    "dlon = Discretization(lonbuckets, name=\"dlon_bkt\")(inputs[\"dropoff_longitude\"])\n",
    "dlat = Discretization(latbuckets, name=\"dlat_bkt\")(inputs[\"dropoff_latitude\"])\n",
    "\n",
    "# Feature Cross with HashedCrossing layer\n",
    "p_fc = HashedCrossing(num_bins=(NBUCKETS + 1) ** 2, name=\"p_fc\")((plon, plat))\n",
    "d_fc = HashedCrossing(num_bins=(NBUCKETS + 1) ** 2, name=\"d_fc\")((dlon, dlat))\n",
    "pd_fc = HashedCrossing(num_bins=(NBUCKETS + 1) ** 4, name=\"pd_fc\")((p_fc, d_fc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embedding with Embedding layer\n",
    "pd_embed = Embedding(\n",
    "    input_dim=(NBUCKETS + 1) ** 4, output_dim=10, name=\"pd_embed\"\n",
    ")(pd_fc)\n",
    "\n",
    "# Concatenate and define inputs for deep network\n",
    "deep = Concatenate(name=\"deep_input\")(\n",
    "    [\n",
    "        inputs[\"pickup_longitude\"],\n",
    "        inputs[\"pickup_latitude\"],\n",
    "        inputs[\"dropoff_longitude\"],\n",
    "        inputs[\"dropoff_latitude\"],\n",
    "        Flatten(name=\"flatten_embedding\")(pd_embed),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Add hidden Dense layers\n",
    "for i, num_nodes in enumerate(dnn_hidden_units, start=1):\n",
    "    deep = Dense(num_nodes, activation=\"relu\", name=f\"hidden_{i}\")(deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Onehot Encoding with CategoryEncoding layer\n",
    "p_onehot = CategoryEncoding(num_tokens=(NBUCKETS + 1) ** 2, name=\"p_onehot\")(\n",
    "    p_fc\n",
    ")\n",
    "d_onehot = CategoryEncoding(num_tokens=(NBUCKETS + 1) ** 2, name=\"d_onehot\")(\n",
    "    d_fc\n",
    ")\n",
    "pd_onehot = CategoryEncoding(num_tokens=(NBUCKETS + 1) ** 4, name=\"pd_onehot\")(\n",
    "    pd_fc\n",
    ")\n",
    "\n",
    "# Concatenate and define inputs for wide network\n",
    "wide = Concatenate(name=\"wide_input\")([p_onehot, d_onehot, pd_onehot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate Wide & Deep model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate wide & deep networks\n",
    "concat = Concatenate(name=\"concatenate\")([deep, wide])\n",
    "\n",
    "# Define the final output layer\n",
    "output = Dense(1, activation=None, name=\"output\")(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define our custom RMSE evaluation metric and build our wide and deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    squared_error = tf.keras.ops.square(y_pred[:, 0] - y_true)\n",
    "    return tf.keras.ops.sqrt(tf.keras.ops.mean(squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the input and output of the entire model, and compile it.  We can also use `plot_model` to see a diagram of the model we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=list(inputs.values()), outputs=output)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=False, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set up our training variables, create our datasets for training and validation, and train our model.\n",
    "\n",
    "(We refer you to the blog post [ML Design Pattern #3: Virtual Epochs](https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730) for further details on why we express the training in terms of `NUM_TRAIN_EXAMPLES` and `NUM_EVALS` and why, in this training code, the number of epochs is really equal to the number of evaluations we perform.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Wide and Deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 10  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 10  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 1000  # enough to get a reasonable sample\n",
    "\n",
    "trainds = create_dataset(\n",
    "    pattern=\"../data/taxi-train.csv\", batch_size=BATCH_SIZE, mode=\"train\"\n",
    ")\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern=\"../data/taxi-valid.csv\", batch_size=BATCH_SIZE, mode=\"eval\"\n",
    ").take(NUM_EVAL_EXAMPLES // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "OUTDIR = \"./taxi_trained\"\n",
    "shutil.rmtree(path=OUTDIR, ignore_errors=True)  # start fresh each time\n",
    "\n",
    "history = model.fit(\n",
    "    x=trainds,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=NUM_EVALS,\n",
    "    validation_data=evalds,\n",
    "    callbacks=[TensorBoard(OUTDIR)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, we can examine the history to see how the RMSE changes through training on the training set and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_COLS = [\"rmse\", \"val_rmse\"]\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Model Performance Using Feature Engineering \n",
    "\n",
    "We now improve our model's performance by creating new feature engineerings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Custom Feature Engineering Method\n",
    "The dataset contains information regarding the pickup and drop off coordinates. However, there is no information regarding the distance between the pickup and drop off points. \n",
    "\n",
    "Therefore, we create a new feature that calculates the distance between each pair of pickup and drop off points. We can do this using the Euclidean Distance, which is the straight-line distance between any two coordinate points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclidean(params):\n",
    "    lon1, lat1, lon2, lat2 = params\n",
    "    londiff = lon2 - lon1\n",
    "    latdiff = lat2 - lat1\n",
    "    return tf.sqrt(londiff * londiff + latdiff * latdiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can later use this custom function using a [Lambda layer](https://keras.io/api/layers/core_layers/lambda/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Stateful Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    \"fare_amount\",\n",
    "    \"pickup_datetime\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"passenger_count\",\n",
    "    \"key\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"../data/taxi-train.csv\", names=CSV_COLUMNS)\n",
    "lat_values = pd.concat(\n",
    "    [df[\"pickup_latitude\"], df[\"dropoff_latitude\"]], ignore_index=True\n",
    ").to_numpy()\n",
    "lon_values = pd.concat(\n",
    "    [df[\"pickup_longitude\"], df[\"dropoff_longitude\"]], ignore_index=True\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lat_scaler = keras.layers.Normalization(axis=None)\n",
    "lon_scaler = keras.layers.Normalization(axis=None)\n",
    "\n",
    "lat_scaler.adapt(lat_values)\n",
    "lon_scaler.adapt(lon_values)\n",
    "\n",
    "print(\n",
    "    f\"Computed statistics for latitude:\\nmean: {lat_scaler.mean}, variance: {lat_scaler.variance}, \"\n",
    ")\n",
    "print(f\"+++++\")\n",
    "print(\n",
    "    f\"Computed statistics for latitude:\\nmean: {lon_scaler.mean}, variance: {lon_scaler.variance}, \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create our DNN model now with custom Lambda layers.\n",
    "\n",
    "Here we define:\n",
    "- Input objects\n",
    "- A custom Preprocessing with Lambda layers for euclidean function\n",
    "- Other feature engineering logics with predefined preprocessing layers\n",
    "- DNN model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_COLS = [\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "]\n",
    "\n",
    "# input layer is all float\n",
    "inputs = {\n",
    "    colname: Input(name=colname, shape=(1,), dtype=\"float32\")\n",
    "    for colname in INPUT_COLS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Preprocessing Layers and Custom Lambda Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NBUCKETS = 16\n",
    "\n",
    "latbuckets = np.linspace(start=-5, stop=5, num=NBUCKETS).tolist()\n",
    "lonbuckets = np.linspace(start=-5, stop=5, num=NBUCKETS).tolist()\n",
    "\n",
    "# Normalize longitude\n",
    "scaled_plon = lon_scaler(inputs[\"pickup_longitude\"])\n",
    "scaled_dlon = lon_scaler(inputs[\"dropoff_longitude\"])\n",
    "\n",
    "# Normalize latitude\n",
    "scaled_plat = lat_scaler(inputs[\"pickup_latitude\"])\n",
    "scaled_dlat = lat_scaler(inputs[\"dropoff_latitude\"])\n",
    "\n",
    "# Lambda layer for the custom euclidean function\n",
    "euclidean_distance = Lambda(euclidean, name=\"euclidean\")(\n",
    "    [scaled_plon, scaled_plat, scaled_dlon, scaled_dlat]\n",
    ")\n",
    "\n",
    "# Discretization\n",
    "plon = Discretization(lonbuckets, name=\"plon_bkt\")(scaled_plon)\n",
    "plat = Discretization(latbuckets, name=\"plat_bkt\")(scaled_plat)\n",
    "dlon = Discretization(lonbuckets, name=\"dlon_bkt\")(scaled_dlon)\n",
    "dlat = Discretization(latbuckets, name=\"dlat_bkt\")(scaled_dlat)\n",
    "\n",
    "\n",
    "# Feature Cross with HashedCrossing layer\n",
    "p_fc = HashedCrossing(num_bins=(NBUCKETS + 1) ** 2, name=\"p_fc\")((plon, plat))\n",
    "d_fc = HashedCrossing(num_bins=(NBUCKETS + 1) ** 2, name=\"d_fc\")((dlon, dlat))\n",
    "pd_fc = HashedCrossing(num_bins=(NBUCKETS + 1) ** 4, name=\"pd_fc\")((p_fc, d_fc))\n",
    "\n",
    "# Embedding with Embedding layer\n",
    "pd_embed = Flatten()(\n",
    "    Embedding(input_dim=(NBUCKETS + 1) ** 4, output_dim=10, name=\"pd_embed\")(\n",
    "        pd_fc\n",
    "    )\n",
    ")\n",
    "\n",
    "deep = Concatenate()([euclidean_distance, pd_embed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define a Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnn_hidden_units = [32, 8]\n",
    "\n",
    "# Add hidden Dense layers\n",
    "for i, num_nodes in enumerate(dnn_hidden_units, start=1):\n",
    "    deep = Dense(num_nodes, activation=\"relu\", name=f\"hidden_{i}\")(deep)\n",
    "\n",
    "# final output is a linear activation because this is regression\n",
    "output = Dense(1, activation=\"linear\", name=\"fare\")(deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=list(inputs.values()), outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our model architecture has changed now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, \"dnn_model_engineered.png\", show_shapes=False, rankdir=\"LR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see this new model is applying various feature engineering techniques not only with predefined preprocessing layers but also with custom Lambda layers.<br>\n",
    "All the preprocessed Tensors are combined in the `Concatenate` layer, and after that we can stack Dense layers.\n",
    "\n",
    "Now let's train this new model and see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 10  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 10  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainds = create_dataset(\n",
    "    pattern=\"../data/taxi-train.csv\", batch_size=BATCH_SIZE, mode=\"train\"\n",
    ")\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern=\"../data/taxi-valid.csv\", batch_size=BATCH_SIZE, mode=\"eval\"\n",
    ").take(NUM_EVAL_EXAMPLES // BATCH_SIZE)\n",
    "\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "history = model.fit(\n",
    "    trainds,\n",
    "    validation_data=evalds,\n",
    "    epochs=NUM_EVALS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_COLS = [\"rmse\", \"val_rmse\"]\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2025 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
