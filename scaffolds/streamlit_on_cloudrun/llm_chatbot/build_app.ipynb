{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7fcfe6-f8c8-46e2-b5d1-1c8354697664",
   "metadata": {},
   "source": [
    "# Deploying a Streamlit Chatbot App on Google Cloud Run\n",
    "\n",
    "This guide provides you with the scaffold and steps to build a simple chatbot application with Gemini using Streamlit.\n",
    "\n",
    "\n",
    "### What is Streamlit?\n",
    "[Streamlit](https://streamlit.io/) is an open-source Python library that's become the go-to tool for quickly creating interactive web applications, especially for data science and machine learning projects.  Streamlit's intuitive design makes it easy to build powerful apps with minimal code.\n",
    "\n",
    "Check out the amazing examples in the [Streamlit Gallery](https://streamlit.io/gallery) to see the wide range of applications you can create. From data dashboards and visualizations to machine learning demos and interactive tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3a625-c626-4fad-b6b0-794f3a937e27",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll setup a few variables to interact with Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad47080-ad70-4a5d-a1c3-72a5ea72b841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8b040-a64a-4925-bd96-123185f4c66f",
   "metadata": {},
   "source": [
    "## Build a streamlit application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441f6b6-bca9-4aad-95f9-84a53fc2119a",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "First, we'll import the necessary Python libraries, including Streamlit itself, as well as `vertexai` to interact with Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faaa4f9-7c12-4d59-bb00-d78afd65aecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\"\"\"Streamlit Chatbot App\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import streamlit as st\n",
    "import vertexai\n",
    "from vertexai.generative_models import Content, GenerativeModel, Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d32d88-ae75-4b73-9856-f15aa26f7cfc",
   "metadata": {},
   "source": [
    "### Add text elements\n",
    "Streamlit eventually renders a web page, but we can simply use Python modules to define the visual and behavior of it.\n",
    "\n",
    "We'll start by configuring some metadata for our app.\n",
    "\n",
    "- [`st.set_page_config`](https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config) lets us customize aspects like the page title and favicon (the little icon that appears in your browser tab).\n",
    "\n",
    "Streamlit provides a variety of ways to display text content:\n",
    "- [`st.title`](https://docs.streamlit.io/develop/api-reference/text/st.title) is used to add a main heading to our page.\n",
    "- You can also use [`st.header`](https://docs.streamlit.io/develop/api-reference/text/st.header) and [`st.subheader`](https://docs.streamlit.io/develop/api-reference/text/st.subheader) for smaller headings.\n",
    "- [`st.text`](https://docs.streamlit.io/develop/api-reference/text/st.text) is for displaying plain text.\n",
    "- [`st.markdown`](https://docs.streamlit.io/develop/api-reference/text/st.markdown) lets you add formatted text using Markdown syntax.\n",
    "For more options, you can check the Streamlit documentation for [other text elements](https://docs.streamlit.io/develop/api-reference/text).\n",
    "\n",
    "Streamlit also offer a \"swiss-army knife\" command called [`st.write`](https://docs.streamlit.io/develop/api-reference/write-magic/st.write). It can handle many types of content, including text, DataFrames (tables of data), Matplotlib plots, and even Keras machine learning models.\n",
    "\n",
    "Also, here we define a few global variables that we'll use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb068578-b530-4baa-a57d-b06571696076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "st.set_page_config(page_title=\"Chat with Gemini\", page_icon=\"♊\")\n",
    "\n",
    "st.title(\"Chat with Gemini\")\n",
    "\n",
    "st.markdown(\"Welcome to this simple web application to chat with Gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227b203-99f0-4113-bbc7-1cb091f572c8",
   "metadata": {},
   "source": [
    "And let's setup some variables.\n",
    "\n",
    "The environment variables (`GCP_PROJECT` and `GCP_REGION`) can be set later when we deploy the app to Cloud Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a8c52-48f2-44c5-8ce2-e0a433bf95c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "PROJECT_ID = os.environ.get(\"GCP_PROJECT\")\n",
    "LOCATION = os.environ.get(\"GCP_REGION\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "if \"gemini_model\" not in st.session_state:\n",
    "    st.session_state[\"gemini_model\"] = \"gemini-1.5-flash-001\"\n",
    "\n",
    "model = GenerativeModel(st.session_state[\"gemini_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fd845-f835-491b-874f-584e58f52f19",
   "metadata": {},
   "source": [
    "### Setup session state\n",
    "Remember, Streamlit reruns the code from the top to the bottom every time an event happens.<br>\n",
    "[Session State](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state) is a way to share variables between these reruns for each user session. We can save values in a key-value format in `st.session_state`.\n",
    "\n",
    "Since this is a chatbot app, we have to keep chat histories. Let's make a `\"messages\"` key and save histories as a list.<br>\n",
    "If the `\"messages\"` key is not present in the session state (when you open the page first), we initialize the list. If the key is already created, we iterate the list and show each message on the page.\n",
    "\n",
    "For chatbot apps, we can use the [`st.chat_message`](https://docs.streamlit.io/develop/api-reference/chat/st.chat_message) container to show each message on the page.<br>\n",
    "We can use `with` notation to add elements to the returned container or simply call methods directly on the returned object like:\n",
    "\n",
    "```python\n",
    "for message in st.session_state.messages:\n",
    "    message = st.chat_message(name=message[\"role\"], avatar=message[\"avatar\"])\n",
    "    message.markdown(message[\"content\"])\n",
    "```\n",
    "\n",
    "The chat_message takes two arguments:\n",
    "- `name`: The name of the message author. It can be \"human\"/\"user\" or \"ai\"/\"assistant\" to enable preset styling and avatars.\n",
    "- `avatar`: The avatar shown next to the message. \n",
    "  - You can specify images supported by [st.image](https://docs.streamlit.io/develop/api-reference/media/st.image).\n",
    "  - Some emoji formats are supported. See [the document](https://docs.streamlit.io/develop/api-reference/chat/st.chat_message) for the details.\n",
    "  - If it is None (default), the icon will be determined by name (\"user\"/\"human\" or \"ai\"/\"assistant\")\n",
    "  \n",
    "We pass these arguments from each message dictionary we'll add later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24219edd-cd10-432d-aa4a-7be9251f5487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat messages from history on app rerun\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(name=message[\"role\"], avatar=message[\"avatar\"]):\n",
    "        st.markdown(message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81422c28-68cc-4a9a-a593-9700366e0276",
   "metadata": {},
   "source": [
    "Let's define the helper functions we'll use later.\n",
    "\n",
    "The `generate_response` function starts a chat with Gemini using a history in the session.\n",
    "\n",
    "The `stream` function will be used later to write the Gemini response in a stream for a more interactive user experience, instead of writing all the responses simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538bc0a-c486-48d3-9742-a84c6b07fca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "\n",
    "def generate_response(input_text):\n",
    "    chat = model.start_chat(\n",
    "        history=[\n",
    "            Content(role=m[\"role\"], parts=[Part.from_text(m[\"content\"])])\n",
    "            for m in st.session_state.messages[:-1]\n",
    "        ]\n",
    "    )\n",
    "    return chat.send_message(input_text)\n",
    "\n",
    "\n",
    "def stream(text):\n",
    "    for word in text.split(\" \"):\n",
    "        yield word + \" \"\n",
    "        time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4bd06-5fe9-4f2b-bbb7-968a646bbf91",
   "metadata": {},
   "source": [
    "### Define the chat iteration\n",
    "\n",
    "Let's define the iteration of chat interactions, which has these steps:\n",
    "1. Show the user input on the page. We use `st.chat_message` as `\"user\"` name and `st.write` to add a message.\n",
    "2. Add the user input to the message history in the session state.\n",
    "3. Call Gemini and write the response. Here, we use `\"assistant\"` as the name and specify the Gemini icon as the avatar. Also, use `st.write_stream` with the `stream` function to show the response in a stream.\n",
    "4. Add the Gemini response to the message history in the session state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55490f20-f594-4648-a7ae-d84fd23520c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "\n",
    "# React to user input\n",
    "if prompt := st.chat_input(\"Write a promt\"):\n",
    "    # 1. Write the user message\n",
    "    with st.chat_message(name=\"user\", avatar=None):\n",
    "        st.write(prompt)\n",
    "    # 2. Add user message to message history\n",
    "    st.session_state.messages.append(\n",
    "        {\"role\": \"user\", \"content\": prompt, \"avatar\": None}\n",
    "    )\n",
    "\n",
    "    # 3. Call Gemini and write the response\n",
    "    with st.chat_message(name=\"assistant\", avatar=\"assets/gemini-icon.png\"):\n",
    "        response = generate_response(prompt)\n",
    "        st.write_stream(stream(response.text))\n",
    "    # 4. Add Gemini response to message history\n",
    "    st.session_state.messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.text,\n",
    "            \"avatar\": \"assets/gemini-icon.png\",\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c0808-5299-4527-9df5-1492beb7d9d5",
   "metadata": {},
   "source": [
    "## Deploying the App on Cloud Run\n",
    "Our Streamlit application is ready! Let's deploy it to Google Cloud Run, a serverless platform designed to run containerized applications seamlessly.\n",
    "\n",
    "### Defining Dockerfile and Dependencies\n",
    "To containerize our app for Cloud Run, we define `requirements.txt` and `Dockerfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5418e-937e-4c34-9996-3e96f51bf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "streamlit==1.37.0\n",
    "google-cloud-aiplatform==1.63.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4c8a7-7f63-450d-8301-4fa4af53ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.10.14\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt /app\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY assets /app/assets\n",
    "COPY app.py /app\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "CMD streamlit run --server.port 8080 --server.enableCORS false app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d25e8-7171-47b5-ab9e-5053fad20b6a",
   "metadata": {},
   "source": [
    "**Note: We've split the `COPY` command into multiple lines, each copying different files. Although this is not required, this is a crucial optimization for Docker's caching mechanism.<br> If you make changes only to app.py, the next time you build the image, Docker will reuse the cached layers for the dependency installation and other files, speeding up the build process significantly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e22c5-e73b-42d3-97c9-bed2011b2812",
   "metadata": {},
   "source": [
    "### Building and Pushing the Container to Artifact Registry\n",
    "Now that we have our `Dockerfile`, we can build the Docker image of our Streamlit app and push it to Google Cloud's Artifact Registry. \n",
    "Artifact Registry offers a secure and scalable way to store your container images.\n",
    "\n",
    "First, we'll create a new repository in Artifact Registry to house our container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e950b-396a-4fd5-83c2-4ec400d0611f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STREAMLIT_ARTIFACT_REG_REPO = \"gemini-chatbot-app\"\n",
    "os.environ[\"STREAMLIT_ARTIFACT_REG_REPO\"] = STREAMLIT_ARTIFACT_REG_REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85dcad-4dc1-4fb2-926c-bf19826d57e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gcloud artifacts repositories describe $STREAMLIT_ARTIFACT_REG_REPO \\\n",
    "       --location=$REGION > /dev/null 2>&1; then\n",
    "    gcloud artifacts repositories create $STREAMLIT_ARTIFACT_REG_REPO \\\n",
    "        --project=$PROJECT --location=$REGION --repository-format=docker\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a7418-ad96-420f-bfdc-06f83a142df5",
   "metadata": {},
   "source": [
    "### Defining cloudbuild.yaml for Cloud Build\n",
    "We'll use Google Cloud Build to automate the process of building our Docker image and pushing it to Artifact Registry. \n",
    "\n",
    "Cloud Build is a serverless CI/CD platform that lets you define build steps in a configuration file called cloudbuild.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec83318-31ac-4d2b-b4c2-10028b2b9c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTAINER_PATH = (\n",
    "    f\"us-central1-docker.pkg.dev/{PROJECT}/{STREAMLIT_ARTIFACT_REG_REPO}/app\"\n",
    ")\n",
    "os.environ[\"CONTAINER_PATH\"] = CONTAINER_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67075a-0864-429b-8be8-0fdf052a70c9",
   "metadata": {},
   "source": [
    "Here's a cloudbuild.yaml file that incorporates caching to make our builds faster:\n",
    "\n",
    "1. **Pull Existing Image**: The first step attempts to pull the latest version of your Docker image from Artifact Registry. Here we use `bash -c` command as the entrypoint so that the job can ignore and proceed even if this step fails in the first run.\n",
    "2. **Build with Caching**: The second step builds the new image. `--cache-from` flag tells Docker to use the layers from the pulled image as a cache, speeding up the build if there are no changes to those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82177b1a-7d4f-4a4e-9fb6-409a7c868414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile cloudbuild.yaml\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  entrypoint: 'bash'\n",
    "  args: ['-c', 'docker pull ${_CONTAINER_PATH}:latest || exit 0']\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [\n",
    "            'build',\n",
    "            '-t', '${_CONTAINER_PATH}:latest',\n",
    "            '--cache-from', '${_CONTAINER_PATH}:latest',\n",
    "            '.'\n",
    "        ]\n",
    "images: ['${_CONTAINER_PATH}:latest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c4542-ec7e-497a-b3b4-4d7dabf68561",
   "metadata": {},
   "source": [
    "### Building the Container Image\n",
    "\n",
    "With our cloudbuild.yaml file defined, we can now instruct Cloud Build to construct our Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b54f0-8e7a-4a5c-8fb0-fb684e944676",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --config cloudbuild.yaml --region $REGION . --substitutions _CONTAINER_PATH={CONTAINER_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212e426-57d5-4f5b-93a4-4295344cf0b9",
   "metadata": {},
   "source": [
    "### Deploying to Cloud Run\n",
    "With our container image stored in Artifact Registry is ready, we're all set to deploy our Streamlit app to Cloud Run.\n",
    "\n",
    "You can also consider incorporating this command into the `cloudbuild.yaml` we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a852ea-cc32-4a63-8838-e97ba4b8bbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"gemini-chatbot-app\"\n",
    "os.environ[\"APP_NAME\"] = APP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64fe98-c1d4-4454-b1b8-f3a6800e4b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 'Deploying the application to Cloud Run...'\n",
    "gcloud run deploy $APP_NAME \\\n",
    "  --image $CONTAINER_PATH:latest --min-instances 1 --max-instances 1 --cpu 1 \\\n",
    "  --memory 4Gi --region us-central1 \\\n",
    "  --update-env-vars GCP_PROJECT=$PROJECT,GCP_REGION=$REGION > /dev/null 2>&1 && \\\n",
    "echo 'Deployment Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf51f5-6703-4a7f-aebc-ac32dfda24eb",
   "metadata": {},
   "source": [
    "### Connect to Cloud Run app via Cloud Shell\n",
    "\n",
    "\n",
    "You have a lot of flexibility when it comes to configuring access to your Cloud Run service. You can even [make it publicly accessible](https://cloud.google.com/run/docs/authenticating/public) if you want to.\n",
    "\n",
    "However, for this example, let's see how to connect to your Cloud Run app securely from Cloud Shell using a proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9840eb6-5f47-45b3-a156-e7b96849d97e",
   "metadata": {},
   "source": [
    "Follow these steps to open the app from Cloud Shell.\n",
    "1. Run the next cell, copy the output `gcloud run services proxy ...`command.\n",
    "2. Open Cloud Shell, paste and run the command.\n",
    "3. In Cloud Shell, click the \"Web Preview\" button on the toolbar.\n",
    "4. Select \"Preview on port 8080\"\n",
    "5. A new browser tab or window will open, displaying your Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57754f-c055-4cb4-8175-338336e5bfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"gcloud run services proxy {APP_NAME} --project {PROJECT} --region {REGION}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9501082-c0b3-46ab-b55f-b825f41dacf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try the app\n",
    "Now you're ready to test your app.\n",
    "\n",
    "Enjoy conversations with Gemini!\n",
    "\n",
    "<img width=\"600\" alt=\"image\" src=\"https://github.com/user-attachments/assets/08a6421a-3b50-413d-a921-55476b03b1ec\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcef05-35c8-4d1a-bb4b-4217c1a84020",
   "metadata": {},
   "source": [
    "Copyright 2024 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b564ae4-6a39-46c7-a328-9c904da1412a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
