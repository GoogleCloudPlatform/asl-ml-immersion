{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d1c73d-9e36-45ec-9a6f-f49c23f90241",
   "metadata": {
    "id": "JAPoU8Sm5E6e",
    "tags": []
   },
   "source": [
    "# Getting Started with Agent2Agent (A2A) Protocol "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a950c3-1d5a-4ecf-bf41-724b0e8a26e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook guides you through deploying and managing a conversational AI agent to **Vertex AI Agent Engine**. \n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this notebook, you will understand how to:\n",
    "* Set up required configuration and deploy ADK **Agents** to **Vertex AI Agent Engine**.\n",
    "* Use the ADK **RemoteAgent** ans **RemoteSession** to execute agent interactions.\n",
    "* Use the Vertex AI SDK to Manage (list/update) and delete agents that you have deployed to Vertex AI Agent Engine.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## A Purchasing Concierge and Remote Seller Agent Interactions on Cloud Run and Agent Engine\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook guides you through deploying and managing a conversational AI agent to **Vertex AI Agent Engine**. \n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this notebook, you will understand how to:\n",
    "* Set up required configuration and deploy ADK **Agents** to **Vertex AI Agent Engine**.\n",
    "* Use the ADK **RemoteAgent** ans **RemoteSession** to execute agent interactions.\n",
    "* Use the Vertex AI SDK to Manage (list/update) and delete agents that you have deployed to Vertex AI Agent Engine.\n",
    "\n",
    "\n",
    "- Core structure of A2A Server\n",
    "- Core structure of A2A Client\n",
    "- Deploying agent service to Cloud Run\n",
    "- Deploying agent service to Agent Engine\n",
    "- How A2A Client connect to A2A Server\n",
    "- Request and Response structure on non-streaming connection\n",
    "\n",
    "\n",
    "\n",
    "Agent2Agent (A2A) protocol is designed to standardize communication between AI agents, particularly for those which are deployed in external systems. Previously, such protocols were established for Tools called Model Context Protocol (MCP) which is an emerging standard to connect LLMs with data and resources. A2A tries to complement MCP where A2A is focused on a different problem, while MCP focuses on lowering complexity to connect agents with tools and data, A2A focuses on how to enable agents to collaborate in their natural modalities. It allows agents to communicate as agents (or as users) instead of as tools; for example, enable back-and-forth communication when you want to order something.\n",
    "\n",
    "A2A is positioned to complement MCP, in the official documentation it is recommended that applications use MCP for tools and A2A for agents - represented by AgentCard ( We will discuss this later on ). The frameworks can then use A2A to communicate with their user, the remote agents, and other agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3de14-c85f-405a-b73a-12fc6c6944f5",
   "metadata": {},
   "source": [
    "## What you'll learn\n",
    "- Core structure of A2A Server\n",
    "- Core structure of A2A Client\n",
    "- Deploying agent service to Cloud Run\n",
    "- Deploying agent service to Agent Engine\n",
    "- How A2A Client connect to A2A Server\n",
    "- Request and Response structure on non-streaming connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404bdfc-deac-4f61-be58-54322c0813ce",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This lab needs a special kernel to run, please run the following cell.\n",
    "**NOTE: You can skip this step if you have already built the ADK Kernel from the previous Lab**"
   ]
  },
  {
   "cell_type": "code",
   "id": "31f3cb52-8c1a-4267-8f34-2492acf16c7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "!echo \"Kernel installation started.\"\n",
    "!cd ../../.. && make adk_mcp_a2a_kernel > /dev/null 2>&1\n",
    "!echo \"Kernel installation completed.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45397750-a9a4-4819-814e-818dc27cea0e",
   "metadata": {},
   "source": [
    "When it's completed, select the **`ADK MCP A2A Kernel`** on the top right before going forward in the notebook.<br>\n",
    "It may take ~1 minutes until the kernel is shown after the installation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ea330-5964-48ee-8946-266bda9edc52",
   "metadata": {},
   "source": [
    "## Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "809041fd-bf61-48bd-87ad-98f63476f5b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "import requests\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "012d1171-502a-4564-8bf8-bf237a90c6a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "REGION=\"us-central1\"\n",
    "BUCKET_NAME = f\"agent-deployment-a2a-{PROJECT_ID}-bucket\"\n",
    "STAGING_BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aaae1eef-7372-4f9e-b8d7-0dca1cebe308",
   "metadata": {
    "tags": []
   },
   "source": [
    "os.environ[\"REGION\"]=REGION\n",
    "os.environ[\"PROJECT_ID\"]=PROJECT_ID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "28260622-7cfd-475b-b0ae-2a4c579ab120",
   "metadata": {},
   "source": [
    "### Defining an auxiliary magic function\n",
    "\n",
    "The magic function `writefile` from Jupyter Notebook can only write the cell as is and could not unpack Python variables. Hence, we need to create an auxiliary magic function that can unpack Python variables and write them to a file."
   ]
  },
  {
   "cell_type": "code",
   "id": "19c731ac-85dd-40d4-9246-8acda78bb977",
   "metadata": {
    "tags": []
   },
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, \"a\") as f:\n",
    "        f.write(cell.format(**globals()))\n",
    "        \n",
    "@register_line_cell_magic\n",
    "def writeconfig(line, cell):\n",
    "    with open(line, \"w\") as f:\n",
    "        f.write(cell.format(**globals()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a942233-d489-44f5-89e5-60992c656dd4",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca7fdb-718a-463d-8b0e-cf40dc41b0f6",
   "metadata": {},
   "source": [
    "## Deploying A2A Server Remote Seller Agents to Cloud Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713808b-59ab-436f-a445-155a3845521d",
   "metadata": {},
   "source": [
    "In this step, we will deploy these two remote seller agents marked by the red box. \n",
    " - The burger agent will be powered by CrewAI agent framework \n",
    " - The pizza agent will be powered by Langgraph agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633403bc-3ca4-4840-9bde-25671baf29db",
   "metadata": {},
   "source": [
    "### Deploying Burger Seller Agent - A2A Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b989c9-32b5-4098-a2af-00e19925f810",
   "metadata": {},
   "source": [
    "#### The burger agent source code is under the remote_seller_agents/burger_agent directory.\n",
    "All files that exist under remote_seller_agents/burger_agent directory are already sufficient to deploy our agent to Cloud Run so that it can be accessible as a service. \n",
    "#### Run the following command to deploy it"
   ]
  },
  {
   "cell_type": "code",
   "id": "4cd6c977-6fc2-47e1-9141-cbf6124d7c32",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "gcloud run deploy burger-agent \\\n",
    "    --source remote_seller_agents/burger_agent \\\n",
    "    --port=8080 \\\n",
    "    --allow-unauthenticated \\\n",
    "    --min 1 \\\n",
    "    --max 1 \\\n",
    "    --region us-central1 \\\n",
    "    --update-env-vars GOOGLE_CLOUD_LOCATION=$REGION \\\n",
    "    --update-env-vars GOOGLE_CLOUD_PROJECT=$PROJECT_ID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "841d9c57-f432-4f9f-8e17-146ac7ae91d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# to get the service URL programmatically\n",
    "SERVICE_URL = !gcloud run services describe burger-agent \\\n",
    "  --platform managed \\\n",
    "  --region $REGION \\\n",
    "  --format \"value(status.url)\"\n",
    "\n",
    "BURGER_AGENT_SERVICE_URL = SERVICE_URL[0]\n",
    "print(BURGER_AGENT_SERVICE_URL)\n",
    "\n",
    "os.environ[\"BURGER_AGENT_HOST_OVERRIDE\"] = BURGER_AGENT_SERVICE_URL"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1338c573-e569-4353-b582-d59f63cb0104",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "gcloud run services update burger-agent --region=us-central1 --update-env-vars=HOST_OVERRIDE=$BURGER_AGENT_HOST_OVERRIDE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "669b22fa-7961-4571-8d64-df086b5b5109",
   "metadata": {
    "tags": []
   },
   "source": [
    "## "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b1468f2a-5942-4412-8a73-5a93a3ac0471",
   "metadata": {},
   "source": [
    "\n",
    "The a2a/.well-known/agent.json API is a crucial component of the Agent-to-Agent (A2A) communication protocol and\n",
    "provides a standardized way for one AI agent (a client) to discover the capabilities of another AI agent (a server). This is part of a broader web standard where the /.well-known/ URL path is used for discovering information about a site or service.\n",
    "When a client agent wants to interact with a server agent, it first makes a GET request to this specific URL. The server then responds with a JSON file that contains vital information about itself."
   ]
  },
  {
   "cell_type": "code",
   "id": "ede63a09-b463-4ec7-8c42-e26c21a111f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "res = requests.get(f'{BURGER_AGENT_SERVICE_URL}/.well-known/agent.json')\n",
    "print(json.dumps(json.loads(res.content), indent=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f858e8a1-d828-49a5-8739-9bb4a5c0c845",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7a7167d-ae83-4cfa-b6c7-1986a0471b6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "gcloud run deploy pizza-agent \\\n",
    "    --source remote_seller_agents/pizza_agent \\\n",
    "    --port=8080 \\\n",
    "    --allow-unauthenticated \\\n",
    "    --min 1 \\\n",
    "    --max 1 \\\n",
    "    --region us-central1 \\\n",
    "    --update-env-vars GOOGLE_CLOUD_LOCATION=$REGION \\\n",
    "    --update-env-vars GOOGLE_CLOUD_PROJECT=$PROJECT_ID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64e109fb-6f88-4c81-8551-4442e6e89e64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# to get the service URL programmatically\n",
    "PIZZA_AGENT_SERVICE_URL = !gcloud run services describe pizza-agent \\\n",
    "  --platform managed \\\n",
    "  --region $REGION \\\n",
    "  --format \"value(status.url)\"\n",
    "\n",
    "PIZZA_AGENT_SERVICE_URL = PIZZA_AGENT_SERVICE_URL[0]\n",
    "print(PIZZA_AGENT_SERVICE_URL)\n",
    "\n",
    "os.environ[\"PIZZA_AGENT_SERVICE_URL\"] = PIZZA_AGENT_SERVICE_URL"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57b801c1-f3e1-4be7-9350-743ed58e1acd",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "gcloud run services update pizza-agent --region=us-central1 --update-env-vars=HOST_OVERRIDE=$PIZZA_AGENT_SERVICE_URL"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49695909-d7c9-4b1c-a9e5-064b0616355b",
   "metadata": {
    "tags": []
   },
   "source": [
    "res = requests.get(f'{PIZZA_AGENT_SERVICE_URL}/.well-known/agent.json')\n",
    "print(json.dumps(json.loads(res.content), indent=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30b12666-a42f-43f4-b6dd-e500c5ef6bba",
   "metadata": {},
   "source": [
    "**Checking for the existence of BUCKET. Creating it if it doesn't exist:**"
   ]
  },
  {
   "cell_type": "code",
   "id": "1da16f98-0754-44e3-91af-6cbf1e1ba511",
   "metadata": {
    "tags": []
   },
   "source": [
    "!gsutil ls $STAGING_BUCKET_URI || gsutil mb -l $LOCATION $STAGING_BUCKET_URI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f2744c4-ed26-43bf-8790-d410087d77ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writeconfig .env\n",
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "GOOGLE_GENAI_USE_VERTEXAI=TRUE\n",
    "PIZZA_SELLER_AGENT_URL={PIZZA_AGENT_SERVICE_URL}\n",
    "BURGER_SELLER_AGENT_URL={BURGER_AGENT_SERVICE_URL}\n",
    "GOOGLE_CLOUD_PROJECT={PROJECT_ID}\n",
    "GOOGLE_CLOUD_LOCATION={REGION}\n",
    "STAGING_BUCKET={STAGING_BUCKET_URI}\n",
    "AGENT_ENGINE_RESOURCE_NAME=your-agent-engine-resource-name"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd0ce3b9-74e6-45a4-be4d-9eb9d405c1e5",
   "metadata": {},
   "source": [
    "### Check .env file content"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ae7c10f-0123-499a-a1df-9cc5570b8fed",
   "metadata": {
    "tags": []
   },
   "source": [
    "!cat .env"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73c2440c-4ff3-42e5-8c23-0d781725db6c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef53f132-4b27-46f6-a3e7-1aa8fbafa15c",
   "metadata": {
    "tags": []
   },
   "source": [
    "ADK_AGENT_PYTHON = './purchasing_concierge/purchasing_agent.py'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f6d7a8c-e36f-4871-9e22-215bed9cfdbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writefile {ADK_AGENT_PYTHON}\n",
    "\"\"\"\n",
    "Copyright 2025 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "from typing import List\n",
    "import httpx\n",
    "\n",
    "from google.adk import Agent\n",
    "from google.adk.agents.readonly_context import ReadonlyContext\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from .remote_agent_connection import RemoteAgentConnections\n",
    "\n",
    "from a2a.client import A2ACardResolver\n",
    "from a2a.types import (\n",
    "    AgentCard,\n",
    "    MessageSendParams,\n",
    "    Part,\n",
    "    SendMessageRequest,\n",
    "    SendMessageResponse,\n",
    "    SendMessageSuccessResponse,\n",
    "    Task,\n",
    ")\n",
    "\n",
    "\n",
    "class PurchasingAgent:\n",
    "    \"\"\"The purchasing agent.\n",
    "\n",
    "    This is the agent responsible for choosing which remote seller agents to send\n",
    "    tasks to and coordinate their work.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        remote_agent_addresses: List[str],\n",
    "    ):\n",
    "        self.remote_agent_connections: dict[str, RemoteAgentConnections] = {}\n",
    "        self.remote_agent_addresses = remote_agent_addresses\n",
    "        self.cards: dict[str, AgentCard] = {}\n",
    "        self.agents = \"\"\n",
    "        self.a2a_client_init_status = False\n",
    "\n",
    "    def create_agent(self) -> Agent:\n",
    "        return Agent(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            name=\"purchasing_agent\",\n",
    "            instruction=self.root_instruction,\n",
    "            before_model_callback=self.before_model_callback,\n",
    "            before_agent_callback=self.before_agent_callback,\n",
    "            description=(\n",
    "                \"This purchasing agent orchestrates the decomposition of the user purchase request into\"\n",
    "                \" tasks that can be performed by the seller agents.\"\n",
    "            ),\n",
    "            tools=[\n",
    "                self.send_task,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def root_instruction(self, context: ReadonlyContext) -> str:\n",
    "        current_agent = self.check_active_agent(context)\n",
    "        return f\"\"\"You are an expert purchasing delegator that can delegate the user product inquiry and purchase request to the\n",
    "appropriate seller remote agents.\n",
    "\n",
    "Execution:\n",
    "- For actionable tasks, you can use `send_task` to assign tasks to remote agents to perform.\n",
    "- When the remote agent is repeatedly asking for user confirmation, assume that the remote agent doesn't have access to user's conversation context. \n",
    "    So improve the task description to include all the necessary information related to that agent\n",
    "- Never ask user permission when you want to connect with remote agents. If you need to make connection with multiple remote agents, directly\n",
    "    connect with them without asking user permission or asking user preference\n",
    "- Always show the detailed response information from the seller agent and propagate it properly to the user. \n",
    "- If the remote seller is asking for confirmation, rely the confirmation question with proper and necessary information to the user if the user haven't do so. \n",
    "- If the user already confirmed the related order in the past conversation history, you can confirm on behalf of the user\n",
    "- Do not give irrelevant context to remote seller agent. For example, ordered pizza item is not relevant for the burger seller agent\n",
    "- Never ask order confirmation to the remote seller agent \n",
    "\n",
    "Please rely on tools to address the request, and don't make up the response. If you are not sure, please ask the user for more details.\n",
    "Focus on the most recent parts of the conversation primarily.\n",
    "\n",
    "If there is an active agent, send the request to that agent with the update task tool.\n",
    "\n",
    "Agents:\n",
    "{self.agents}\n",
    "\n",
    "Current active seller agent: {current_agent[\"active_agent\"]}\n",
    "\"\"\"\n",
    "\n",
    "    def check_active_agent(self, context: ReadonlyContext):\n",
    "        state = context.state\n",
    "        if (\n",
    "            \"session_id\" in state\n",
    "            and \"session_active\" in state\n",
    "            and state[\"session_active\"]\n",
    "            and \"active_agent\" in state\n",
    "        ):\n",
    "            return {\"active_agent\": f\"{state['active_agent']}\"}\n",
    "        return {\"active_agent\": \"None\"}\n",
    "\n",
    "    async def before_agent_callback(self, callback_context: CallbackContext):\n",
    "        if not self.a2a_client_init_status:\n",
    "            httpx_client = httpx.AsyncClient(timeout=httpx.Timeout(timeout=30))\n",
    "            for address in self.remote_agent_addresses:\n",
    "                card_resolver = A2ACardResolver(\n",
    "                    base_url=address, httpx_client=httpx_client\n",
    "                )\n",
    "                try:\n",
    "                    card = await card_resolver.get_agent_card()\n",
    "                    remote_connection = RemoteAgentConnections(\n",
    "                        agent_card=card, agent_url=card.url\n",
    "                    )\n",
    "                    self.remote_agent_connections[card.name] = remote_connection\n",
    "                    self.cards[card.name] = card\n",
    "                except httpx.ConnectError:\n",
    "                    print(f\"ERROR: Failed to get agent card from : {address}\")\n",
    "            agent_info = []\n",
    "            for ra in self.list_remote_agents():\n",
    "                agent_info.append(json.dumps(ra))\n",
    "            self.agents = \"\\n\".join(agent_info)\n",
    "            self.a2a_client_init_status = True\n",
    "\n",
    "    async def before_model_callback(\n",
    "        self, callback_context: CallbackContext, llm_request\n",
    "    ):\n",
    "        state = callback_context.state\n",
    "        if \"session_active\" not in state or not state[\"session_active\"]:\n",
    "            if \"session_id\" not in state:\n",
    "                state[\"session_id\"] = str(uuid.uuid4())\n",
    "            state[\"session_active\"] = True\n",
    "\n",
    "    def list_remote_agents(self):\n",
    "        \"\"\"List the available remote agents you can use to delegate the task.\"\"\"\n",
    "        if not self.remote_agent_connections:\n",
    "            return []\n",
    "\n",
    "        remote_agent_info = []\n",
    "        for card in self.cards.values():\n",
    "            print(f\"Found agent card: {card.model_dump()}\")\n",
    "            print(\"=\" * 100)\n",
    "            remote_agent_info.append(\n",
    "                {\"name\": card.name, \"description\": card.description}\n",
    "            )\n",
    "        return remote_agent_info\n",
    "\n",
    "    def send_task(self, agent_name: str, task: str, tool_context: ToolContext):\n",
    "        \"\"\"Sends a task to remote seller agent\n",
    "\n",
    "        This will send a message to the remote agent named agent_name.\n",
    "\n",
    "        Args:\n",
    "            agent_name: The name of the agent to send the task to.\n",
    "            task: The comprehensive conversation context summary\n",
    "                and goal to be achieved regarding user inquiry and purchase request.\n",
    "            tool_context: The tool context this method runs in.\n",
    "\n",
    "        Yields:\n",
    "            A dictionary of JSON data.\n",
    "        \"\"\"\n",
    "        if agent_name not in self.remote_agent_connections:\n",
    "            raise ValueError(f\"Agent {agent_name} not found\")\n",
    "        state = tool_context.state\n",
    "        state[\"active_agent\"] = agent_name\n",
    "        client = self.remote_agent_connections[agent_name]\n",
    "        if not client:\n",
    "            raise ValueError(f\"Client not available for {agent_name}\")\n",
    "        session_id = state[\"session_id\"]\n",
    "        task: Task\n",
    "        message_id = \"\"\n",
    "        metadata = {}\n",
    "        if \"input_message_metadata\" in state:\n",
    "            metadata.update(**state[\"input_message_metadata\"])\n",
    "            if \"message_id\" in state[\"input_message_metadata\"]:\n",
    "                message_id = state[\"input_message_metadata\"][\"message_id\"]\n",
    "        if not message_id:\n",
    "            message_id = str(uuid.uuid4())\n",
    "\n",
    "        payload = {\n",
    "            \"message\": {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\n",
    "                    {\"type\": \"text\", \"text\": task}\n",
    "                ],  # Use the 'task' argument here\n",
    "                \"messageId\": message_id,\n",
    "                \"contextId\": session_id,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        message_request = SendMessageRequest(\n",
    "            id=message_id, params=MessageSendParams.model_validate(payload)\n",
    "        )\n",
    "        send_response: SendMessageResponse = client.send_message(\n",
    "            message_request=message_request\n",
    "        )\n",
    "        print(\n",
    "            \"send_response\",\n",
    "            send_response.model_dump_json(exclude_none=True, indent=2),\n",
    "        )\n",
    "\n",
    "        if not isinstance(send_response.root, SendMessageSuccessResponse):\n",
    "            print(\"received non-success response. Aborting get task \")\n",
    "            return None\n",
    "\n",
    "        if not isinstance(send_response.root.result, Task):\n",
    "            print(\"received non-task response. Aborting get task \")\n",
    "            return None\n",
    "\n",
    "        return send_response.root.result\n",
    "\n",
    "\n",
    "def convert_parts(parts: list[Part], tool_context: ToolContext):\n",
    "    rval = []\n",
    "    for p in parts:\n",
    "        rval.append(convert_part(p, tool_context))\n",
    "    return rval\n",
    "\n",
    "\n",
    "def convert_part(part: Part, tool_context: ToolContext):\n",
    "    # Currently only support text parts\n",
    "    if part.type == \"text\":\n",
    "        return part.text\n",
    "\n",
    "    return f\"Unknown type: {part.type}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20466f3d-14df-45fe-aea8-acb7fd039f2d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af720432-afee-4716-b98d-954d94e574a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "AGENT_REMOTE_CONNECTION_PYTHON = './purchasing_concierge/remote_agent_connection.py'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5457920-e017-4606-a15b-583d31d3ccac",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writefile {AGENT_REMOTE_CONNECTION_PYTHON}\n",
    "from typing import Callable\n",
    "\n",
    "import httpx\n",
    "\n",
    "from a2a.client import A2AClient\n",
    "from a2a.types import (\n",
    "    AgentCard,\n",
    "    SendMessageRequest,\n",
    "    SendMessageResponse,\n",
    "    Task,\n",
    "    TaskArtifactUpdateEvent,\n",
    "    TaskStatusUpdateEvent,\n",
    ")\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from typing import Any\n",
    "from a2a.client.errors import (\n",
    "    A2AClientHTTPError,\n",
    "    A2AClientJSONError,\n",
    "    A2AClientTimeoutError,\n",
    ")\n",
    "from a2a.client.middleware import ClientCallContext\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TaskCallbackArg = Task | TaskStatusUpdateEvent | TaskArtifactUpdateEvent\n",
    "TaskUpdateCallback = Callable[[TaskCallbackArg, AgentCard], Task]\n",
    "\n",
    "\n",
    "def _send_request(\n",
    "    self,\n",
    "    rpc_request_payload: dict[str, Any],\n",
    "    http_kwargs: dict[str, Any] | None = None,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Sends a non-streaming JSON-RPC request to the agent.\n",
    "\n",
    "    Args:\n",
    "        rpc_request_payload: JSON RPC payload for sending the request.\n",
    "        http_kwargs: Optional dictionary of keyword arguments to pass to the\n",
    "            underlying post request.\n",
    "\n",
    "    Returns:\n",
    "        The JSON response payload as a dictionary.\n",
    "\n",
    "    Raises:\n",
    "        A2AClientHTTPError: If an HTTP error occurs during the request.\n",
    "        A2AClientJSONError: If the response body cannot be decoded as JSON.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            self.url, json=rpc_request_payload, **(http_kwargs or {})\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except httpx.ReadTimeout as e:\n",
    "        raise A2AClientTimeoutError(\"Client Request timed out\") from e\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        raise A2AClientHTTPError(e.response.status_code, str(e)) from e\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise A2AClientJSONError(str(e)) from e\n",
    "    except httpx.RequestError as e:\n",
    "        raise A2AClientHTTPError(503, f\"Network communication error: {e}\") from e\n",
    "\n",
    "\n",
    "def send_message(\n",
    "    self,\n",
    "    request: SendMessageRequest,\n",
    "    *,\n",
    "    http_kwargs: dict[str, Any] | None = None,\n",
    "    context: ClientCallContext | None = None,\n",
    ") -> SendMessageResponse:\n",
    "    \"\"\"Sends a non-streaming message request to the agent.\n",
    "\n",
    "    Args:\n",
    "        request: The `SendMessageRequest` object containing the message and configuration.\n",
    "        http_kwargs: Optional dictionary of keyword arguments to pass to the\n",
    "            underlying httpx.post request.\n",
    "        context: The client call context.\n",
    "\n",
    "    Returns:\n",
    "        A `SendMessageResponse` object containing the agent's response (Task or Message) or an error.\n",
    "\n",
    "    Raises:\n",
    "        A2AClientHTTPError: If an HTTP error occurs during the request.\n",
    "        A2AClientJSONError: If the response body cannot be decoded as JSON or validated.\n",
    "    \"\"\"\n",
    "    if not request.id:\n",
    "        request.id = str(uuid4())\n",
    "\n",
    "    response_data = self._send_request(\n",
    "        request.model_dump(mode=\"json\", exclude_none=True), http_kwargs\n",
    "    )\n",
    "    return SendMessageResponse.model_validate(response_data)\n",
    "\n",
    "\n",
    "class RemoteAgentConnections:\n",
    "    \"\"\"A class to hold the connections to the remote agents.\"\"\"\n",
    "\n",
    "    def __init__(self, agent_card: AgentCard, agent_url: str):\n",
    "        print(f\"agent_card: {agent_card}\")\n",
    "        print(f\"agent_url: {agent_url}\")\n",
    "        self._httpx_client = httpx.AsyncClient(timeout=30)\n",
    "        self.agent_client = A2AClient(self._httpx_client, agent_card, url=agent_url)\n",
    "\n",
    "        # Replace the original method with our custom implementation\n",
    "        # NOTE: This is a temporary workaround for issue in httpx event closed\n",
    "        self.agent_client._send_request = _send_request.__get__(self.agent_client)\n",
    "        self.agent_client.send_message = send_message.__get__(self.agent_client)\n",
    "\n",
    "        self.card = agent_card\n",
    "\n",
    "    def get_agent(self) -> AgentCard:\n",
    "        return self.card\n",
    "\n",
    "    def send_message(self, message_request: SendMessageRequest) -> SendMessageResponse:\n",
    "        return self.agent_client.send_message(message_request)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ab30479-cdc4-4768-ba2e-c0f613703d24",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e269de22-cf16-4681-b49c-9eb7faecb74b",
   "metadata": {
    "tags": []
   },
   "source": [
    "ADK_AGENT_PYTHON = './purchasing_concierge/agent.py'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f613393-65ed-4626-9bb7-0c9cb8a11161",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writefile {ADK_AGENT_PYTHON}\n",
    "from .purchasing_agent import PurchasingAgent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(os.path.join(os.path.dirname(__file__), \".env\"))\n",
    "\n",
    "root_agent = PurchasingAgent(\n",
    "    remote_agent_addresses=[\n",
    "        os.getenv(\"PIZZA_SELLER_AGENT_URL\", \"http://localhost:10000\"),\n",
    "        os.getenv(\"BURGER_SELLER_AGENT_URL\", \"http://localhost:10001\"),\n",
    "    ]\n",
    ").create_agent()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5362e86-8196-443a-82fe-02c608c0a507",
   "metadata": {
    "tags": []
   },
   "source": [
    "import vertexai\n",
    "from vertexai.preview import reasoning_engines\n",
    "from vertexai import agent_engines\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from purchasing_concierge.agent import root_agent\n",
    "\n",
    "#importlib.reload(agent)  # Force reload\n",
    "\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET_URI,\n",
    ")\n",
    "\n",
    "adk_app = reasoning_engines.AdkApp(\n",
    "    agent=root_agent,\n",
    "    enable_tracing=True\n",
    ")\n",
    "\n",
    "remote_app = agent_engines.create(\n",
    "    agent_engine=adk_app,\n",
    "    display_name=\"purchasing-concierge\",\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[agent_engines]==1.115.0\",\n",
    "        \"google-adk==1.15.1\",\n",
    "        \"a2a-sdk==0.2.16\",\n",
    "    ],\n",
    "    extra_packages=[\n",
    "        \"./purchasing_concierge/\",\n",
    "    ],\n",
    "    env_vars={\n",
    "        \"GOOGLE_GENAI_USE_VERTEXAI\": \"TRUE\",\n",
    "        \"PIZZA_SELLER_AGENT_URL\": PIZZA_AGENT_SERVICE_URL,\n",
    "        \"BURGER_SELLER_AGENT_URL\": BURGER_AGENT_SERVICE_URL,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Deployed remote app resource: {remote_app.resource_name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4356d36-c69b-4dbb-9531-e7510f32ae25",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(remote_app.resource_name)\n",
    "os.environ[\"AGENT_ENGINE_RESOURCE_NAME\"] = remote_app.resource_name"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cee450e0-4638-4211-b4b2-b54763bac3cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test ADK Agent using curl:"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f48f1b6-ee88-4c24-af53-264f91759a3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "curl \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/v1/${AGENT_ENGINE_RESOURCE_NAME}:streamQuery?alt=sse -d '{\n",
    "  \"class_method\": \"stream_query\",\n",
    "  \"input\": {\n",
    "    \"user_id\": \"user_123\",\n",
    "    \"message\": \"List available burger menu please\",\n",
    "  }\n",
    "}'\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45f6a490-7525-40ec-847f-a033a6000ac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 1. Get the AGENT_ENGINE_RESOURCE_NAME from environment variables\n",
    "# Example: \"projects/your-gcp-project-id/locations/us-central1/agents/your-agent-id/engines/your-engine-id\"\n",
    "agent_engine_resource_name = os.getenv(\"AGENT_ENGINE_RESOURCE_NAME\")\n",
    "if not agent_engine_resource_name:\n",
    "    raise ValueError(\"The 'AGENT_ENGINE_RESOURCE_NAME' environment variable is not set.\")\n",
    "\n",
    "# 2. Construct the full URL\n",
    "url = f\"https://us-central1-aiplatform.googleapis.com/v1/{agent_engine_resource_name}:streamQuery\"\n",
    "\n",
    "# 3. Get the gcloud access token\n",
    "try:\n",
    "    token_process = subprocess.run(\n",
    "        [\"gcloud\", \"auth\", \"print-access-token\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    access_token = token_process.stdout.strip()\n",
    "except (subprocess.CalledProcessError, FileNotFoundError) as e:\n",
    "    print(f\"Error getting gcloud access token: {e}\")\n",
    "    print(\"Please ensure the gcloud CLI is installed, authenticated, and in your system's PATH.\")\n",
    "    exit(1)\n",
    "\n",
    "# 4. Define the request headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# 5. Define the request payload (data)\n",
    "payload = {\n",
    "    \"class_method\": \"stream_query\",\n",
    "    \"input\": {\n",
    "        \"user_id\": \"user_123\",\n",
    "        \"message\": \"List available pizza menu please\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 6. Make the POST request with streaming enabled\n",
    "try:\n",
    "    with requests.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json=payload, # requests handles JSON serialization\n",
    "        params={\"alt\": \"sse\"}, # Handles the query parameter\n",
    "        stream=True  # This is key for streaming responses\n",
    "    ) as response:\n",
    "        # Check for HTTP errors\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        print(\"Successfully connected to stream. Waiting for data...\")\n",
    "        # Iterate over the response line by line as data arrives\n",
    "        stream_chunk = 0\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                # Decode bytes to string\n",
    "                decoded_line = line.decode('utf-8')\n",
    "                print(f\"------------------------[Stream chunk:{str(stream_chunk)}]------------------------\")\n",
    "                print(json.dumps(json.loads(decoded_line), indent=4))\n",
    "                stream_chunk+=1\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred during the request: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d64a9693-a366-4956-9a00-2d68f848e60c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import gradio as gr\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "from pprint import pformat\n",
    "from vertexai import agent_engines\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()\n",
    "\n",
    "USER_ID = \"default_user\"\n",
    "\n",
    "REMOTE_APP = agent_engines.get(os.getenv(\"AGENT_ENGINE_RESOURCE_NAME\"))\n",
    "SESSION_ID = REMOTE_APP.create_session(user_id=USER_ID)[\"id\"]\n",
    "\n",
    "\n",
    "async def get_response_from_agent(\n",
    "    message: str,\n",
    "    history: List[Dict[str, Any]],\n",
    ") -> str:\n",
    "    \"\"\"Send the message to the backend and get a response.\n",
    "\n",
    "    Args:\n",
    "        message: Text content of the message.\n",
    "        history: List of previous message dictionaries in the conversation.\n",
    "\n",
    "    Returns:\n",
    "        Text response from the backend service.\n",
    "    \"\"\"\n",
    "    # try:\n",
    "\n",
    "    default_response = \"No response from agent\"\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    for event in REMOTE_APP.stream_query(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        message=message,\n",
    "    ):\n",
    "        parts = event.get(\"content\", {}).get(\"parts\", [])\n",
    "        if parts:\n",
    "            for part in parts:\n",
    "                if part.get(\"function_call\"):\n",
    "                    #formatted_call = f\"```python\\n{pformat(part.get('function_call'), indent=2, width=80)}\\n```\"\n",
    "                    formatted_call = pformat(part.get('function_call'), indent=2, width=80)\n",
    "                    responses.append(\n",
    "                        gr.ChatMessage(\n",
    "                            role=\"assistant\",\n",
    "                            content=f\"{part.get('function_call').get('name')}:\\n{formatted_call}\",\n",
    "                            metadata={\"title\": \"üõ†Ô∏è Tool Call\"},\n",
    "                        )\n",
    "                        # {\n",
    "                        #     \"role\": \"assistant\",\n",
    "                        #     \"content\": f\"{part.get('function_call').get('name')}:\\n{formatted_call}\",\n",
    "                        #     \"metadata\": {\"title\": \"üõ†Ô∏è Tool Call\"},\n",
    "                        # }\n",
    "                    )\n",
    "                elif part.get(\"function_response\"):\n",
    "                    formatted_response = pformat(part.get('function_response'), indent=2, width=80)\n",
    "\n",
    "                    responses.append(\n",
    "                        gr.ChatMessage(\n",
    "                            role=\"assistant\",\n",
    "                            content=formatted_response,\n",
    "                            metadata={\"title\": \"‚ö° Tool Response\"},\n",
    "                        )\n",
    "                        # {\n",
    "                        #     \"role\": \"assistant\",\n",
    "                        #     \"content\": formatted_response,\n",
    "                        #     \"metadata\": {\"title\": \"‚ö° Tool Response\"},\n",
    "                        # }\n",
    "                    )\n",
    "                elif part.get(\"text\"):\n",
    "                    responses.append(\n",
    "                        gr.ChatMessage(\n",
    "                            role=\"assistant\",\n",
    "                            content=part.get(\"text\"),\n",
    "                        )\n",
    "                        # {\n",
    "                        #     \"role\": \"assistant\",\n",
    "                        #     \"content\": part.get(\"text\"),\n",
    "                        # }\n",
    "                    )\n",
    "                else:\n",
    "                    formatted_unknown_parts = pformat(part, indent=2, width=80)\n",
    "\n",
    "                    responses.append(\n",
    "                        gr.ChatMessage(\n",
    "                            role=\"assistant\",\n",
    "                            content=formatted_unknown_parts,\n",
    "                        )\n",
    "                        \n",
    "                        # {\n",
    "                        #     \"role\": \"assistant\",\n",
    "                        #     \"content\": formatted_unknown_parts,\n",
    "                        # }\n",
    "                    )\n",
    "\n",
    "    if not responses:\n",
    "        yield default_response\n",
    "\n",
    "    yield responses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6bbc03ee-3615-4416-ac90-bcbe958f63ff",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e17f571-6bf5-4281-9c6c-9285dbabb928",
   "metadata": {
    "tags": []
   },
   "source": [
    "%autoawait asyncio\n",
    "aaa=get_response_from_agent(\"List available pizza menu please\", None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "397c7db5-5904-4cc7-b641-50acb955b869",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This will wait for the generator to finish and collect all chunks\n",
    "all_chunks = [chunk async for chunk in get_response_from_agent(\"List available pizza menu please\", None)]\n",
    "for chunks in all_chunks:\n",
    "    for chunk in chunks:\n",
    "        print(\"--------------------\\n\")\n",
    "        print(chunk)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1669bf30-716f-49f7-a82a-f06936f088c9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-adk_a2a_kernel-adk_a2a_kernel",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "ADK A2A Kernel (Local)",
   "language": "python",
   "name": "conda-env-adk_a2a_kernel-adk_a2a_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
