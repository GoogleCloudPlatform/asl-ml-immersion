{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L6Nm1C-wshE"
   },
   "source": [
    "# Model Context Protocol(MCP)\n",
    "\n",
    "The **Model Context Protocol (MCP)** is an **open standard protocol initiated by Anthropic**. Its core purpose is to **standardize how AI models, applications, and agents connect to and interact with external tools, data sources, and services**. This allows AI applications to **access real-time data, use tools, fetch data, and utilize prompts** from compliant external systems.\n",
    "\n",
    "Think of MCP as a \"**USB-C port for AI**\",\n",
    "providing a **standardized interface** to solve the M×N integration problem by enabling any compliant AI client to connect to any compliant MCP server. It follows a **client-server architecture** (Hosts, Clients, Servers) and is built on **JSON-RPC 2.0**, supporting transports like Stdio and HTTP with SSE.\n",
    "\n",
    "MCP servers expose capabilities including **Tools, Resources, and Prompts**. It **standardizes the execution** of instructions generated by methods like Function Calling.\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Why MCP is needed?\n",
    "\n",
    "The need for the Model Context Protocol (MCP) arose primarily from the **limitations of LLMs being isolated** from real-time data, user-specific context, and external systems. Before MCP, connecting AI applications to the vast landscape of tools, databases, and services required **custom, fragmented integrations for each pair** of application and tool. This resulted in the \"M×N integration problem,\" which was **time-consuming, difficult to scale, and led to limited functionality**.\n",
    "\n",
    "MCP was needed to provide a **standardized, universal interface**—often likened to a \"**USB-C port for AI**\"—to connect AI models to *any* compliant external system. It also addresses the need to **standardize the execution phase** of LLM-generated instructions (like those from Function Calling), ensuring consistency and scalability across diverse tools. This approach **simplifies development, promotes interoperability**, and allows AI applications to access the real-world context and capabilities necessary to be truly helpful.\n",
    "<hr/>\n",
    "\n",
    "![MCP](https://norahsakal.com/assets/images/mcp_overview-641a298352ff835488af36be3d8eee52.png)\n",
    "Source: [Norah Sakal](https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/)\n",
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-3k4PVFxepX"
   },
   "source": [
    "### Core Architecture\n",
    "\n",
    "The core architecture of MCP follows a client-server model. The key components are:\n",
    "<br/><br/>\n",
    "• MCP Hosts: These are AI applications or environments, such as LLM Apps or IDEs, that initiate connections and operate the MCP client.\n",
    "<br/><br/>\n",
    "• MCP Clients: Located within the host application, clients maintain a one-to-one connection with servers. They act as intermediaries, facilitating communication between the MCP host and servers, sending requests, seeking information about server services, and handling LLM routing and orchestration.\n",
    "<br/><br/>\n",
    "• MCP Servers: These are lightweight programs that act as a gateway, allowing the MCP client to interact with external services and execute tasks. Servers connect to data sources and tools (like Google Drive, Slack, or databases) and expose specific capabilities\n",
    "\n",
    "<hr/>\n",
    "\n",
    "![Corearchitecture.png](https://composio.dev/wp-content/uploads/2025/03/mcp-matt.jpeg)\n",
    "Source: [Composio.dev Blogs](https://composio.dev/blog/what-is-model-context-protocol-mcp-explained/)\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR9_hyA42HNC"
   },
   "source": [
    "## Function Calling vs MCP\n",
    "\n",
    "Function Calling and the Model Context Protocol (MCP) are distinct but **complementary** frameworks for integrating Large Language Models (LLMs) with external systems. They represent **two phases** in the process of enabling LLMs to interact with the real world.\n",
    "\n",
    "**Key Differences Summarized:**\n",
    "\n",
    "\n",
    "| Feature           | Function Calling                                 | MCP (Model Context Protocol)                                   |\n",
    "| :---------------- | :----------------------------------------------- | :------------------------------------------------------------- |\n",
    "| **Purpose**       | Translates prompts into structured instructions. | Standardizes execution and response handling of instructions. |     |\n",
    "| **Focus**         | Generating action-ready commands from natural language. | Managing tool discovery, invocation, and response handling. |\n",
    "| **Control**       | LLM provider (e.g., Google Gemini, OpenAI, Anthropic).     | External system/application handling LLM integration.    |             |\n",
    "| **Output/Protocol** | Varies by LLM vendor (JSON-based). | Uses a standardized protocol (JSON-RPC 2.0). |\n",
    "| **Role in Workflow**| \"Ordering the task\" (Translation phase). | \"Executing the task\" (Execution phase).    |\n",
    "| **Architecture**  | Part of the LLM's output structure. | Client-server architecture connecting hosts, clients, and servers. |\n",
    "| **Statefulness**  | Typically a stateless request/response outcome from the LLM | Can support stateful connections and interactive workflows |\n",
    "| **Standardization** | No universal standard (frameworks like LangChain help manage variations). | Provides a consistent execution framework and ensures interoperability across tools. |\n",
    "| **Complexity/Setup** | Simpler, more direct method. | Requires setup of MCP clients and servers, potentially higher initial complexity. |       |\n",
    "| **Security**      | Relies on external API security and execution control management. | Designed with inherent security measures (host-mediated, access controls, user approval). |\n",
    "\n",
    "**Working Together:**\n",
    "\n",
    "Function Calling and MCP work together seamlessly. The application acts as an intermediary, translating the LLM's function call output (which varies by vendor) into a standardized MCP request (using JSON-RPC) that the MCP server can understand and execute. MCP then handles the execution of the tool and returns the result in a structured format, which the application can feed back to the LLM or the user.\n",
    "\n",
    "Think of it like a universal adapter for AI applications, similar to USB-C for physical devices. While Function Calling allows LLMs to translate prompts into *what* needs to be done (the command), MCP standardizes *how* it gets done (the execution across different tools and data sources). This combined approach allows for more efficient, scalable, and flexible AI-powered systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjxNy3BCH3zz"
   },
   "source": [
    "# Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGckulE4H58R"
   },
   "source": [
    "## Setup\n",
    "This lab needs a special kernel to run, please run the following cell.\n",
    "**NOTE: You can skip this step if you have already built the ADK Kernel from the previous Lab**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeJiIbR2ItpW",
    "outputId": "63c5cd1d-7811-4a14-dcfd-11eb769a1066",
    "tags": []
   },
   "source": [
    "!echo \"Kernel installation started.\"\n",
    "!cd ../../../.. && make adk_mcp_a2a_kernel > /dev/null 2>&1\n",
    "!echo \"Kernel installation completed.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKwGrxSiJXAk"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Tu6ca4rJJVxp",
    "tags": []
   },
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"REGION\"]=REGION\n",
    "os.environ[\"PROJECT_ID\"]=PROJECT_ID\n",
    "os.environ.setdefault(\"GOOGLE_CLOUD_PROJECT\", PROJECT_ID)\n",
    "os.environ.setdefault(\"GOOGLE_CLOUD_LOCATION\", LOCATION)\n",
    "os.environ.setdefault(\"GOOGLE_GENAI_USE_VERTEXAI\", \"True\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfJ-_siaLJUZ"
   },
   "source": [
    "# Demo\n",
    "\n",
    "* This Demo uses [FastMCP](https://gofastmcp.com/getting-started/welcome) to create an Inventory Management tool MCP Server.\n",
    "\n",
    "* An ADK based agent act as MCP host and uses a MCP client([ADK MCP Toolset](https://google.github.io/adk-docs/tools/mcp-tools/#step-1-attach-the-fastmcp-server-to-your-adk-agent-via-mcptoolset:~:text=to%20your%20ADK%20agent%20via%20MCPToolset-,%C2%B6,-Create%20agent.py%20in%20./adk_agent_samples/fastmcp_agent)) to communicate with the MCP Server and fetches the available tools.\n",
    "\n",
    "* The ADK agent uses the tools from MCP server to answer inventory related request from users.\n",
    "\n",
    "### Create Directory for the project"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ftwIFKXV_hIs",
    "tags": []
   },
   "source": [
    "!mkdir mcp-demo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCIRgv0FMLAs"
   },
   "source": [
    "# Download dummy Inventory data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCiZIjhVNuBo",
    "outputId": "9e88444f-c02c-42d1-d5be-17ee9e6ad877",
    "tags": []
   },
   "source": [
    "!wget https://raw.githubusercontent.com/solidate/mcp-demo/refs/heads/main/sku_data.csv -O mcp-demo/sku_data.csv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZ1GEPMnMQX7"
   },
   "source": [
    "# MCP Server code usign FastMCP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olS-8oqkKArg",
    "outputId": "99b9b522-b4cb-4077-fd1f-4e9c3cc7b68f",
    "tags": []
   },
   "source": [
    "%%writefile mcp-demo/operations.py\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import asyncio\n",
    "from fastmcp import FastMCP\n",
    "from pydantic import  Field\n",
    "from pydantic.types import Literal\n",
    "\n",
    "# Define the path to the CSV file relative to this script\n",
    "# Assuming operations.py and sku_data.csv are in the same directory 'agents/inventory/'\n",
    "CSV_FILE_PATH = os.path.join(os.path.dirname(__file__), 'sku_data.csv')\n",
    "\n",
    "\n",
    "global mcp\n",
    "mcp = FastMCP(\n",
    "    name=\"Inventory MCP Server\",\n",
    "    instructions=\"\"\"\n",
    "    This Server provides inventory related data and helps in\n",
    "    updating the quantity of a specific SKU.\n",
    "\n",
    "    Call list_skus() to get the list of all the SKUs or any details related the items/SKUs.\n",
    "    Call update_sku_qty(sku_id) to update the quantity of a specific SKU.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def list_skus(sku_name: str = Field(\"*\", description=\"Name of the SKU\")):\n",
    "    \"\"\"\n",
    "    Reads the SKU data from the CSV file and returns it as a list of dictionaries.\n",
    "    If you are asked for the available items or any enquiry about the items/SKUs, call this function and\n",
    "    return only the consumer freindly information like id, name and its cost and available quantity.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CSV_FILE_PATH):\n",
    "        return {\"error\": \"SKU data file not found.\"}\n",
    "\n",
    "    skus = []\n",
    "    try:\n",
    "        with open(CSV_FILE_PATH, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                skus.append(row)\n",
    "        return {\"skus\": skus}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to read SKU data: {str(e)}\"}\n",
    "\n",
    "@mcp.tool()\n",
    "def update_sku_qty(\n",
    "            sku_id: str = Field(..., description=\"The SKU ID of the product to update.\"),\n",
    "            quantity: int = Field(..., description=\"The quantity to be added or removed from the SKU.\", ge=0),\n",
    "            sign: int = Field(1, description=\"1 for adding and -1 for removing.\")\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Updates the quantity of a specific SKU in the CSV file.\n",
    "    If you are asked for placing or returning/cancelling an order, call this function.\n",
    "\n",
    "    Args:\n",
    "        sku_id (str): The SKU ID of the product to update.\n",
    "        quantity (int): The new quantity for the SKU.\n",
    "        sign (int): 1 for adding and -1 for removing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A message indicating success or failure.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CSV_FILE_PATH):\n",
    "        return {\"error\": \"SKU data file not found.\"}\n",
    "\n",
    "    if not isinstance(quantity, int):\n",
    "        return {\"error\": \"Invalid quantity. Must be a non-negative integer.\"}\n",
    "\n",
    "    rows = []\n",
    "    updated = False\n",
    "    fieldnames = []\n",
    "\n",
    "    try:\n",
    "        with open(CSV_FILE_PATH, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            fieldnames = reader.fieldnames\n",
    "            if not fieldnames: # Handle empty or malformed CSV\n",
    "                return {\"error\": \"CSV file is empty or has no header.\"}\n",
    "\n",
    "            quantity *= sign\n",
    "\n",
    "            for row in reader:\n",
    "                if row.get('SKU') == sku_id:\n",
    "                    row['QuantityOnHand'] = int(row['QuantityOnHand']) + int(quantity)\n",
    "                    # Potentially update 'Status' based on new quantity vs ReorderLevel\n",
    "                    if 'ReorderLevel' in row and quantity <= int(row.get('ReorderLevel', 0)):\n",
    "                        row['Status'] = 'Low Stock'\n",
    "                    elif 'ReorderLevel' in row and quantity > int(row.get('ReorderLevel', 0)):\n",
    "                        row['Status'] = 'In Stock'\n",
    "                    updated = True\n",
    "                    updated_qty = row['QuantityOnHand']\n",
    "                rows.append(row)\n",
    "\n",
    "        if not updated:\n",
    "            return {\"error\": f\"SKU ID '{sku_id}' not found.\"}\n",
    "\n",
    "        with open(CSV_FILE_PATH, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        return {\"message\": f\"Quantity for SKU '{sku_id}' updated to {updated_qty}.\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to update SKU quantity: {str(e)}\"}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(mcp.run_sse_async(\n",
    "                        host=\"0.0.0.0\",\n",
    "                        port=4200,\n",
    "                        path=\"/inventory\",\n",
    "                        )\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PtAwoGnMiCh"
   },
   "source": [
    "### Setup MCP Server\n",
    "\n",
    "#### Step 1: Open the Built-in Terminal\n",
    "\n",
    "First, open the integrated terminal in your Vertex AI Workbench interface.\n",
    " - Go to File -> New -> Terminal.\n",
    "\n",
    "#### Step 2: Start a New tmux Session\n",
    "In the terminal you just opened, check current directory:\n",
    "```bash\n",
    "pwd\n",
    "```\n",
    "change your current driectory to \n",
    "\"/asl-ml-immersion/notebooks/vertex_genai/solutions/a2a/\",\n",
    "```bash\n",
    "cd a2a\n",
    "```\n",
    "#### Step 3: Start a New tmux Session\n",
    "\n",
    "In the terminal, give your session a name. Let's call it my_session.\n",
    "Type the following command and press Enter:\n",
    "```bash\n",
    "tmux new -s demo_mcp_session\n",
    "```\n",
    "#### Step 4: Send Commands from Your Notebook Cell"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "!tmux send-keys -t demo_mcp_session 'python mcp-demo/operations.py' C-m"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZmEr-i0Mioq"
   },
   "source": [
    "# Create ADK based agent with MCP client\n",
    "* Here MCPToolset is used to communicate with SSE server url where MCP Server runs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jxsE_rGI_z9b",
    "tags": []
   },
   "source": [
    "import argparse\n",
    "import asyncio\n",
    "from contextlib import AsyncExitStack\n",
    "from uuid import uuid4\n",
    "\n",
    "import click\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import SseServerParams\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# TODO: IMPORTANT! Change the path below to your remote MCP Server path\n",
    "MCP_SERVER_URL=\"http://0.0.0.0:4200/inventory\"\n",
    "\n",
    "async def create_agent():\n",
    "    common_exit_stack = AsyncExitStack()\n",
    "\n",
    "    agent = LlmAgent(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        name=\"inventory_assistant\",\n",
    "        description=\"You are a specialized assistant for inventory management.\",\n",
    "        instruction=(\n",
    "            \"Help user get answer to their queries about inventory and update \"\n",
    "            \"the items.\"\n",
    "        ),\n",
    "        tools=[\n",
    "            McpToolset(\n",
    "                connection_params=SseServerParams(\n",
    "                url=MCP_SERVER_URL\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    return agent, common_exit_stack\n",
    "\n",
    "async def ask_agent(query):\n",
    "    session_service = InMemorySessionService()\n",
    "    inventory_agent, exit_stack = await create_agent()\n",
    "\n",
    "    # Create the session here, just before it's used\n",
    "    session = await session_service.create_session(\n",
    "        state={}, app_name=\"mcp_inventory_app\", user_id=str(uuid4())\n",
    "    )\n",
    "\n",
    "    runner = Runner(\n",
    "        app_name=\"mcp_inventory_app\",\n",
    "        agent=inventory_agent,\n",
    "        session_service=session_service,\n",
    "    )\n",
    "    user_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "    print(\"Running agent...\")\n",
    "    events_async = runner.run_async(\n",
    "        session_id=session.id, user_id=session.user_id, new_message=user_content\n",
    "    )\n",
    "    async for event in events_async:\n",
    "        print(\"-\" * 10)\n",
    "        print(event)\n",
    "        if event.is_final_response():\n",
    "            final_response = \"\".join(part.text for part in event.content.parts)\n",
    "            break\n",
    "\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"Final response:\")\n",
    "    print(\"-\" * 10)\n",
    "    print(final_response)\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Closing MCP server connection...\")\n",
    "    await exit_stack.aclose()\n",
    "    print(\"Cleanup complete.\")\n",
    "\n",
    "\n",
    "async def ask_inventory_agent(query):\n",
    "    loop = asyncio.get_running_loop()\n",
    "    await loop.create_task(ask_agent(query))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "def print_adk_output(event: dict):\n",
    "    # Extract the first part of the content\n",
    "    part = event.get(\"content\", {}).get(\"parts\", [{}])[0]\n",
    "    author = event.get(\"author\", \"unknown_agent\")\n",
    "    print(f\"\\n--- [Event: {author}] ---\")\n",
    "\n",
    "    # Case 1: The model is calling a function/tool\n",
    "    if \"function_call\" in part:\n",
    "        call = part[\"function_call\"]\n",
    "        func_name = call.get(\"name\", \"N/A\")\n",
    "        func_args = call.get(\"args\", {})\n",
    "        print(\"Tool Call:\")\n",
    "        print(f\"  - Function: {func_name}\")\n",
    "        print(f\"  - Arguments: {json.dumps(func_args, indent=2)}\")\n",
    "\n",
    "    # Case 2: The tool is returning a response\n",
    "    elif \"function_response\" in part:\n",
    "        response = part[\"function_response\"]\n",
    "        func_name = response.get(\"name\", \"N/A\")\n",
    "        func_response = response.get(\"response\", {})\n",
    "        print(\"Tool Response:\")\n",
    "        print(f\"  - From: {func_name}\")\n",
    "        # Pretty print the response JSON\n",
    "        print(f\"  - Data: {json.dumps(func_response, indent=2)}\")\n",
    "\n",
    "    # Case 3: The model is generating a final text response\n",
    "    elif \"text\" in part:\n",
    "        text_response = part[\"text\"].strip()\n",
    "        print(\"Final Agent Response:\")\n",
    "        print(f\"  -> {text_response}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Unknown step type.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDSiRFB5GwGp",
    "outputId": "119bfc8f-7e6a-47c4-fac3-4d8bdef62991",
    "tags": []
   },
   "source": [
    "await ask_inventory_agent(\"How many mouse are available?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXB4Nisydm0S",
    "outputId": "0475bc36-999d-4f67-95bd-3fcf634d1ed4",
    "tags": []
   },
   "source": [
    "await ask_inventory_agent(\"Order 5 wireless mouse\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CDI4qVmIUd2",
    "outputId": "3fa4c3fe-82b4-4c40-d602-c455c1456b04",
    "tags": []
   },
   "source": [
    "await ask_inventory_agent(\"Sell 5 units for SKU002\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVWNUWCPF9n9",
    "outputId": "cc94ad96-f1da-4aab-a1fe-8638d581eaef",
    "tags": []
   },
   "source": [
    "await ask_inventory_agent(\"How many mouse are available?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZs1Ct4yG3I6",
    "outputId": "b0f780a7-c033-4948-9599-7eb53f2621a2",
    "tags": []
   },
   "source": [
    "await ask_inventory_agent(\"Sell 5 units for SKU002\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0C4OMmfIl_T",
    "outputId": "8f9d39ac-ef12-4484-a85a-c1b7300e8387",
    "tags": []
   },
   "source": [
    "await ask_inventory_agent(\"Restock 5 units for SKU002\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RuEYKMY0Iq3h"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-adk_mcp_a2a_kernel-adk_mcp_a2a_kernel",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "ADK MCP A2A Kernel (Local)",
   "language": "python",
   "name": "conda-env-adk_mcp_a2a_kernel-adk_mcp_a2a_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
