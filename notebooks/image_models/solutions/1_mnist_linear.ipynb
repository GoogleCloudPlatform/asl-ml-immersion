{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MNIST Image Classification with JAX/Flax\n",
    "\n",
    "This notebook demonstrates how to implement a simple linear image model on [MNIST](http://yann.lecun.com/exdb/mnist/) using [JAX](https://jax.readthedocs.io/) and [Flax](https://flax.readthedocs.io/).\n",
    "\n",
    "## Learning Objectives\n",
    "1. Know how to read and display image data\n",
    "2. Know how to find incorrect predictions to analyze the model\n",
    "3. Visually see how computers see images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf # For data loading\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "print(jax.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "The MNIST dataset is already included in tensorflow through the keras datasets module. Let's load it and get a sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = x_train[0].shape\n",
    "NCLASSES = len(np.unique(y_train))\n",
    "print(\"Image height x width is\", HEIGHT, \"x\", WIDTH)\n",
    "print(\"There are\", NCLASSES, \"classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is 28 x 28 pixels and represents a digit from 0 to 9. These images are black and white, so each pixel is a value from 0 (white) to 255 (black). Raw numbers can be hard to interpret sometimes, so we can plot the values to see the handwritten digit as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "IMGNO = 12\n",
    "# Uncomment to see raw numerical values.\n",
    "# print(x_test[IMGNO])\n",
    "plt.imshow(x_test[IMGNO].reshape(HEIGHT, WIDTH))\n",
    "print(\"The label for image number\", IMGNO, \"is\", y_test[IMGNO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the model\n",
    "Let's start with a very simple linear classifier. This was the first method to be tried on MNIST in 1998, and scored an 88% accuracy. Quite ground breaking at the time!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build our linear classifier using [Flax](https://flax.readthedocs.io/). We can define a module with a Dense layer and a Softmax activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(features=NCLASSES)(x)\n",
    "        x = nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    model = LinearModel()\n",
    "    params = model.init(rng, jnp.ones([1, HEIGHT, WIDTH]))['params']\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write Input Functions\n",
    "\n",
    "As usual, we need to specify input functions for training and evaluating. We'll scale each pixel value so it's a decimal value between 0 and 1 as a way of normalizing the data.\n",
    "\n",
    "**TODO 1**: Define the scale function below and build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 5000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_dataset(training=True):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = mnist\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, NCLASSES)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(BATCH_SIZE)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE).repeat()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shape_test(training):\n",
    "    dataset = load_dataset(training=training)\n",
    "    data_iter = dataset.as_numpy_iterator()\n",
    "    (images, labels) = next(data_iter)\n",
    "    expected_image_shape = (BATCH_SIZE, HEIGHT, WIDTH)\n",
    "    expected_label_ndim = 2\n",
    "    assert images.shape == expected_image_shape\n",
    "    assert labels.ndim == expected_label_ndim\n",
    "    test_name = \"training\" if training else \"eval\"\n",
    "    print(\"Test for\", test_name, \"passed!\")\n",
    "\n",
    "\n",
    "create_shape_test(True)\n",
    "create_shape_test(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the model! The original MNIST linear classifier had an error rate of 12%. Let's use that to sanity check that our model is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, batch['image'])\n",
    "        loss = -jnp.mean(jnp.sum(batch['label'] * jnp.log(logits + 1e-7), axis=-1))\n",
    "        return loss, logits\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == jnp.argmax(batch['label'], -1))\n",
    "    return state, loss, accuracy\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn({'params': state.params}, batch['image'])\n",
    "    loss = -jnp.mean(jnp.sum(batch['label'] * jnp.log(logits + 1e-7), axis=-1))\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == jnp.argmax(batch['label'], -1))\n",
    "    return loss, accuracy\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "state = create_train_state(init_rng, learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "train_ds = load_dataset(training=True).as_numpy_iterator()\n",
    "val_ds_tf = load_dataset(training=False)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "STEPS_PER_EPOCH = 60000 // BATCH_SIZE\n",
    "\n",
    "history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for _ in range(STEPS_PER_EPOCH):\n",
    "        batch = next(train_ds)\n",
    "        batch_jax = {'image': batch[0], 'label': batch[1]}\n",
    "        state, loss, acc = train_step(state, batch_jax)\n",
    "        train_loss += loss\n",
    "        train_acc += acc\n",
    "    \n",
    "    train_loss /= STEPS_PER_EPOCH\n",
    "    train_acc /= STEPS_PER_EPOCH\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    count = 0\n",
    "    for batch in val_ds_tf.as_numpy_iterator():\n",
    "        batch_jax = {'image': batch[0], 'label': batch[1]}\n",
    "        l, a = eval_step(state, batch_jax)\n",
    "        val_loss += l\n",
    "        val_acc += a\n",
    "        count += 1\n",
    "    \n",
    "    val_loss /= count\n",
    "    val_acc /= count\n",
    "    \n",
    "    history['loss'].append(train_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_ERROR = 0.12\n",
    "BENCHMARK_ACCURACY = 1 - BENCHMARK_ERROR\n",
    "\n",
    "accuracy = history[\"accuracy\"]\n",
    "val_accuracy = history[\"val_accuracy\"]\n",
    "loss = history[\"loss\"]\n",
    "val_loss = history[\"val_loss\"]\n",
    "\n",
    "assert accuracy[-1] > BENCHMARK_ACCURACY\n",
    "assert val_accuracy[-1] > BENCHMARK_ACCURACY\n",
    "print(\"Test to beat benchmark accuracy passed!\")\n",
    "\n",
    "assert accuracy[0] < accuracy[1]\n",
    "assert accuracy[1] < accuracy[-1]\n",
    "assert val_accuracy[0] < val_accuracy[1]\n",
    "assert val_accuracy[1] < val_accuracy[-1]\n",
    "print(\"Test model accuracy is improving passed!\")\n",
    "\n",
    "assert loss[0] > loss[1]\n",
    "assert loss[1] > loss[-1]\n",
    "assert val_loss[0] > val_loss[1]\n",
    "assert val_loss[1] > val_loss[-1]\n",
    "print(\"Test loss is decreasing passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were you able to get an accuracy of over 90%? Not bad for a linear estimator! Let's make some predictions and see if we can find where the model has trouble. Change the range of values below to find incorrect predictions, and plot the corresponding images. What would you have guessed for these images?\n",
    "\n",
    "**TODO 2**: Change the range below to find an incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = range(0, 10, 1)  # Change me, please.\n",
    "\n",
    "def load_prediction_dataset():\n",
    "    dataset = (x_test[image_numbers], y_test[image_numbers])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.map(scale).batch(len(image_numbers))\n",
    "    return dataset\n",
    "\n",
    "# Get batch\n",
    "batch = next(load_prediction_dataset().as_numpy_iterator())\n",
    "images, labels = batch\n",
    "\n",
    "# Predict\n",
    "logits = state.apply_fn({'params': state.params}, images)\n",
    "predicted_results = logits\n",
    "\n",
    "for index, prediction in enumerate(predicted_results):\n",
    "    predicted_value = np.argmax(prediction)\n",
    "    actual_value = y_test[image_numbers[index]]\n",
    "    if actual_value != predicted_value:\n",
    "        print(\"image number: \" + str(image_numbers[index]))\n",
    "        print(\"the prediction was \" + str(predicted_value))\n",
    "        print(\"the actual label is \" + str(actual_value))\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_image_number = 8\n",
    "plt.imshow(x_test[bad_image_number].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's understandable why the poor computer would have some trouble. Some of these images are difficult for even humans to read. In fact, we can see what the computer thinks each digit looks like.\n",
    "\n",
    "Each of the 10 neurons in the dense layer of our model has 785 weights feeding into it. That's 1 weight for every pixel in the image + 1 for a bias term. These weights are flattened feeding into the model, but we can reshape them back into the original image dimensions to see what the computer sees.\n",
    "\n",
    "**TODO 3**: Reshape the layer weights to be the shape of an input image and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGIT = 0  # Change me to be an integer from 0 to 9.\n",
    "LAYER = 1  # Layer 0 flattens image, so no weights\n",
    "WEIGHT_TYPE = 0  # 0 for variable weights, 1 for biases\n",
    "\n",
    "# Access weights from JAX state\n",
    "# Params are a frozen dict.\n",
    "# Structure: {'Dense_0': {'kernel': (784, 10), 'bias': (10,)}}\n",
    "# The original code accessed model.layers[LAYER].get_weights().\n",
    "# Dense layer is the only one with weights here.\n",
    "\n",
    "dense_layer_weights = state.params['Dense_0']\n",
    "if WEIGHT_TYPE == 0:\n",
    "    digit_weights = dense_layer_weights['kernel'][:, DIGIT]\n",
    "else:\n",
    "    digit_weights = dense_layer_weights['bias'] # Bias is 1D\n",
    "\n",
    "if WEIGHT_TYPE == 0:\n",
    "    plt.imshow(digit_weights.reshape((HEIGHT, WIDTH)))\n",
    "else:\n",
    "    print(\"Bias for digit\", DIGIT, \"is\", digit_weights[DIGIT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you recognize the digit the computer was trying to learn? Pretty trippy, isn't it! Even with a simple \"brain\", the computer can form an idea of what a digit should be. The human brain, however, uses [layers and layers of calculations for image recognition](https://www.salk.edu/news-release/brain-recognizes-eye-sees/). Ready for the next challenge? <a href=\"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/images/mnist_linear.ipynb\">Click here</a> to super charge our models with human-like vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercise\n",
    "\n",
    "Want to push your understanding further? Instead of using Keras' built in layers, try repeating the above exercise with your own [custom layers](https://www.tensorflow.org/tutorials/eager/custom_layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2021 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}